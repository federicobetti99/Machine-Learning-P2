{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc28116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0900c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\GSM1586785_ScrH-12A_Exd_14mer_cg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f858a90",
   "metadata": {},
   "source": [
    "We visualize the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834ab75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Kmer</th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>zC_1</th>\n",
       "      <th>zC_2</th>\n",
       "      <th>...</th>\n",
       "      <th>zW_76</th>\n",
       "      <th>zW_77</th>\n",
       "      <th>zW_78</th>\n",
       "      <th>y_79</th>\n",
       "      <th>y_80</th>\n",
       "      <th>y_81</th>\n",
       "      <th>y_82</th>\n",
       "      <th>y_83</th>\n",
       "      <th>y_84</th>\n",
       "      <th>relKa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AATGATTAATTACC</td>\n",
       "      <td>0.593697</td>\n",
       "      <td>-1.092779</td>\n",
       "      <td>0.309117</td>\n",
       "      <td>0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>1.177586</td>\n",
       "      <td>-2.166888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674709</td>\n",
       "      <td>10.019444</td>\n",
       "      <td>-1.012806</td>\n",
       "      <td>-0.790300</td>\n",
       "      <td>-0.112492</td>\n",
       "      <td>0.118705</td>\n",
       "      <td>0.237596</td>\n",
       "      <td>-0.009713</td>\n",
       "      <td>0.267886</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GGTAATTAATCATT</td>\n",
       "      <td>0.790300</td>\n",
       "      <td>-0.112492</td>\n",
       "      <td>0.118705</td>\n",
       "      <td>-0.237596</td>\n",
       "      <td>-0.009713</td>\n",
       "      <td>0.267886</td>\n",
       "      <td>2.591673</td>\n",
       "      <td>-3.422281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986852</td>\n",
       "      <td>9.851130</td>\n",
       "      <td>-1.990198</td>\n",
       "      <td>-0.593697</td>\n",
       "      <td>-1.092779</td>\n",
       "      <td>0.309117</td>\n",
       "      <td>-0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AATGATTAATTACT</td>\n",
       "      <td>0.593690</td>\n",
       "      <td>-1.092780</td>\n",
       "      <td>0.309116</td>\n",
       "      <td>0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>1.177587</td>\n",
       "      <td>-2.166890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.839165</td>\n",
       "      <td>10.065669</td>\n",
       "      <td>-1.499679</td>\n",
       "      <td>-0.826872</td>\n",
       "      <td>-1.141872</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>-0.143809</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.095141</td>\n",
       "      <td>0.968830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AGTAATTAATCATT</td>\n",
       "      <td>0.826872</td>\n",
       "      <td>-1.141872</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>0.143809</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.095141</td>\n",
       "      <td>2.137980</td>\n",
       "      <td>-2.777053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986851</td>\n",
       "      <td>9.851129</td>\n",
       "      <td>-1.990198</td>\n",
       "      <td>-0.593690</td>\n",
       "      <td>-1.092780</td>\n",
       "      <td>0.309116</td>\n",
       "      <td>-0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>0.968830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AGGTAATTAATCAT</td>\n",
       "      <td>1.260372</td>\n",
       "      <td>-0.870861</td>\n",
       "      <td>0.397555</td>\n",
       "      <td>0.124897</td>\n",
       "      <td>0.053255</td>\n",
       "      <td>0.213696</td>\n",
       "      <td>1.977567</td>\n",
       "      <td>-2.851909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.960712</td>\n",
       "      <td>9.943948</td>\n",
       "      <td>-1.806082</td>\n",
       "      <td>0.336528</td>\n",
       "      <td>-0.596511</td>\n",
       "      <td>0.184099</td>\n",
       "      <td>-0.075285</td>\n",
       "      <td>0.032807</td>\n",
       "      <td>0.149085</td>\n",
       "      <td>0.968752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170576</th>\n",
       "      <td>170576</td>\n",
       "      <td>AAATAAATCAAAAA</td>\n",
       "      <td>0.876056</td>\n",
       "      <td>-1.165222</td>\n",
       "      <td>0.321638</td>\n",
       "      <td>0.106295</td>\n",
       "      <td>0.028863</td>\n",
       "      <td>-0.202603</td>\n",
       "      <td>1.139074</td>\n",
       "      <td>-1.939220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779331</td>\n",
       "      <td>9.794168</td>\n",
       "      <td>-1.737971</td>\n",
       "      <td>0.085539</td>\n",
       "      <td>-0.955026</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>0.256477</td>\n",
       "      <td>0.048950</td>\n",
       "      <td>0.080873</td>\n",
       "      <td>0.076591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170577</th>\n",
       "      <td>170577</td>\n",
       "      <td>TAATTGTTTTTTTT</td>\n",
       "      <td>0.585035</td>\n",
       "      <td>-0.150802</td>\n",
       "      <td>0.171198</td>\n",
       "      <td>-0.256918</td>\n",
       "      <td>0.058377</td>\n",
       "      <td>0.181906</td>\n",
       "      <td>1.209817</td>\n",
       "      <td>-3.391274</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.162514</td>\n",
       "      <td>9.929123</td>\n",
       "      <td>-1.934750</td>\n",
       "      <td>-1.023253</td>\n",
       "      <td>-0.926061</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>-0.098051</td>\n",
       "      <td>0.026279</td>\n",
       "      <td>-0.269782</td>\n",
       "      <td>0.073354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170578</th>\n",
       "      <td>170578</td>\n",
       "      <td>AAAAAAAACAATTA</td>\n",
       "      <td>1.023253</td>\n",
       "      <td>-0.926061</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>0.098051</td>\n",
       "      <td>0.026279</td>\n",
       "      <td>-0.269782</td>\n",
       "      <td>1.151259</td>\n",
       "      <td>-1.899359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.832287</td>\n",
       "      <td>9.702945</td>\n",
       "      <td>-1.787255</td>\n",
       "      <td>-0.585035</td>\n",
       "      <td>-0.150802</td>\n",
       "      <td>0.171198</td>\n",
       "      <td>0.256918</td>\n",
       "      <td>0.058377</td>\n",
       "      <td>0.181906</td>\n",
       "      <td>0.073354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170579</th>\n",
       "      <td>170579</td>\n",
       "      <td>TTATTTTTTTAATT</td>\n",
       "      <td>-0.413908</td>\n",
       "      <td>-0.828290</td>\n",
       "      <td>0.190382</td>\n",
       "      <td>-0.246474</td>\n",
       "      <td>0.039222</td>\n",
       "      <td>0.122640</td>\n",
       "      <td>0.331353</td>\n",
       "      <td>-3.875098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.978912</td>\n",
       "      <td>9.863057</td>\n",
       "      <td>-1.994680</td>\n",
       "      <td>-0.735610</td>\n",
       "      <td>-1.194044</td>\n",
       "      <td>0.298711</td>\n",
       "      <td>-0.138674</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>-0.129401</td>\n",
       "      <td>0.073150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170580</th>\n",
       "      <td>170580</td>\n",
       "      <td>AATTAAAAAAATAA</td>\n",
       "      <td>0.735610</td>\n",
       "      <td>-1.194044</td>\n",
       "      <td>0.298711</td>\n",
       "      <td>0.138674</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>-0.129401</td>\n",
       "      <td>1.245580</td>\n",
       "      <td>-2.277798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362874</td>\n",
       "      <td>9.328955</td>\n",
       "      <td>-1.623023</td>\n",
       "      <td>0.413908</td>\n",
       "      <td>-0.828290</td>\n",
       "      <td>0.190382</td>\n",
       "      <td>0.246474</td>\n",
       "      <td>0.039222</td>\n",
       "      <td>0.122640</td>\n",
       "      <td>0.073150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170581 rows × 321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0            Kmer       y_1       y_2       y_3       y_4  \\\n",
       "0                0  AATGATTAATTACC  0.593697 -1.092779  0.309117  0.133525   \n",
       "1                1  GGTAATTAATCATT  0.790300 -0.112492  0.118705 -0.237596   \n",
       "2                2  AATGATTAATTACT  0.593690 -1.092780  0.309116  0.133525   \n",
       "3                3  AGTAATTAATCATT  0.826872 -1.141872  0.500342  0.143809   \n",
       "4                4  AGGTAATTAATCAT  1.260372 -0.870861  0.397555  0.124897   \n",
       "...            ...             ...       ...       ...       ...       ...   \n",
       "170576      170576  AAATAAATCAAAAA  0.876056 -1.165222  0.321638  0.106295   \n",
       "170577      170577  TAATTGTTTTTTTT  0.585035 -0.150802  0.171198 -0.256918   \n",
       "170578      170578  AAAAAAAACAATTA  1.023253 -0.926061  0.372899  0.098051   \n",
       "170579      170579  TTATTTTTTTAATT -0.413908 -0.828290  0.190382 -0.246474   \n",
       "170580      170580  AATTAAAAAAATAA  0.735610 -1.194044  0.298711  0.138674   \n",
       "\n",
       "             y_5       y_6      zC_1      zC_2  ...     zW_76      zW_77  \\\n",
       "0       0.023403 -0.157348  1.177586 -2.166888  ... -0.674709  10.019444   \n",
       "1      -0.009713  0.267886  2.591673 -3.422281  ... -0.986852   9.851130   \n",
       "2       0.023403 -0.157348  1.177587 -2.166890  ... -0.839165  10.065669   \n",
       "3       0.043456  0.095141  2.137980 -2.777053  ... -0.986851   9.851129   \n",
       "4       0.053255  0.213696  1.977567 -2.851909  ... -0.960712   9.943948   \n",
       "...          ...       ...       ...       ...  ...       ...        ...   \n",
       "170576  0.028863 -0.202603  1.139074 -1.939220  ... -0.779331   9.794168   \n",
       "170577  0.058377  0.181906  1.209817 -3.391274  ... -1.162514   9.929123   \n",
       "170578  0.026279 -0.269782  1.151259 -1.899359  ... -0.832287   9.702945   \n",
       "170579  0.039222  0.122640  0.331353 -3.875098  ... -0.978912   9.863057   \n",
       "170580  0.028309 -0.129401  1.245580 -2.277798  ... -0.362874   9.328955   \n",
       "\n",
       "           zW_78      y_79      y_80      y_81      y_82      y_83      y_84  \\\n",
       "0      -1.012806 -0.790300 -0.112492  0.118705  0.237596 -0.009713  0.267886   \n",
       "1      -1.990198 -0.593697 -1.092779  0.309117 -0.133525  0.023403 -0.157348   \n",
       "2      -1.499679 -0.826872 -1.141872  0.500342 -0.143809  0.043456  0.095141   \n",
       "3      -1.990198 -0.593690 -1.092780  0.309116 -0.133525  0.023403 -0.157348   \n",
       "4      -1.806082  0.336528 -0.596511  0.184099 -0.075285  0.032807  0.149085   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "170576 -1.737971  0.085539 -0.955026  0.025427  0.256477  0.048950  0.080873   \n",
       "170577 -1.934750 -1.023253 -0.926061  0.372899 -0.098051  0.026279 -0.269782   \n",
       "170578 -1.787255 -0.585035 -0.150802  0.171198  0.256918  0.058377  0.181906   \n",
       "170579 -1.994680 -0.735610 -1.194044  0.298711 -0.138674  0.028309 -0.129401   \n",
       "170580 -1.623023  0.413908 -0.828290  0.190382  0.246474  0.039222  0.122640   \n",
       "\n",
       "           relKa  \n",
       "0       1.000000  \n",
       "1       1.000000  \n",
       "2       0.968830  \n",
       "3       0.968830  \n",
       "4       0.968752  \n",
       "...          ...  \n",
       "170576  0.076591  \n",
       "170577  0.073354  \n",
       "170578  0.073354  \n",
       "170579  0.073150  \n",
       "170580  0.073150  \n",
       "\n",
       "[170581 rows x 321 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca83864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d448f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kmer</th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>zC_1</th>\n",
       "      <th>zC_2</th>\n",
       "      <th>zC_3</th>\n",
       "      <th>...</th>\n",
       "      <th>zW_76</th>\n",
       "      <th>zW_77</th>\n",
       "      <th>zW_78</th>\n",
       "      <th>y_79</th>\n",
       "      <th>y_80</th>\n",
       "      <th>y_81</th>\n",
       "      <th>y_82</th>\n",
       "      <th>y_83</th>\n",
       "      <th>y_84</th>\n",
       "      <th>relKa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AATGATTAATTACC</td>\n",
       "      <td>0.593697</td>\n",
       "      <td>-1.092779</td>\n",
       "      <td>0.309117</td>\n",
       "      <td>0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>1.177586</td>\n",
       "      <td>-2.166888</td>\n",
       "      <td>-1.059702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674709</td>\n",
       "      <td>10.019444</td>\n",
       "      <td>-1.012806</td>\n",
       "      <td>-0.790300</td>\n",
       "      <td>-0.112492</td>\n",
       "      <td>0.118705</td>\n",
       "      <td>0.237596</td>\n",
       "      <td>-0.009713</td>\n",
       "      <td>0.267886</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGTAATTAATCATT</td>\n",
       "      <td>0.790300</td>\n",
       "      <td>-0.112492</td>\n",
       "      <td>0.118705</td>\n",
       "      <td>-0.237596</td>\n",
       "      <td>-0.009713</td>\n",
       "      <td>0.267886</td>\n",
       "      <td>2.591673</td>\n",
       "      <td>-3.422281</td>\n",
       "      <td>-1.331358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986852</td>\n",
       "      <td>9.851130</td>\n",
       "      <td>-1.990198</td>\n",
       "      <td>-0.593697</td>\n",
       "      <td>-1.092779</td>\n",
       "      <td>0.309117</td>\n",
       "      <td>-0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AATGATTAATTACT</td>\n",
       "      <td>0.593690</td>\n",
       "      <td>-1.092780</td>\n",
       "      <td>0.309116</td>\n",
       "      <td>0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>1.177587</td>\n",
       "      <td>-2.166890</td>\n",
       "      <td>-1.059703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.839165</td>\n",
       "      <td>10.065669</td>\n",
       "      <td>-1.499679</td>\n",
       "      <td>-0.826872</td>\n",
       "      <td>-1.141872</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>-0.143809</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.095141</td>\n",
       "      <td>0.968830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGTAATTAATCATT</td>\n",
       "      <td>0.826872</td>\n",
       "      <td>-1.141872</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>0.143809</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.095141</td>\n",
       "      <td>2.137980</td>\n",
       "      <td>-2.777053</td>\n",
       "      <td>-1.371144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986851</td>\n",
       "      <td>9.851129</td>\n",
       "      <td>-1.990198</td>\n",
       "      <td>-0.593690</td>\n",
       "      <td>-1.092780</td>\n",
       "      <td>0.309116</td>\n",
       "      <td>-0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>0.968830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGGTAATTAATCAT</td>\n",
       "      <td>1.260372</td>\n",
       "      <td>-0.870861</td>\n",
       "      <td>0.397555</td>\n",
       "      <td>0.124897</td>\n",
       "      <td>0.053255</td>\n",
       "      <td>0.213696</td>\n",
       "      <td>1.977567</td>\n",
       "      <td>-2.851909</td>\n",
       "      <td>-1.221460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.960712</td>\n",
       "      <td>9.943948</td>\n",
       "      <td>-1.806082</td>\n",
       "      <td>0.336528</td>\n",
       "      <td>-0.596511</td>\n",
       "      <td>0.184099</td>\n",
       "      <td>-0.075285</td>\n",
       "      <td>0.032807</td>\n",
       "      <td>0.149085</td>\n",
       "      <td>0.968752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170576</th>\n",
       "      <td>AAATAAATCAAAAA</td>\n",
       "      <td>0.876056</td>\n",
       "      <td>-1.165222</td>\n",
       "      <td>0.321638</td>\n",
       "      <td>0.106295</td>\n",
       "      <td>0.028863</td>\n",
       "      <td>-0.202603</td>\n",
       "      <td>1.139074</td>\n",
       "      <td>-1.939220</td>\n",
       "      <td>-0.782830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779331</td>\n",
       "      <td>9.794168</td>\n",
       "      <td>-1.737971</td>\n",
       "      <td>0.085539</td>\n",
       "      <td>-0.955026</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>0.256477</td>\n",
       "      <td>0.048950</td>\n",
       "      <td>0.080873</td>\n",
       "      <td>0.076591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170577</th>\n",
       "      <td>TAATTGTTTTTTTT</td>\n",
       "      <td>0.585035</td>\n",
       "      <td>-0.150802</td>\n",
       "      <td>0.171198</td>\n",
       "      <td>-0.256918</td>\n",
       "      <td>0.058377</td>\n",
       "      <td>0.181906</td>\n",
       "      <td>1.209817</td>\n",
       "      <td>-3.391274</td>\n",
       "      <td>-1.164594</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.162514</td>\n",
       "      <td>9.929123</td>\n",
       "      <td>-1.934750</td>\n",
       "      <td>-1.023253</td>\n",
       "      <td>-0.926061</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>-0.098051</td>\n",
       "      <td>0.026279</td>\n",
       "      <td>-0.269782</td>\n",
       "      <td>0.073354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170578</th>\n",
       "      <td>AAAAAAAACAATTA</td>\n",
       "      <td>1.023253</td>\n",
       "      <td>-0.926061</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>0.098051</td>\n",
       "      <td>0.026279</td>\n",
       "      <td>-0.269782</td>\n",
       "      <td>1.151259</td>\n",
       "      <td>-1.899359</td>\n",
       "      <td>-0.775374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.832287</td>\n",
       "      <td>9.702945</td>\n",
       "      <td>-1.787255</td>\n",
       "      <td>-0.585035</td>\n",
       "      <td>-0.150802</td>\n",
       "      <td>0.171198</td>\n",
       "      <td>0.256918</td>\n",
       "      <td>0.058377</td>\n",
       "      <td>0.181906</td>\n",
       "      <td>0.073354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170579</th>\n",
       "      <td>TTATTTTTTTAATT</td>\n",
       "      <td>-0.413908</td>\n",
       "      <td>-0.828290</td>\n",
       "      <td>0.190382</td>\n",
       "      <td>-0.246474</td>\n",
       "      <td>0.039222</td>\n",
       "      <td>0.122640</td>\n",
       "      <td>0.331353</td>\n",
       "      <td>-3.875098</td>\n",
       "      <td>-2.096984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.978912</td>\n",
       "      <td>9.863057</td>\n",
       "      <td>-1.994680</td>\n",
       "      <td>-0.735610</td>\n",
       "      <td>-1.194044</td>\n",
       "      <td>0.298711</td>\n",
       "      <td>-0.138674</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>-0.129401</td>\n",
       "      <td>0.073150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170580</th>\n",
       "      <td>AATTAAAAAAATAA</td>\n",
       "      <td>0.735610</td>\n",
       "      <td>-1.194044</td>\n",
       "      <td>0.298711</td>\n",
       "      <td>0.138674</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>-0.129401</td>\n",
       "      <td>1.245580</td>\n",
       "      <td>-2.277798</td>\n",
       "      <td>-1.089694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362874</td>\n",
       "      <td>9.328955</td>\n",
       "      <td>-1.623023</td>\n",
       "      <td>0.413908</td>\n",
       "      <td>-0.828290</td>\n",
       "      <td>0.190382</td>\n",
       "      <td>0.246474</td>\n",
       "      <td>0.039222</td>\n",
       "      <td>0.122640</td>\n",
       "      <td>0.073150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170581 rows × 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Kmer       y_1       y_2       y_3       y_4       y_5  \\\n",
       "0       AATGATTAATTACC  0.593697 -1.092779  0.309117  0.133525  0.023403   \n",
       "1       GGTAATTAATCATT  0.790300 -0.112492  0.118705 -0.237596 -0.009713   \n",
       "2       AATGATTAATTACT  0.593690 -1.092780  0.309116  0.133525  0.023403   \n",
       "3       AGTAATTAATCATT  0.826872 -1.141872  0.500342  0.143809  0.043456   \n",
       "4       AGGTAATTAATCAT  1.260372 -0.870861  0.397555  0.124897  0.053255   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "170576  AAATAAATCAAAAA  0.876056 -1.165222  0.321638  0.106295  0.028863   \n",
       "170577  TAATTGTTTTTTTT  0.585035 -0.150802  0.171198 -0.256918  0.058377   \n",
       "170578  AAAAAAAACAATTA  1.023253 -0.926061  0.372899  0.098051  0.026279   \n",
       "170579  TTATTTTTTTAATT -0.413908 -0.828290  0.190382 -0.246474  0.039222   \n",
       "170580  AATTAAAAAAATAA  0.735610 -1.194044  0.298711  0.138674  0.028309   \n",
       "\n",
       "             y_6      zC_1      zC_2      zC_3  ...     zW_76      zW_77  \\\n",
       "0      -0.157348  1.177586 -2.166888 -1.059702  ... -0.674709  10.019444   \n",
       "1       0.267886  2.591673 -3.422281 -1.331358  ... -0.986852   9.851130   \n",
       "2      -0.157348  1.177587 -2.166890 -1.059703  ... -0.839165  10.065669   \n",
       "3       0.095141  2.137980 -2.777053 -1.371144  ... -0.986851   9.851129   \n",
       "4       0.213696  1.977567 -2.851909 -1.221460  ... -0.960712   9.943948   \n",
       "...          ...       ...       ...       ...  ...       ...        ...   \n",
       "170576 -0.202603  1.139074 -1.939220 -0.782830  ... -0.779331   9.794168   \n",
       "170577  0.181906  1.209817 -3.391274 -1.164594  ... -1.162514   9.929123   \n",
       "170578 -0.269782  1.151259 -1.899359 -0.775374  ... -0.832287   9.702945   \n",
       "170579  0.122640  0.331353 -3.875098 -2.096984  ... -0.978912   9.863057   \n",
       "170580 -0.129401  1.245580 -2.277798 -1.089694  ... -0.362874   9.328955   \n",
       "\n",
       "           zW_78      y_79      y_80      y_81      y_82      y_83      y_84  \\\n",
       "0      -1.012806 -0.790300 -0.112492  0.118705  0.237596 -0.009713  0.267886   \n",
       "1      -1.990198 -0.593697 -1.092779  0.309117 -0.133525  0.023403 -0.157348   \n",
       "2      -1.499679 -0.826872 -1.141872  0.500342 -0.143809  0.043456  0.095141   \n",
       "3      -1.990198 -0.593690 -1.092780  0.309116 -0.133525  0.023403 -0.157348   \n",
       "4      -1.806082  0.336528 -0.596511  0.184099 -0.075285  0.032807  0.149085   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "170576 -1.737971  0.085539 -0.955026  0.025427  0.256477  0.048950  0.080873   \n",
       "170577 -1.934750 -1.023253 -0.926061  0.372899 -0.098051  0.026279 -0.269782   \n",
       "170578 -1.787255 -0.585035 -0.150802  0.171198  0.256918  0.058377  0.181906   \n",
       "170579 -1.994680 -0.735610 -1.194044  0.298711 -0.138674  0.028309 -0.129401   \n",
       "170580 -1.623023  0.413908 -0.828290  0.190382  0.246474  0.039222  0.122640   \n",
       "\n",
       "           relKa  \n",
       "0       1.000000  \n",
       "1       1.000000  \n",
       "2       0.968830  \n",
       "3       0.968830  \n",
       "4       0.968752  \n",
       "...          ...  \n",
       "170576  0.076591  \n",
       "170577  0.073354  \n",
       "170578  0.073354  \n",
       "170579  0.073150  \n",
       "170580  0.073150  \n",
       "\n",
       "[170581 rows x 320 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99834e5",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b5747",
   "metadata": {},
   "source": [
    "#### Splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d52da9d",
   "metadata": {},
   "source": [
    "First of all we split the data and we drop Kmer, this is a string so we cannot use it for machine learning purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb21235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Kmer', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e470ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>zC_1</th>\n",
       "      <th>zC_2</th>\n",
       "      <th>zC_3</th>\n",
       "      <th>zC_4</th>\n",
       "      <th>...</th>\n",
       "      <th>zW_76</th>\n",
       "      <th>zW_77</th>\n",
       "      <th>zW_78</th>\n",
       "      <th>y_79</th>\n",
       "      <th>y_80</th>\n",
       "      <th>y_81</th>\n",
       "      <th>y_82</th>\n",
       "      <th>y_83</th>\n",
       "      <th>y_84</th>\n",
       "      <th>relKa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.593697</td>\n",
       "      <td>-1.092779</td>\n",
       "      <td>0.309117</td>\n",
       "      <td>0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>1.177586</td>\n",
       "      <td>-2.166888</td>\n",
       "      <td>-1.059702</td>\n",
       "      <td>-0.986852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674709</td>\n",
       "      <td>10.019444</td>\n",
       "      <td>-1.012806</td>\n",
       "      <td>-0.790300</td>\n",
       "      <td>-0.112492</td>\n",
       "      <td>0.118705</td>\n",
       "      <td>0.237596</td>\n",
       "      <td>-0.009713</td>\n",
       "      <td>0.267886</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.790300</td>\n",
       "      <td>-0.112492</td>\n",
       "      <td>0.118705</td>\n",
       "      <td>-0.237596</td>\n",
       "      <td>-0.009713</td>\n",
       "      <td>0.267886</td>\n",
       "      <td>2.591673</td>\n",
       "      <td>-3.422281</td>\n",
       "      <td>-1.331358</td>\n",
       "      <td>-0.674709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986852</td>\n",
       "      <td>9.851130</td>\n",
       "      <td>-1.990198</td>\n",
       "      <td>-0.593697</td>\n",
       "      <td>-1.092779</td>\n",
       "      <td>0.309117</td>\n",
       "      <td>-0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.593690</td>\n",
       "      <td>-1.092780</td>\n",
       "      <td>0.309116</td>\n",
       "      <td>0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>1.177587</td>\n",
       "      <td>-2.166890</td>\n",
       "      <td>-1.059703</td>\n",
       "      <td>-0.986851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.839165</td>\n",
       "      <td>10.065669</td>\n",
       "      <td>-1.499679</td>\n",
       "      <td>-0.826872</td>\n",
       "      <td>-1.141872</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>-0.143809</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.095141</td>\n",
       "      <td>0.968830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.826872</td>\n",
       "      <td>-1.141872</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>0.143809</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.095141</td>\n",
       "      <td>2.137980</td>\n",
       "      <td>-2.777053</td>\n",
       "      <td>-1.371144</td>\n",
       "      <td>-0.839165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.986851</td>\n",
       "      <td>9.851129</td>\n",
       "      <td>-1.990198</td>\n",
       "      <td>-0.593690</td>\n",
       "      <td>-1.092780</td>\n",
       "      <td>0.309116</td>\n",
       "      <td>-0.133525</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>-0.157348</td>\n",
       "      <td>0.968830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.260372</td>\n",
       "      <td>-0.870861</td>\n",
       "      <td>0.397555</td>\n",
       "      <td>0.124897</td>\n",
       "      <td>0.053255</td>\n",
       "      <td>0.213696</td>\n",
       "      <td>1.977567</td>\n",
       "      <td>-2.851909</td>\n",
       "      <td>-1.221460</td>\n",
       "      <td>-0.880962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.960712</td>\n",
       "      <td>9.943948</td>\n",
       "      <td>-1.806082</td>\n",
       "      <td>0.336528</td>\n",
       "      <td>-0.596511</td>\n",
       "      <td>0.184099</td>\n",
       "      <td>-0.075285</td>\n",
       "      <td>0.032807</td>\n",
       "      <td>0.149085</td>\n",
       "      <td>0.968752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170576</th>\n",
       "      <td>0.876056</td>\n",
       "      <td>-1.165222</td>\n",
       "      <td>0.321638</td>\n",
       "      <td>0.106295</td>\n",
       "      <td>0.028863</td>\n",
       "      <td>-0.202603</td>\n",
       "      <td>1.139074</td>\n",
       "      <td>-1.939220</td>\n",
       "      <td>-0.782830</td>\n",
       "      <td>-1.156945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.779331</td>\n",
       "      <td>9.794168</td>\n",
       "      <td>-1.737971</td>\n",
       "      <td>0.085539</td>\n",
       "      <td>-0.955026</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>0.256477</td>\n",
       "      <td>0.048950</td>\n",
       "      <td>0.080873</td>\n",
       "      <td>0.076591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170577</th>\n",
       "      <td>0.585035</td>\n",
       "      <td>-0.150802</td>\n",
       "      <td>0.171198</td>\n",
       "      <td>-0.256918</td>\n",
       "      <td>0.058377</td>\n",
       "      <td>0.181906</td>\n",
       "      <td>1.209817</td>\n",
       "      <td>-3.391274</td>\n",
       "      <td>-1.164594</td>\n",
       "      <td>-0.832287</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.162514</td>\n",
       "      <td>9.929123</td>\n",
       "      <td>-1.934750</td>\n",
       "      <td>-1.023253</td>\n",
       "      <td>-0.926061</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>-0.098051</td>\n",
       "      <td>0.026279</td>\n",
       "      <td>-0.269782</td>\n",
       "      <td>0.073354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170578</th>\n",
       "      <td>1.023253</td>\n",
       "      <td>-0.926061</td>\n",
       "      <td>0.372899</td>\n",
       "      <td>0.098051</td>\n",
       "      <td>0.026279</td>\n",
       "      <td>-0.269782</td>\n",
       "      <td>1.151259</td>\n",
       "      <td>-1.899359</td>\n",
       "      <td>-0.775374</td>\n",
       "      <td>-1.162514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.832287</td>\n",
       "      <td>9.702945</td>\n",
       "      <td>-1.787255</td>\n",
       "      <td>-0.585035</td>\n",
       "      <td>-0.150802</td>\n",
       "      <td>0.171198</td>\n",
       "      <td>0.256918</td>\n",
       "      <td>0.058377</td>\n",
       "      <td>0.181906</td>\n",
       "      <td>0.073354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170579</th>\n",
       "      <td>-0.413908</td>\n",
       "      <td>-0.828290</td>\n",
       "      <td>0.190382</td>\n",
       "      <td>-0.246474</td>\n",
       "      <td>0.039222</td>\n",
       "      <td>0.122640</td>\n",
       "      <td>0.331353</td>\n",
       "      <td>-3.875098</td>\n",
       "      <td>-2.096984</td>\n",
       "      <td>-0.362874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.978912</td>\n",
       "      <td>9.863057</td>\n",
       "      <td>-1.994680</td>\n",
       "      <td>-0.735610</td>\n",
       "      <td>-1.194044</td>\n",
       "      <td>0.298711</td>\n",
       "      <td>-0.138674</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>-0.129401</td>\n",
       "      <td>0.073150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170580</th>\n",
       "      <td>0.735610</td>\n",
       "      <td>-1.194044</td>\n",
       "      <td>0.298711</td>\n",
       "      <td>0.138674</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>-0.129401</td>\n",
       "      <td>1.245580</td>\n",
       "      <td>-2.277798</td>\n",
       "      <td>-1.089694</td>\n",
       "      <td>-0.978912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362874</td>\n",
       "      <td>9.328955</td>\n",
       "      <td>-1.623023</td>\n",
       "      <td>0.413908</td>\n",
       "      <td>-0.828290</td>\n",
       "      <td>0.190382</td>\n",
       "      <td>0.246474</td>\n",
       "      <td>0.039222</td>\n",
       "      <td>0.122640</td>\n",
       "      <td>0.073150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170581 rows × 319 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y_1       y_2       y_3       y_4       y_5       y_6      zC_1  \\\n",
       "0       0.593697 -1.092779  0.309117  0.133525  0.023403 -0.157348  1.177586   \n",
       "1       0.790300 -0.112492  0.118705 -0.237596 -0.009713  0.267886  2.591673   \n",
       "2       0.593690 -1.092780  0.309116  0.133525  0.023403 -0.157348  1.177587   \n",
       "3       0.826872 -1.141872  0.500342  0.143809  0.043456  0.095141  2.137980   \n",
       "4       1.260372 -0.870861  0.397555  0.124897  0.053255  0.213696  1.977567   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "170576  0.876056 -1.165222  0.321638  0.106295  0.028863 -0.202603  1.139074   \n",
       "170577  0.585035 -0.150802  0.171198 -0.256918  0.058377  0.181906  1.209817   \n",
       "170578  1.023253 -0.926061  0.372899  0.098051  0.026279 -0.269782  1.151259   \n",
       "170579 -0.413908 -0.828290  0.190382 -0.246474  0.039222  0.122640  0.331353   \n",
       "170580  0.735610 -1.194044  0.298711  0.138674  0.028309 -0.129401  1.245580   \n",
       "\n",
       "            zC_2      zC_3      zC_4  ...     zW_76      zW_77     zW_78  \\\n",
       "0      -2.166888 -1.059702 -0.986852  ... -0.674709  10.019444 -1.012806   \n",
       "1      -3.422281 -1.331358 -0.674709  ... -0.986852   9.851130 -1.990198   \n",
       "2      -2.166890 -1.059703 -0.986851  ... -0.839165  10.065669 -1.499679   \n",
       "3      -2.777053 -1.371144 -0.839165  ... -0.986851   9.851129 -1.990198   \n",
       "4      -2.851909 -1.221460 -0.880962  ... -0.960712   9.943948 -1.806082   \n",
       "...          ...       ...       ...  ...       ...        ...       ...   \n",
       "170576 -1.939220 -0.782830 -1.156945  ... -0.779331   9.794168 -1.737971   \n",
       "170577 -3.391274 -1.164594 -0.832287  ... -1.162514   9.929123 -1.934750   \n",
       "170578 -1.899359 -0.775374 -1.162514  ... -0.832287   9.702945 -1.787255   \n",
       "170579 -3.875098 -2.096984 -0.362874  ... -0.978912   9.863057 -1.994680   \n",
       "170580 -2.277798 -1.089694 -0.978912  ... -0.362874   9.328955 -1.623023   \n",
       "\n",
       "            y_79      y_80      y_81      y_82      y_83      y_84     relKa  \n",
       "0      -0.790300 -0.112492  0.118705  0.237596 -0.009713  0.267886  1.000000  \n",
       "1      -0.593697 -1.092779  0.309117 -0.133525  0.023403 -0.157348  1.000000  \n",
       "2      -0.826872 -1.141872  0.500342 -0.143809  0.043456  0.095141  0.968830  \n",
       "3      -0.593690 -1.092780  0.309116 -0.133525  0.023403 -0.157348  0.968830  \n",
       "4       0.336528 -0.596511  0.184099 -0.075285  0.032807  0.149085  0.968752  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "170576  0.085539 -0.955026  0.025427  0.256477  0.048950  0.080873  0.076591  \n",
       "170577 -1.023253 -0.926061  0.372899 -0.098051  0.026279 -0.269782  0.073354  \n",
       "170578 -0.585035 -0.150802  0.171198  0.256918  0.058377  0.181906  0.073354  \n",
       "170579 -0.735610 -1.194044  0.298711 -0.138674  0.028309 -0.129401  0.073150  \n",
       "170580  0.413908 -0.828290  0.190382  0.246474  0.039222  0.122640  0.073150  \n",
       "\n",
       "[170581 rows x 319 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7003305b",
   "metadata": {},
   "source": [
    "Now we divide into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f59104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['relKa'].to_numpy()\n",
    "x = df.loc[:, df.columns != 'relKa'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70941739",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91fae9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform (x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d46be8",
   "metadata": {},
   "source": [
    "#### Naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f13cfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3539e782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the MSE for non tuned model XGB Regressor is 0.0013181866451271926\n"
     ]
    }
   ],
   "source": [
    "print('the MSE for non tuned model XGB Regressor is', MSE(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd1e5d",
   "metadata": {},
   "source": [
    "The model fits the data pretty well, the MSE seems quite small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09bf048",
   "metadata": {},
   "source": [
    "#### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7935b",
   "metadata": {},
   "source": [
    "Now we will tune the hyperparameters to improve the model performances, we will consider the regressor that we obtain after hyperparameter tuning the baseline regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2378252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5; 1/15] START colsample_bylevel=0.4, colsample_bytree=0.5, lambda=2.4999999999999996, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 1/15] END colsample_bylevel=0.4, colsample_bytree=0.5, lambda=2.4999999999999996, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV 2/5; 1/15] START colsample_bylevel=0.4, colsample_bytree=0.5, lambda=2.4999999999999996, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 1/15] END colsample_bylevel=0.4, colsample_bytree=0.5, lambda=2.4999999999999996, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=  11.7s\n",
      "[CV 3/5; 1/15] START colsample_bylevel=0.4, colsample_bytree=0.5, lambda=2.4999999999999996, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 1/15] END colsample_bylevel=0.4, colsample_bytree=0.5, lambda=2.4999999999999996, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV 4/5; 1/15] START colsample_bylevel=0.4, colsample_bytree=0.5, lambda=2.4999999999999996, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 1/15] END colsample_bylevel=0.4, colsample_bytree=0.5, lambda=2.4999999999999996, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=  11.9s\n",
      "[CV 5/5; 1/15] START colsample_bylevel=0.4, colsample_bytree=0.5, lambda=2.4999999999999996, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 1/15] END colsample_bylevel=0.4, colsample_bytree=0.5, lambda=2.4999999999999996, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.5; total time=  11.8s\n",
      "[CV 1/5; 2/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=2.4999999999999996, learning_rate=0.3, max_depth=20, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 2/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=2.4999999999999996, learning_rate=0.3, max_depth=20, n_estimators=100, subsample=0.5; total time= 3.2min\n",
      "[CV 2/5; 2/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=2.4999999999999996, learning_rate=0.3, max_depth=20, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 2/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=2.4999999999999996, learning_rate=0.3, max_depth=20, n_estimators=100, subsample=0.5; total time= 3.3min\n",
      "[CV 3/5; 2/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=2.4999999999999996, learning_rate=0.3, max_depth=20, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 2/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=2.4999999999999996, learning_rate=0.3, max_depth=20, n_estimators=100, subsample=0.5; total time= 3.2min\n",
      "[CV 4/5; 2/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=2.4999999999999996, learning_rate=0.3, max_depth=20, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 2/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=2.4999999999999996, learning_rate=0.3, max_depth=20, n_estimators=100, subsample=0.5; total time= 3.3min\n",
      "[CV 5/5; 2/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=2.4999999999999996, learning_rate=0.3, max_depth=20, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 2/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=2.4999999999999996, learning_rate=0.3, max_depth=20, n_estimators=100, subsample=0.5; total time= 3.3min\n",
      "[CV 1/5; 3/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=3.0999999999999996, learning_rate=0.3, max_depth=15, n_estimators=500, subsample=0.7\n",
      "[CV 1/5; 3/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=3.0999999999999996, learning_rate=0.3, max_depth=15, n_estimators=500, subsample=0.7; total time=13.5min\n",
      "[CV 2/5; 3/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=3.0999999999999996, learning_rate=0.3, max_depth=15, n_estimators=500, subsample=0.7\n",
      "[CV 2/5; 3/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=3.0999999999999996, learning_rate=0.3, max_depth=15, n_estimators=500, subsample=0.7; total time=13.6min\n",
      "[CV 3/5; 3/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=3.0999999999999996, learning_rate=0.3, max_depth=15, n_estimators=500, subsample=0.7\n",
      "[CV 3/5; 3/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=3.0999999999999996, learning_rate=0.3, max_depth=15, n_estimators=500, subsample=0.7; total time=13.7min\n",
      "[CV 4/5; 3/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=3.0999999999999996, learning_rate=0.3, max_depth=15, n_estimators=500, subsample=0.7\n",
      "[CV 4/5; 3/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=3.0999999999999996, learning_rate=0.3, max_depth=15, n_estimators=500, subsample=0.7; total time=13.7min\n",
      "[CV 5/5; 3/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=3.0999999999999996, learning_rate=0.3, max_depth=15, n_estimators=500, subsample=0.7\n",
      "[CV 5/5; 3/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7999999999999999, lambda=3.0999999999999996, learning_rate=0.3, max_depth=15, n_estimators=500, subsample=0.7; total time=13.5min\n",
      "[CV 1/5; 4/15] START colsample_bylevel=0.5, colsample_bytree=0.7, lambda=3.8999999999999995, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.7\n",
      "[CV 1/5; 4/15] END colsample_bylevel=0.5, colsample_bytree=0.7, lambda=3.8999999999999995, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.7; total time=16.5min\n",
      "[CV 2/5; 4/15] START colsample_bylevel=0.5, colsample_bytree=0.7, lambda=3.8999999999999995, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.7\n",
      "[CV 2/5; 4/15] END colsample_bylevel=0.5, colsample_bytree=0.7, lambda=3.8999999999999995, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.7; total time=16.5min\n",
      "[CV 3/5; 4/15] START colsample_bylevel=0.5, colsample_bytree=0.7, lambda=3.8999999999999995, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.7\n",
      "[CV 3/5; 4/15] END colsample_bylevel=0.5, colsample_bytree=0.7, lambda=3.8999999999999995, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.7; total time=16.4min\n",
      "[CV 4/5; 4/15] START colsample_bylevel=0.5, colsample_bytree=0.7, lambda=3.8999999999999995, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.7\n",
      "[CV 4/5; 4/15] END colsample_bylevel=0.5, colsample_bytree=0.7, lambda=3.8999999999999995, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.7; total time=16.6min\n",
      "[CV 5/5; 4/15] START colsample_bylevel=0.5, colsample_bytree=0.7, lambda=3.8999999999999995, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.7\n",
      "[CV 5/5; 4/15] END colsample_bylevel=0.5, colsample_bytree=0.7, lambda=3.8999999999999995, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.7; total time=16.6min\n",
      "[CV 1/5; 5/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=2.6999999999999993, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 1/5; 5/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=2.6999999999999993, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999; total time= 8.5min\n",
      "[CV 2/5; 5/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=2.6999999999999993, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 2/5; 5/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=2.6999999999999993, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999; total time= 8.8min\n",
      "[CV 3/5; 5/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=2.6999999999999993, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=2.6999999999999993, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999; total time= 8.5min\n",
      "[CV 4/5; 5/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=2.6999999999999993, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 4/5; 5/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=2.6999999999999993, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999; total time= 8.6min\n",
      "[CV 5/5; 5/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=2.6999999999999993, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 5/5; 5/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=2.6999999999999993, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999; total time= 8.5min\n",
      "[CV 1/5; 6/15] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, lambda=4.299999999999999, learning_rate=0.2, max_depth=20, n_estimators=100, subsample=0.7\n",
      "[CV 1/5; 6/15] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, lambda=4.299999999999999, learning_rate=0.2, max_depth=20, n_estimators=100, subsample=0.7; total time= 2.2min\n",
      "[CV 2/5; 6/15] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, lambda=4.299999999999999, learning_rate=0.2, max_depth=20, n_estimators=100, subsample=0.7\n",
      "[CV 2/5; 6/15] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, lambda=4.299999999999999, learning_rate=0.2, max_depth=20, n_estimators=100, subsample=0.7; total time= 2.2min\n",
      "[CV 3/5; 6/15] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, lambda=4.299999999999999, learning_rate=0.2, max_depth=20, n_estimators=100, subsample=0.7\n",
      "[CV 3/5; 6/15] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, lambda=4.299999999999999, learning_rate=0.2, max_depth=20, n_estimators=100, subsample=0.7; total time= 2.1min\n",
      "[CV 4/5; 6/15] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, lambda=4.299999999999999, learning_rate=0.2, max_depth=20, n_estimators=100, subsample=0.7\n",
      "[CV 4/5; 6/15] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, lambda=4.299999999999999, learning_rate=0.2, max_depth=20, n_estimators=100, subsample=0.7; total time= 2.2min\n",
      "[CV 5/5; 6/15] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, lambda=4.299999999999999, learning_rate=0.2, max_depth=20, n_estimators=100, subsample=0.7\n",
      "[CV 5/5; 6/15] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.4, lambda=4.299999999999999, learning_rate=0.2, max_depth=20, n_estimators=100, subsample=0.7; total time= 2.2min\n",
      "[CV 1/5; 7/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=2.3, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 1/5; 7/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=2.3, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999; total time= 5.0min\n",
      "[CV 2/5; 7/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=2.3, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 2/5; 7/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=2.3, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999; total time= 5.0min\n",
      "[CV 3/5; 7/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=2.3, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 3/5; 7/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=2.3, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999; total time= 5.0min\n",
      "[CV 4/5; 7/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=2.3, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 4/5; 7/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=2.3, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999; total time= 5.0min\n",
      "[CV 5/5; 7/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=2.3, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 5/5; 7/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=2.3, learning_rate=0.3, max_depth=20, n_estimators=1000, subsample=0.7999999999999999; total time= 5.0min\n",
      "[CV 1/5; 8/15] START colsample_bylevel=0.6, colsample_bytree=0.5, lambda=2.3, learning_rate=0.3, max_depth=3, n_estimators=500, subsample=0.6\n",
      "[CV 1/5; 8/15] END colsample_bylevel=0.6, colsample_bytree=0.5, lambda=2.3, learning_rate=0.3, max_depth=3, n_estimators=500, subsample=0.6; total time= 1.3min\n",
      "[CV 2/5; 8/15] START colsample_bylevel=0.6, colsample_bytree=0.5, lambda=2.3, learning_rate=0.3, max_depth=3, n_estimators=500, subsample=0.6\n",
      "[CV 2/5; 8/15] END colsample_bylevel=0.6, colsample_bytree=0.5, lambda=2.3, learning_rate=0.3, max_depth=3, n_estimators=500, subsample=0.6; total time= 1.3min\n",
      "[CV 3/5; 8/15] START colsample_bylevel=0.6, colsample_bytree=0.5, lambda=2.3, learning_rate=0.3, max_depth=3, n_estimators=500, subsample=0.6\n",
      "[CV 3/5; 8/15] END colsample_bylevel=0.6, colsample_bytree=0.5, lambda=2.3, learning_rate=0.3, max_depth=3, n_estimators=500, subsample=0.6; total time= 1.3min\n",
      "[CV 4/5; 8/15] START colsample_bylevel=0.6, colsample_bytree=0.5, lambda=2.3, learning_rate=0.3, max_depth=3, n_estimators=500, subsample=0.6\n",
      "[CV 4/5; 8/15] END colsample_bylevel=0.6, colsample_bytree=0.5, lambda=2.3, learning_rate=0.3, max_depth=3, n_estimators=500, subsample=0.6; total time= 1.3min\n",
      "[CV 5/5; 8/15] START colsample_bylevel=0.6, colsample_bytree=0.5, lambda=2.3, learning_rate=0.3, max_depth=3, n_estimators=500, subsample=0.6\n",
      "[CV 5/5; 8/15] END colsample_bylevel=0.6, colsample_bytree=0.5, lambda=2.3, learning_rate=0.3, max_depth=3, n_estimators=500, subsample=0.6; total time= 1.3min\n",
      "[CV 1/5; 9/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=6, n_estimators=500, subsample=0.7\n",
      "[CV 1/5; 9/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=6, n_estimators=500, subsample=0.7; total time= 6.4min\n",
      "[CV 2/5; 9/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=6, n_estimators=500, subsample=0.7\n",
      "[CV 2/5; 9/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=6, n_estimators=500, subsample=0.7; total time= 6.5min\n",
      "[CV 3/5; 9/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=6, n_estimators=500, subsample=0.7\n",
      "[CV 3/5; 9/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=6, n_estimators=500, subsample=0.7; total time= 6.5min\n",
      "[CV 4/5; 9/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=6, n_estimators=500, subsample=0.7\n",
      "[CV 4/5; 9/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=6, n_estimators=500, subsample=0.7; total time= 6.5min\n",
      "[CV 5/5; 9/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=6, n_estimators=500, subsample=0.7\n",
      "[CV 5/5; 9/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=6, n_estimators=500, subsample=0.7; total time= 6.5min\n",
      "[CV 1/5; 10/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.5\n",
      "[CV 1/5; 10/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.5; total time= 2.2min\n",
      "[CV 2/5; 10/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 10/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.5; total time= 2.2min\n",
      "[CV 3/5; 10/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.5\n",
      "[CV 3/5; 10/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.5; total time= 2.2min\n",
      "[CV 4/5; 10/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.5\n",
      "[CV 4/5; 10/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.5; total time= 2.2min\n",
      "[CV 5/5; 10/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.5\n",
      "[CV 5/5; 10/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=0.5; total time= 2.2min\n",
      "[CV 1/5; 11/15] START colsample_bylevel=0.4, colsample_bytree=0.8999999999999999, lambda=0.8999999999999999, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6\n",
      "[CV 1/5; 11/15] END colsample_bylevel=0.4, colsample_bytree=0.8999999999999999, lambda=0.8999999999999999, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=  35.3s\n",
      "[CV 2/5; 11/15] START colsample_bylevel=0.4, colsample_bytree=0.8999999999999999, lambda=0.8999999999999999, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6\n",
      "[CV 2/5; 11/15] END colsample_bylevel=0.4, colsample_bytree=0.8999999999999999, lambda=0.8999999999999999, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=  35.2s\n",
      "[CV 3/5; 11/15] START colsample_bylevel=0.4, colsample_bytree=0.8999999999999999, lambda=0.8999999999999999, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6\n",
      "[CV 3/5; 11/15] END colsample_bylevel=0.4, colsample_bytree=0.8999999999999999, lambda=0.8999999999999999, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=  35.1s\n",
      "[CV 4/5; 11/15] START colsample_bylevel=0.4, colsample_bytree=0.8999999999999999, lambda=0.8999999999999999, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6\n",
      "[CV 4/5; 11/15] END colsample_bylevel=0.4, colsample_bytree=0.8999999999999999, lambda=0.8999999999999999, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=  35.2s\n",
      "[CV 5/5; 11/15] START colsample_bylevel=0.4, colsample_bytree=0.8999999999999999, lambda=0.8999999999999999, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6\n",
      "[CV 5/5; 11/15] END colsample_bylevel=0.4, colsample_bytree=0.8999999999999999, lambda=0.8999999999999999, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=  35.2s\n",
      "[CV 1/5; 12/15] START colsample_bylevel=0.4, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7\n",
      "[CV 1/5; 12/15] END colsample_bylevel=0.4, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7; total time=  36.8s\n",
      "[CV 2/5; 12/15] START colsample_bylevel=0.4, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7\n",
      "[CV 2/5; 12/15] END colsample_bylevel=0.4, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7; total time=  37.2s\n",
      "[CV 3/5; 12/15] START colsample_bylevel=0.4, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7\n",
      "[CV 3/5; 12/15] END colsample_bylevel=0.4, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7; total time=  37.1s\n",
      "[CV 4/5; 12/15] START colsample_bylevel=0.4, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7\n",
      "[CV 4/5; 12/15] END colsample_bylevel=0.4, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7; total time=  36.8s\n",
      "[CV 5/5; 12/15] START colsample_bylevel=0.4, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7\n",
      "[CV 5/5; 12/15] END colsample_bylevel=0.4, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.7; total time=  37.0s\n",
      "[CV 1/5; 13/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=4.699999999999999, learning_rate=0.3, max_depth=10, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 1/5; 13/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=4.699999999999999, learning_rate=0.3, max_depth=10, n_estimators=100, subsample=0.8999999999999999; total time=  57.4s\n",
      "[CV 2/5; 13/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=4.699999999999999, learning_rate=0.3, max_depth=10, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 2/5; 13/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=4.699999999999999, learning_rate=0.3, max_depth=10, n_estimators=100, subsample=0.8999999999999999; total time=  57.2s\n",
      "[CV 3/5; 13/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=4.699999999999999, learning_rate=0.3, max_depth=10, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 3/5; 13/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=4.699999999999999, learning_rate=0.3, max_depth=10, n_estimators=100, subsample=0.8999999999999999; total time=  57.9s\n",
      "[CV 4/5; 13/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=4.699999999999999, learning_rate=0.3, max_depth=10, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 4/5; 13/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=4.699999999999999, learning_rate=0.3, max_depth=10, n_estimators=100, subsample=0.8999999999999999; total time=  57.7s\n",
      "[CV 5/5; 13/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=4.699999999999999, learning_rate=0.3, max_depth=10, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 5/5; 13/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=4.699999999999999, learning_rate=0.3, max_depth=10, n_estimators=100, subsample=0.8999999999999999; total time=  57.8s\n",
      "[CV 1/5; 14/15] START colsample_bylevel=0.7, colsample_bytree=0.6, lambda=4.499999999999999, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 1/5; 14/15] END colsample_bylevel=0.7, colsample_bytree=0.6, lambda=4.499999999999999, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8999999999999999; total time= 2.1min\n",
      "[CV 2/5; 14/15] START colsample_bylevel=0.7, colsample_bytree=0.6, lambda=4.499999999999999, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 2/5; 14/15] END colsample_bylevel=0.7, colsample_bytree=0.6, lambda=4.499999999999999, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8999999999999999; total time= 2.1min\n",
      "[CV 3/5; 14/15] START colsample_bylevel=0.7, colsample_bytree=0.6, lambda=4.499999999999999, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 3/5; 14/15] END colsample_bylevel=0.7, colsample_bytree=0.6, lambda=4.499999999999999, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8999999999999999; total time= 2.1min\n",
      "[CV 4/5; 14/15] START colsample_bylevel=0.7, colsample_bytree=0.6, lambda=4.499999999999999, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 4/5; 14/15] END colsample_bylevel=0.7, colsample_bytree=0.6, lambda=4.499999999999999, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8999999999999999; total time= 2.1min\n",
      "[CV 5/5; 14/15] START colsample_bylevel=0.7, colsample_bytree=0.6, lambda=4.499999999999999, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 5/5; 14/15] END colsample_bylevel=0.7, colsample_bytree=0.6, lambda=4.499999999999999, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8999999999999999; total time= 2.1min\n",
      "[CV 1/5; 15/15] START colsample_bylevel=0.7, colsample_bytree=0.5, lambda=3.8999999999999995, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 15/15] END colsample_bylevel=0.7, colsample_bytree=0.5, lambda=3.8999999999999995, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  26.8s\n",
      "[CV 2/5; 15/15] START colsample_bylevel=0.7, colsample_bytree=0.5, lambda=3.8999999999999995, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 15/15] END colsample_bylevel=0.7, colsample_bytree=0.5, lambda=3.8999999999999995, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  26.8s\n",
      "[CV 3/5; 15/15] START colsample_bylevel=0.7, colsample_bytree=0.5, lambda=3.8999999999999995, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 15/15] END colsample_bylevel=0.7, colsample_bytree=0.5, lambda=3.8999999999999995, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  26.9s\n",
      "[CV 4/5; 15/15] START colsample_bylevel=0.7, colsample_bytree=0.5, lambda=3.8999999999999995, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 15/15] END colsample_bylevel=0.7, colsample_bytree=0.5, lambda=3.8999999999999995, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  27.1s\n",
      "[CV 5/5; 15/15] START colsample_bylevel=0.7, colsample_bytree=0.5, lambda=3.8999999999999995, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 15/15] END colsample_bylevel=0.7, colsample_bytree=0.5, lambda=3.8999999999999995, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.5; total time=  27.2s\n",
      "Best parameters: {'subsample': 0.7, 'n_estimators': 1000, 'max_depth': 15, 'learning_rate': 0.1, 'lambda': 3.8999999999999995, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.5}\n",
      "Lowest RMSE:  0.025225053574427447\n"
     ]
    }
   ],
   "source": [
    "params = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'lambda' : np.arange(0.5,2,0.2)\n",
    "            }\n",
    "model = XGBRegressor(seed = 20)\n",
    "clf = RandomizedSearchCV(estimator = model,\n",
    "                         param_distributions = params,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         n_iter=15,\n",
    "                         verbose=10)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8072fa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'subsample': 0.7, 'n_estimators': 1000, 'max_depth': 15, 'learning_rate': 0.1, 'lambda': 3.8999999999999995, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.5}\n",
      "Lowest RMSE:  0.025225053574427447\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3e203ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "411d4b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the MSE for tuned model XGB Regressor is 0.0005287934425923489\n"
     ]
    }
   ],
   "source": [
    "print('the MSE for tuned model XGB Regressor is', MSE(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d87e33",
   "metadata": {},
   "source": [
    "### Features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd93253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(subsample = 0.7, n_estimators = 1000, max_depth = 15, learning_rate = 0.1, reg_lambda = 3.8999,\n",
    "                     colsample_bytree = 0.7, colsample_bylevel = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efb1a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0879898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00063508 0.00048283 0.00074958 0.00047041 0.00052753 0.00068872\n",
      " 0.00055149 0.00070202 0.00062631 0.00087299 0.00149044 0.00104346\n",
      " 0.00093482 0.00198257 0.00091558 0.00079878 0.00114358 0.0006978\n",
      " 0.00113119 0.00125822 0.00199444 0.00412398 0.0014116  0.00089716\n",
      " 0.00178629 0.00161689 0.00159695 0.00128787 0.00135669 0.00265071\n",
      " 0.00379541 0.00239945 0.00102576 0.00204374 0.00248111 0.00175079\n",
      " 0.00160674 0.00393307 0.00160933 0.00307094 0.0032169  0.00120781\n",
      " 0.00129693 0.00246873 0.0065111  0.00335185 0.00683105 0.00144478\n",
      " 0.00186879 0.00178737 0.00125027 0.00225975 0.00136005 0.00107974\n",
      " 0.00230964 0.0015718  0.00161097 0.00183146 0.00417426 0.0036072\n",
      " 0.00294612 0.00607137 0.00292454 0.00373995 0.00510433 0.00085118\n",
      " 0.00343225 0.00348573 0.00781835 0.00240094 0.00262377 0.00186521\n",
      " 0.00267382 0.00151751 0.00172458 0.00407073 0.00131859 0.00112745\n",
      " 0.00536356 0.00150909 0.00325685 0.00278176 0.00203093 0.00191603\n",
      " 0.00371068 0.00322687 0.00161727 0.00294672 0.00326728 0.00291111\n",
      " 0.00301936 0.00256918 0.00328611 0.00393179 0.00291814 0.00637686\n",
      " 0.00260346 0.00141319 0.00381492 0.00314608 0.00167616 0.00275342\n",
      " 0.0020963  0.00194491 0.002598   0.00183052 0.00166286 0.00468682\n",
      " 0.00424154 0.01640849 0.0028339  0.00321209 0.0036072  0.00360898\n",
      " 0.00139717 0.0014086  0.00689401 0.00349378 0.00750787 0.00213\n",
      " 0.00277635 0.00166349 0.00289385 0.00735085 0.00219322 0.00132211\n",
      " 0.00148247 0.00246051 0.00321544 0.00260783 0.00212447 0.00520948\n",
      " 0.00321612 0.02338357 0.00264826 0.00179271 0.017147   0.00212053\n",
      " 0.00151214 0.00190716 0.00264763 0.00156869 0.00234366 0.00579335\n",
      " 0.00143901 0.00222066 0.00287397 0.00831611 0.00200929 0.00288848\n",
      " 0.00251584 0.00218605 0.0024996  0.00278973 0.0023771  0.00354607\n",
      " 0.00218009 0.02654281 0.00234428 0.00361369 0.00567788 0.00492367\n",
      " 0.0034951  0.00393835 0.00131444 0.00209228 0.00335018 0.00187633\n",
      " 0.00351326 0.00191641 0.00230061 0.00413243 0.00172518 0.00232499\n",
      " 0.00218109 0.00535431 0.00440381 0.0025868  0.00476615 0.00296683\n",
      " 0.00450731 0.01580042 0.00347753 0.00384997 0.00495578 0.00329481\n",
      " 0.00176835 0.00425673 0.00306434 0.00268014 0.00194174 0.00346789\n",
      " 0.00428147 0.00159722 0.00517883 0.00629431 0.00319923 0.00292037\n",
      " 0.0027486  0.00225489 0.0071817  0.00373109 0.00249051 0.0021402\n",
      " 0.00409287 0.02153482 0.0027608  0.00483095 0.00326092 0.00533298\n",
      " 0.00133482 0.0021627  0.00541827 0.001268   0.00167334 0.0023519\n",
      " 0.00152236 0.00234441 0.00327204 0.00420317 0.0021441  0.00202227\n",
      " 0.0035573  0.00214039 0.00222517 0.00186126 0.00311976 0.00623831\n",
      " 0.00581379 0.00984414 0.00147804 0.00272181 0.00295859 0.00164429\n",
      " 0.00184744 0.00253514 0.00158095 0.00386158 0.00315305 0.00434717\n",
      " 0.00258191 0.00158885 0.00194794 0.00570739 0.00133951 0.00165534\n",
      " 0.00302287 0.00153637 0.0124166  0.00283602 0.00233807 0.00148839\n",
      " 0.00398436 0.00584234 0.00191629 0.00267578 0.00313778 0.00118123\n",
      " 0.00337986 0.00277849 0.00336867 0.00576765 0.00263467 0.0020893\n",
      " 0.00352945 0.00138128 0.00210263 0.00232723 0.00199065 0.00160163\n",
      " 0.00154188 0.00225801 0.00469884 0.00812127 0.00603478 0.0041457\n",
      " 0.00300089 0.00395134 0.00267341 0.00437505 0.00332259 0.00134167\n",
      " 0.00263337 0.00430137 0.00492134 0.0014714  0.00264539 0.00180139\n",
      " 0.00275933 0.00173368 0.00297517 0.002402   0.001046   0.00214924\n",
      " 0.0019295  0.00178406 0.00344145 0.00898795 0.00276359 0.00196723\n",
      " 0.00213227 0.00423613 0.00174711 0.00130559 0.00251847 0.00096302\n",
      " 0.00272856 0.00161433 0.00146681 0.0014936  0.00172168 0.00196609\n",
      " 0.00236036 0.00172289 0.00313008 0.0018221  0.0014848  0.00166351]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.feature_importances_)\n",
    "# plot\n",
    "plt.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5274e964",
   "metadata": {},
   "source": [
    "Some features have way less important than others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03984bbd",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db32aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68bfa978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.95)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942d723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33f7aa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119406, 44)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d6a32",
   "metadata": {},
   "source": [
    "We are just left with 44 features, we performed a great dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73ea16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9b6d0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the MSE for tuned model XGB Regressor when applied PCA is 0.002659388081142156\n"
     ]
    }
   ],
   "source": [
    "print('the MSE for tuned model XGB Regressor when applied PCA is', MSE(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc6a769",
   "metadata": {},
   "source": [
    "The accuracy seems decreased, but what if we perform an hyperparameter tuning ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7adef937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5; 1/15] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=500, subsample=0.7999999999999999\n",
      "[CV 1/5; 1/15] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=500, subsample=0.7999999999999999; total time=  45.8s\n",
      "[CV 2/5; 1/15] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=500, subsample=0.7999999999999999\n",
      "[CV 2/5; 1/15] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=500, subsample=0.7999999999999999; total time=  47.9s\n",
      "[CV 3/5; 1/15] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=500, subsample=0.7999999999999999\n",
      "[CV 3/5; 1/15] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=500, subsample=0.7999999999999999; total time=  47.6s\n",
      "[CV 4/5; 1/15] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=500, subsample=0.7999999999999999\n",
      "[CV 4/5; 1/15] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=500, subsample=0.7999999999999999; total time=  47.6s\n",
      "[CV 5/5; 1/15] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=500, subsample=0.7999999999999999\n",
      "[CV 5/5; 1/15] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=500, subsample=0.7999999999999999; total time=  49.0s\n",
      "[CV 1/5; 2/15] START colsample_bylevel=0.7, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 2/15] END colsample_bylevel=0.7, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5; total time=  15.9s\n",
      "[CV 2/5; 2/15] START colsample_bylevel=0.7, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 2/15] END colsample_bylevel=0.7, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5; total time=  15.6s\n",
      "[CV 3/5; 2/15] START colsample_bylevel=0.7, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 2/15] END colsample_bylevel=0.7, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5; total time=  15.7s\n",
      "[CV 4/5; 2/15] START colsample_bylevel=0.7, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 2/15] END colsample_bylevel=0.7, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5; total time=  15.6s\n",
      "[CV 5/5; 2/15] START colsample_bylevel=0.7, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 2/15] END colsample_bylevel=0.7, colsample_bytree=0.4, lambda=1.8999999999999997, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.5; total time=  15.6s\n",
      "[CV 1/5; 3/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, lambda=0.7, learning_rate=0.3, max_depth=20, n_estimators=500, subsample=0.6\n",
      "[CV 1/5; 3/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, lambda=0.7, learning_rate=0.3, max_depth=20, n_estimators=500, subsample=0.6; total time= 1.1min\n",
      "[CV 2/5; 3/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, lambda=0.7, learning_rate=0.3, max_depth=20, n_estimators=500, subsample=0.6\n",
      "[CV 2/5; 3/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, lambda=0.7, learning_rate=0.3, max_depth=20, n_estimators=500, subsample=0.6; total time= 1.1min\n",
      "[CV 3/5; 3/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, lambda=0.7, learning_rate=0.3, max_depth=20, n_estimators=500, subsample=0.6\n",
      "[CV 3/5; 3/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, lambda=0.7, learning_rate=0.3, max_depth=20, n_estimators=500, subsample=0.6; total time= 1.1min\n",
      "[CV 4/5; 3/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, lambda=0.7, learning_rate=0.3, max_depth=20, n_estimators=500, subsample=0.6\n",
      "[CV 4/5; 3/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, lambda=0.7, learning_rate=0.3, max_depth=20, n_estimators=500, subsample=0.6; total time= 1.1min\n",
      "[CV 5/5; 3/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, lambda=0.7, learning_rate=0.3, max_depth=20, n_estimators=500, subsample=0.6\n",
      "[CV 5/5; 3/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.6, lambda=0.7, learning_rate=0.3, max_depth=20, n_estimators=500, subsample=0.6; total time= 1.1min\n",
      "[CV 1/5; 4/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=1.2999999999999998, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 1/5; 4/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=1.2999999999999998, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.7999999999999999; total time= 1.2min\n",
      "[CV 2/5; 4/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=1.2999999999999998, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 2/5; 4/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=1.2999999999999998, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.7999999999999999; total time= 1.2min\n",
      "[CV 3/5; 4/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=1.2999999999999998, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 3/5; 4/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=1.2999999999999998, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.7999999999999999; total time= 1.2min\n",
      "[CV 4/5; 4/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=1.2999999999999998, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 4/5; 4/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=1.2999999999999998, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.7999999999999999; total time= 1.2min\n",
      "[CV 5/5; 4/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=1.2999999999999998, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 5/5; 4/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.7, lambda=1.2999999999999998, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.7999999999999999; total time= 1.2min\n",
      "[CV 1/5; 5/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, lambda=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 1/5; 5/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, lambda=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8999999999999999; total time=   8.9s\n",
      "[CV 2/5; 5/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, lambda=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 2/5; 5/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, lambda=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8999999999999999; total time=   8.9s\n",
      "[CV 3/5; 5/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, lambda=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8999999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, lambda=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8999999999999999; total time=   9.0s\n",
      "[CV 4/5; 5/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, lambda=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 4/5; 5/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, lambda=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8999999999999999; total time=   9.0s\n",
      "[CV 5/5; 5/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, lambda=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 5/5; 5/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.4, lambda=0.5, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8999999999999999; total time=   9.0s\n",
      "[CV 1/5; 6/15] START colsample_bylevel=0.6, colsample_bytree=0.7999999999999999, lambda=1.0999999999999999, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.7\n",
      "[CV 1/5; 6/15] END colsample_bylevel=0.6, colsample_bytree=0.7999999999999999, lambda=1.0999999999999999, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.7; total time=   8.5s\n",
      "[CV 2/5; 6/15] START colsample_bylevel=0.6, colsample_bytree=0.7999999999999999, lambda=1.0999999999999999, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.7\n",
      "[CV 2/5; 6/15] END colsample_bylevel=0.6, colsample_bytree=0.7999999999999999, lambda=1.0999999999999999, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.7; total time=   8.5s\n",
      "[CV 3/5; 6/15] START colsample_bylevel=0.6, colsample_bytree=0.7999999999999999, lambda=1.0999999999999999, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.7\n",
      "[CV 3/5; 6/15] END colsample_bylevel=0.6, colsample_bytree=0.7999999999999999, lambda=1.0999999999999999, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.7; total time=   8.5s\n",
      "[CV 4/5; 6/15] START colsample_bylevel=0.6, colsample_bytree=0.7999999999999999, lambda=1.0999999999999999, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.7\n",
      "[CV 4/5; 6/15] END colsample_bylevel=0.6, colsample_bytree=0.7999999999999999, lambda=1.0999999999999999, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.7; total time=   8.5s\n",
      "[CV 5/5; 6/15] START colsample_bylevel=0.6, colsample_bytree=0.7999999999999999, lambda=1.0999999999999999, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.7\n",
      "[CV 5/5; 6/15] END colsample_bylevel=0.6, colsample_bytree=0.7999999999999999, lambda=1.0999999999999999, learning_rate=0.3, max_depth=5, n_estimators=100, subsample=0.7; total time=   8.5s\n",
      "[CV 1/5; 7/15] START colsample_bylevel=0.5, colsample_bytree=0.5, lambda=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.7999999999999999\n",
      "[CV 1/5; 7/15] END colsample_bylevel=0.5, colsample_bytree=0.5, lambda=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.7999999999999999; total time=   7.4s\n",
      "[CV 2/5; 7/15] START colsample_bylevel=0.5, colsample_bytree=0.5, lambda=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.7999999999999999\n",
      "[CV 2/5; 7/15] END colsample_bylevel=0.5, colsample_bytree=0.5, lambda=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.7999999999999999; total time=   7.3s\n",
      "[CV 3/5; 7/15] START colsample_bylevel=0.5, colsample_bytree=0.5, lambda=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.7999999999999999\n",
      "[CV 3/5; 7/15] END colsample_bylevel=0.5, colsample_bytree=0.5, lambda=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.7999999999999999; total time=   7.3s\n",
      "[CV 4/5; 7/15] START colsample_bylevel=0.5, colsample_bytree=0.5, lambda=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.7999999999999999\n",
      "[CV 4/5; 7/15] END colsample_bylevel=0.5, colsample_bytree=0.5, lambda=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.7999999999999999; total time=   7.3s\n",
      "[CV 5/5; 7/15] START colsample_bylevel=0.5, colsample_bytree=0.5, lambda=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.7999999999999999\n",
      "[CV 5/5; 7/15] END colsample_bylevel=0.5, colsample_bytree=0.5, lambda=0.5, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.7999999999999999; total time=   7.3s\n",
      "[CV 1/5; 8/15] START colsample_bylevel=0.5, colsample_bytree=0.6, lambda=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7999999999999999\n",
      "[CV 1/5; 8/15] END colsample_bylevel=0.5, colsample_bytree=0.6, lambda=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7999999999999999; total time=   8.6s\n",
      "[CV 2/5; 8/15] START colsample_bylevel=0.5, colsample_bytree=0.6, lambda=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7999999999999999\n",
      "[CV 2/5; 8/15] END colsample_bylevel=0.5, colsample_bytree=0.6, lambda=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7999999999999999; total time=   8.6s\n",
      "[CV 3/5; 8/15] START colsample_bylevel=0.5, colsample_bytree=0.6, lambda=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7999999999999999\n",
      "[CV 3/5; 8/15] END colsample_bylevel=0.5, colsample_bytree=0.6, lambda=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7999999999999999; total time=   8.7s\n",
      "[CV 4/5; 8/15] START colsample_bylevel=0.5, colsample_bytree=0.6, lambda=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7999999999999999\n",
      "[CV 4/5; 8/15] END colsample_bylevel=0.5, colsample_bytree=0.6, lambda=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7999999999999999; total time=   8.6s\n",
      "[CV 5/5; 8/15] START colsample_bylevel=0.5, colsample_bytree=0.6, lambda=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7999999999999999\n",
      "[CV 5/5; 8/15] END colsample_bylevel=0.5, colsample_bytree=0.6, lambda=0.5, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.7999999999999999; total time=   8.6s\n",
      "[CV 1/5; 9/15] START colsample_bylevel=0.4, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 1/5; 9/15] END colsample_bylevel=0.4, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5; total time=   3.0s\n",
      "[CV 2/5; 9/15] START colsample_bylevel=0.4, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 2/5; 9/15] END colsample_bylevel=0.4, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5; total time=   3.1s\n",
      "[CV 3/5; 9/15] START colsample_bylevel=0.4, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 3/5; 9/15] END colsample_bylevel=0.4, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5; total time=   3.0s\n",
      "[CV 4/5; 9/15] START colsample_bylevel=0.4, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 4/5; 9/15] END colsample_bylevel=0.4, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5; total time=   3.1s\n",
      "[CV 5/5; 9/15] START colsample_bylevel=0.4, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5\n",
      "[CV 5/5; 9/15] END colsample_bylevel=0.4, colsample_bytree=0.7, lambda=0.7, learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.5; total time=   3.0s\n",
      "[CV 1/5; 10/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 1/5; 10/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.8999999999999999; total time=  11.6s\n",
      "[CV 2/5; 10/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 2/5; 10/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.8999999999999999; total time=  11.6s\n",
      "[CV 3/5; 10/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.8999999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.8999999999999999; total time=  11.6s\n",
      "[CV 4/5; 10/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 4/5; 10/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.8999999999999999; total time=  11.5s\n",
      "[CV 5/5; 10/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 5/5; 10/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=1.8999999999999997, learning_rate=0.3, max_depth=6, n_estimators=100, subsample=0.8999999999999999; total time=  12.0s\n",
      "[CV 1/5; 11/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=0.8999999999999999, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 1/5; 11/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=0.8999999999999999, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.8999999999999999; total time=  32.0s\n",
      "[CV 2/5; 11/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=0.8999999999999999, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 2/5; 11/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=0.8999999999999999, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.8999999999999999; total time=  31.6s\n",
      "[CV 3/5; 11/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=0.8999999999999999, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 3/5; 11/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=0.8999999999999999, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.8999999999999999; total time=  31.6s\n",
      "[CV 4/5; 11/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=0.8999999999999999, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 4/5; 11/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=0.8999999999999999, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.8999999999999999; total time=  31.5s\n",
      "[CV 5/5; 11/15] START colsample_bylevel=0.7, colsample_bytree=0.7, lambda=0.8999999999999999, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
      "[CV 5/5; 11/15] END colsample_bylevel=0.7, colsample_bytree=0.7, lambda=0.8999999999999999, learning_rate=0.2, max_depth=15, n_estimators=100, subsample=0.8999999999999999; total time=  32.0s\n",
      "[CV 1/5; 12/15] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.2999999999999998, learning_rate=0.01, max_depth=20, n_estimators=500, subsample=0.7\n",
      "[CV 1/5; 12/15] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.2999999999999998, learning_rate=0.01, max_depth=20, n_estimators=500, subsample=0.7; total time= 3.4min\n",
      "[CV 2/5; 12/15] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.2999999999999998, learning_rate=0.01, max_depth=20, n_estimators=500, subsample=0.7\n",
      "[CV 2/5; 12/15] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.2999999999999998, learning_rate=0.01, max_depth=20, n_estimators=500, subsample=0.7; total time= 3.2min\n",
      "[CV 3/5; 12/15] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.2999999999999998, learning_rate=0.01, max_depth=20, n_estimators=500, subsample=0.7\n",
      "[CV 3/5; 12/15] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.2999999999999998, learning_rate=0.01, max_depth=20, n_estimators=500, subsample=0.7; total time= 3.3min\n",
      "[CV 4/5; 12/15] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.2999999999999998, learning_rate=0.01, max_depth=20, n_estimators=500, subsample=0.7\n",
      "[CV 4/5; 12/15] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.2999999999999998, learning_rate=0.01, max_depth=20, n_estimators=500, subsample=0.7; total time= 4.4min\n",
      "[CV 5/5; 12/15] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.2999999999999998, learning_rate=0.01, max_depth=20, n_estimators=500, subsample=0.7\n",
      "[CV 5/5; 12/15] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, lambda=1.2999999999999998, learning_rate=0.01, max_depth=20, n_estimators=500, subsample=0.7; total time= 3.6min\n",
      "[CV 1/5; 13/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=0.8999999999999999, learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.6\n",
      "[CV 1/5; 13/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=0.8999999999999999, learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.6; total time=  28.2s\n",
      "[CV 2/5; 13/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=0.8999999999999999, learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.6\n",
      "[CV 2/5; 13/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=0.8999999999999999, learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.6; total time=  29.7s\n",
      "[CV 3/5; 13/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=0.8999999999999999, learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.6\n",
      "[CV 3/5; 13/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=0.8999999999999999, learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.6; total time=  29.8s\n",
      "[CV 4/5; 13/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=0.8999999999999999, learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.6\n",
      "[CV 4/5; 13/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=0.8999999999999999, learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.6; total time=  29.8s\n",
      "[CV 5/5; 13/15] START colsample_bylevel=0.6, colsample_bytree=0.4, lambda=0.8999999999999999, learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.6\n",
      "[CV 5/5; 13/15] END colsample_bylevel=0.6, colsample_bytree=0.4, lambda=0.8999999999999999, learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.6; total time=  30.2s\n",
      "[CV 1/5; 14/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 1/5; 14/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7999999999999999; total time= 4.2min\n",
      "[CV 2/5; 14/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 2/5; 14/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7999999999999999; total time= 4.3min\n",
      "[CV 3/5; 14/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 3/5; 14/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7999999999999999; total time= 4.3min\n",
      "[CV 4/5; 14/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 4/5; 14/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7999999999999999; total time= 4.2min\n",
      "[CV 5/5; 14/15] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7999999999999999\n",
      "[CV 5/5; 14/15] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, lambda=1.8999999999999997, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7999999999999999; total time= 4.3min\n",
      "[CV 1/5; 15/15] START colsample_bylevel=0.6, colsample_bytree=0.5, lambda=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 15/15] END colsample_bylevel=0.6, colsample_bytree=0.5, lambda=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7; total time= 2.7min\n",
      "[CV 2/5; 15/15] START colsample_bylevel=0.6, colsample_bytree=0.5, lambda=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7\n",
      "[CV 2/5; 15/15] END colsample_bylevel=0.6, colsample_bytree=0.5, lambda=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7; total time= 2.7min\n",
      "[CV 3/5; 15/15] START colsample_bylevel=0.6, colsample_bytree=0.5, lambda=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7\n",
      "[CV 3/5; 15/15] END colsample_bylevel=0.6, colsample_bytree=0.5, lambda=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7; total time= 2.7min\n",
      "[CV 4/5; 15/15] START colsample_bylevel=0.6, colsample_bytree=0.5, lambda=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7\n",
      "[CV 4/5; 15/15] END colsample_bylevel=0.6, colsample_bytree=0.5, lambda=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7; total time= 2.7min\n",
      "[CV 5/5; 15/15] START colsample_bylevel=0.6, colsample_bytree=0.5, lambda=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7\n",
      "[CV 5/5; 15/15] END colsample_bylevel=0.6, colsample_bytree=0.5, lambda=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=1000, subsample=0.7; total time= 2.7min\n",
      "Best parameters: {'subsample': 0.7999999999999999, 'n_estimators': 1000, 'max_depth': 10, 'learning_rate': 0.1, 'lambda': 1.8999999999999997, 'colsample_bytree': 0.8999999999999999, 'colsample_bylevel': 0.8999999999999999}\n",
      "Lowest RMSE:  0.050224145447512865\n"
     ]
    }
   ],
   "source": [
    "params = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'lambda' : np.arange(0.5,2,0.2)\n",
    "            }\n",
    "model = XGBRegressor(seed = 20)\n",
    "clf = RandomizedSearchCV(estimator = model,\n",
    "                         param_distributions = params,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         n_iter=15,\n",
    "                         verbose=10)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da33562d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'subsample': 0.7999999999999999, 'n_estimators': 1000, 'max_depth': 10, 'learning_rate': 0.1, 'lambda': 1.8999999999999997, 'colsample_bytree': 0.8999999999999999, 'colsample_bylevel': 0.8999999999999999}\n",
      "Lowest RMSE:  0.050224145447512865\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b612b2",
   "metadata": {},
   "source": [
    "Decrease in performaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da60ce77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
