{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Full_regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EFJD9FLSoy16"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "import math\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from scipy import stats\n",
        "import scipy as sci\n",
        "\n",
        "import random\n",
        "\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from scipy.spatial.distance import minkowski\n",
        "\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount  Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive/Colab\\ Notebooks/ML\\ Project2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dKpmmGRrbFV",
        "outputId": "5a0c5c74-bcf1-4a34-feb1-0df6d85c1799"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Colab Notebooks/ML Project2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset"
      ],
      "metadata": {
        "id": "lQeZc60OuW1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('GSM1586785_ScrH-12A_Exd_14mer_cg.csv.zip', compression='zip')"
      ],
      "metadata": {
        "id": "f1fAXgGIrqyH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns = 'Unnamed: 0', inplace = True)\n",
        "df.drop(columns = 'Kmer', inplace = True)"
      ],
      "metadata": {
        "id": "ATPYYK6HruO7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['relKa'].to_numpy()\n",
        "x = df.loc[:, df.columns != 'relKa'].to_numpy()"
      ],
      "metadata": {
        "id": "2hLrB8vquQHJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split to 0 & 1"
      ],
      "metadata": {
        "id": "nj8JK_I4y2BB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_importance(x,y,importance_class=0.7):\n",
        "  \"\"\"\n",
        "  Split the samples into interesting ones and not interesting ones\n",
        "  :param x: numpy.ndarray:the feature vector of the initial dataset\n",
        "  :param y: numpy.ndarray: the value vector of the initial dataset\n",
        "  :param importance_class: float: the lower bound for the underepresented class\n",
        "  \"\"\"\n",
        "  return x[y>=importance_class], y[y>=importance_class], x[y<importance_class], y[y<importance_class]"
      ],
      "metadata": {
        "id": "wK2ng3NRy47T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_1,y_1,x_0,y_0 = split_importance(x,y)"
      ],
      "metadata": {
        "id": "EgJ9bfph0d3d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train - Test Split"
      ],
      "metadata": {
        "id": "WzFdM7KK1fPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the two classes seperately into train and test set to ensure representation of the minority class\n",
        "# both in the test set and in the train set\n",
        "x_1_train,x_1_test,y_1_train,y_1_test = train_test_split(x_1, y_1, test_size=0.30, random_state=42)\n",
        "x_0_train,x_0_test,y_0_train,y_0_test = train_test_split(x_0, y_0, test_size=0.30, random_state=42)\n",
        "\n",
        "x_train = np.concatenate((x_1_train,x_0_train))\n",
        "y_train = np.concatenate((y_1_train,y_0_train))\n",
        "x_test = np.concatenate((x_1_test,x_0_test))\n",
        "y_test = np.concatenate((y_1_test,y_0_test))"
      ],
      "metadata": {
        "id": "0xgHKQkg1dPA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove Outliers"
      ],
      "metadata": {
        "id": "6zM9TrUluZKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Worse performances\n",
        "def Anomaly_Detection_Isolation_Forests(x, change_split=True):\n",
        "  random_state = np.random.RandomState(42)\n",
        "  contamination = 'auto'\n",
        "  threshold = np.random.uniform(-0.03, -0.02, 1)\n",
        "  model = IsolationForest(n_estimators=120, max_samples='auto', contamination=contamination, random_state=random_state)\n",
        "  model.fit(x)\n",
        "  scores = model.decision_function(x)\n",
        "  if change_split == False:\n",
        "    anomaly_score = model.predict(x)\n",
        "    outliers_indices = np.where(anomaly_score == -1)[0]\n",
        "  if change_split == True:\n",
        "    outliers_indices = split_outliers(threshold, scores)\n",
        "  return contamination, scores, outliers_indices\n",
        "\n",
        "def check_Isolation_Forests(contamination, outliers_indices):\n",
        "  \"\"\"\n",
        "  Simply a check on the proper working of the IF algorithm\n",
        "  \"\"\"\n",
        "  tol = 1.0e-02\n",
        "  if contamination != 'auto':\n",
        "    outliers_percentage = 1 / len(RelKa) * len(outliers_indices)\n",
        "    assert np.abs(contamination-outliers_percentage) < tol\n",
        "\n",
        "def check_boundary_decision(scores, p, verbose=1):\n",
        "  \"\"\"\n",
        "  This function simply controls how many scores returned by the IF algorithm \n",
        "  are likely to be misclassified\n",
        "  \"\"\"\n",
        "  indecision_percentage = 1 / len(y) * np.count_nonzero(np.abs(scores) <= p)\n",
        "  if verbose == 1:\n",
        "    plt.hist(scores)\n",
        "    plt.show()\n",
        "    print(\"The indecision percentage around\", p,  \"is\", indecision_percentage)\n",
        "    print(\"The percentage of outliers detected is\", 1 / len(scores) * len(np.where(scores < 0)[0]))\n",
        "\n",
        "def drop_outliers(x, y, outliers):\n",
        "  x = np.delete(x, outliers, axis=0)\n",
        "  y = np.delete(y, outliers, axis=0)\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "tBDiGVbquTSa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contamination, scores, outliers_indices = Anomaly_Detection_Isolation_Forests(x_train, change_split=False)\n",
        "check_Isolation_Forests(contamination, outliers_indices)\n",
        "check_boundary_decision(scores, 0.02, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "wU_e-0CRukGZ",
        "outputId": "de987df9-1b3f-4795-e2b9-e07a911c7f62"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The indecision percentage around 0.02 is 0.3352659440383161\n",
            "The percentage of outliers detected is 0.06591796057149557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = drop_outliers(x_train, y_train, outliers_indices)"
      ],
      "metadata": {
        "id": "nY4GquNvuoIZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Manipulation"
      ],
      "metadata": {
        "id": "M30LuGhM8_AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "3uRlU-2s9Bkj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boxcox Transformation"
      ],
      "metadata": {
        "id": "c0jXjMimOOGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, fitted_lambda= stats.boxcox(list(y_train),lmbda=None)\n",
        "#print(fitted_lambda)\n",
        "#print(stats.boxcox([0.7,1], fitted_lambda))\n",
        "y_train = np.array(y_train)\n",
        "print(fitted_lambda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lib9c4qEOQU5",
        "outputId": "a535ef47-6d09-4b59-b4b4-f7d93c6f17df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.0008549422054305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Smote Sampling "
      ],
      "metadata": {
        "id": "YIluw6pa-OIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Fisher_Score(x_import,x_nimport):\n",
        "  \"\"\"\n",
        "  Given two arrays of two classes this function calculates the Fischer_scores to \n",
        "  measure the significance for all features\n",
        "  :param x_import: numpy.ndarray: the array containing the samples of one class\n",
        "  :param x_nimport: numpy.ndarray: the array containing the samples of the other class\n",
        "  :return: numpy.ndarray: returns an array containg the Fisher_Score for all features \n",
        "  \"\"\"\n",
        "  mean_import = np.mean(x_import,axis = 0)\n",
        "  mean_nimport = np.mean(x_nimport,axis = 0)\n",
        "  mean_dist = np.absolute(mean_import-mean_nimport)\n",
        "  std_import = np.std(x_import,axis=0)\n",
        "  std_nimport = np.std(x_nimport,axis=0)\n",
        "  std_sum = std_import+std_nimport\n",
        "  #return std_sum\n",
        "  return np.divide(mean_dist,std_sum)\n",
        "\n",
        "def calculate_distances(x,distance):\n",
        "  \"\"\"\n",
        "  Calculates the distance between any two pairs of the set x using \n",
        "  the Minkowski distance of degree distance.\n",
        "  :param x: numpy.ndarray: the vector for which we will calculate the distance \n",
        "                            between all of its elements \n",
        "  :param distance: float: the norm which should be used for the Minkowski distance\n",
        "  :return: numpy.ndarray: returns the Minkowski distance with the specified norm \n",
        "                          between all pairs of elements in x \n",
        "  \"\"\"\n",
        "  dist = np.array([[minkowski(a1,a2,distance) for a2 in x] for a1 in x])\n",
        "  np.fill_diagonal(dist,float('inf'))\n",
        "  return dist\n",
        "\n",
        "def random_sampler(x,y,randomsize):\n",
        "  \"\"\"\n",
        "  This function does random undersampling of vectors x,y and reduces them to \n",
        "  size random size\n",
        "  :param x: numpy.ndarray: the feature vector to be subsampled\n",
        "  :param y: numpy.ndarray: the label vector to be subsampled\n",
        "  :return: <class 'tuple'>: A tuple containing the two undersampled vectors\n",
        "  \"\"\"\n",
        "  p = np.random.permutation(len(y))\n",
        "  new_x = x[p]\n",
        "  new_y = y[p]\n",
        "  return new_x[:randomsize],new_y[:randomsize]\n",
        "\n",
        "def generate_samples(x,y,neighbors,N):\n",
        "  \"\"\"\n",
        "  This function generate N samples which are convex combinations of \n",
        "  the features of x and the labels of y\n",
        "  :param x: numpy.ndarray:\n",
        "  :param y: numpy.ndarray:\n",
        "  :return: <class 'tuple'>:\n",
        "  \"\"\"\n",
        "  new_samples_x = []\n",
        "  new_samples_y = []\n",
        "  for i in range(N):\n",
        "    random_sample_i = random.randint(0,y.shape[0]-1)\n",
        "    x_i = x[random_sample_i]\n",
        "    random_sample_j = random.randint(0,neighbors.shape[1]-1)\n",
        "    neigh_i = neighbors[random_sample_i,random_sample_j]\n",
        "    x_j = x[neigh_i]\n",
        "    lambda_ = random.uniform(0,1)\n",
        "    y_i = y[random_sample_i]\n",
        "    y_j = y[neigh_i]\n",
        "    new_x = x_i + lambda_*(x_j-x_i)\n",
        "    new_y = y_i + lambda_*(y_j-y_i)\n",
        "    new_samples_x.append(new_x)\n",
        "    new_samples_y.append(new_y)\n",
        "  return np.array(new_samples_x),np.array(new_samples_y)\n",
        "\n",
        "def smote_sf(x, y, undersample=0.5, oversample = 0.1, attribute_scorer=Fisher_Score, \n",
        "             attribute_number = 10, distance = float('inf'), kneighbors = 3,\n",
        "             undersampling = random_sampler, importance_class = 0.7):\n",
        "  \"\"\"\n",
        "  This function takes the complete input and produces a more balanced dataset based on the importance class\n",
        "  :param x: numpy.ndarray: the feature vector of the initial dataset\n",
        "  :param y: numpy.ndarray: the value vector of the initial dataset\n",
        "  :param undersample: float: the percentage of the dominant class that we want to keep\n",
        "  :param oversample: float: the percentage of the dataset that the small class will be at the end\n",
        "  :param attribute_scorer: function: a function which will be used to score the relevance of a feature\n",
        "  :param attribute_number: int: the number of attributes to keep according to their score\n",
        "  :param distance: float: the norm which should be used for the Minkowski distance\n",
        "  :param kneighbors: int: the number of samples which should be considered for each point \n",
        "  :param undersampling: function: the function to use for the undersampling of the majority class\n",
        "  :param importance_class: float: the lower bound for the underepresented class\n",
        "  :return: returns 2 new feature vectors and 2 new label vectors containing \n",
        "            the data for the importance class and the data for the non importance \n",
        "            class and their labels. \n",
        "  \"\"\"\n",
        "  x_import = x[y>=importance_class]\n",
        "  y_import = y[y>=importance_class]\n",
        "  x_nimport = x[y<importance_class]\n",
        "  y_nimport = y[y<importance_class]\n",
        "\n",
        "  feature_scores =  attribute_scorer(x_import,x_nimport)\n",
        "  #find the attribute_number highest coordinates of the feature_scores vector\n",
        "  indices = np.sort((-feature_scores).argsort()[:attribute_number])\n",
        "  x_import_filtered = x_import[:,indices]\n",
        "  #x_nimport = x_nimport[:,indices]\n",
        "  distances = calculate_distances(x_import_filtered,distance)\n",
        "  #find the k lowest indices\n",
        "  neighbors = np.array([ np.sort(d.argsort()[:(kneighbors)]) for d in distances])\n",
        "  #undersampling for the majority class\n",
        "  nimport_len = int(undersample*y_nimport.shape[0])\n",
        "  x_nimport,y_nimport = undersampling(x_nimport,y_nimport,nimport_len)\n",
        "  #Calculate the number of samples to be generated\n",
        "  N = int(oversample*(y_nimport.shape[0]) - y_import.shape[0])\n",
        "  #Generate N new samples\n",
        "  new_samples_x,new_samples_y = generate_samples(x_import, y_import, neighbors, N)\n",
        "  #merge the new samples of the minority class with its old samples\n",
        "  x_import = np.concatenate((x_import,new_samples_x))\n",
        "  y_import = np.concatenate((y_import,new_samples_y))\n",
        "\n",
        "  x_ret = np.concatenate((x_import, x_nimport))\n",
        "  y_ret = np.concatenate((y_import,y_nimport))\n",
        "  return x_ret, y_ret"
      ],
      "metadata": {
        "id": "KY_m2BEF-dsn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_boundary = stats.boxcox([0.7,1.],fitted_lambda)[0]\n",
        "print(importance_boundary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIt02CxxTf4T",
        "outputId": "a6fce055-49ba-4234-c2eb-83887508fda1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.4286406555284001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train = smote_sf(x_train,y_train,undersample=0.1,oversample=0.3, kneighbors=5, importance_class = importance_boundary)"
      ],
      "metadata": {
        "id": "6066fXiS-4iN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape,y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgAhJisfW1o6",
        "outputId": "21975872-b393-4896-a102-c3ccbccd1fa9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14469, 318) (14469,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric"
      ],
      "metadata": {
        "id": "ZvEXLgieP1xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def penalized_MSE_helper(y_true, y_pred):\n",
        "    critical_indices = np.where(y_true >= 0.7)\n",
        "    critical_y = y_true[critical_indices]\n",
        "    common_y = np.delete(y_true, critical_indices)\n",
        "    critical_predictions = y_pred[critical_indices]\n",
        "    common_predictions = np.delete(y_pred, critical_indices)\n",
        "    return 1/2*MSE(critical_y, critical_predictions)+ 1/2*MSE(common_y, common_predictions)"
      ],
      "metadata": {
        "id": "7sv8B7apP44H"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def penalized_MSE(y_true, y_pred,fitted_lambda=-1.0008549422054305):\n",
        "  return penalized_MSE_helper(y_true,sci.special.inv_boxcox(y_pred, fitted_lambda))\n",
        "\n",
        "def penalized_MSE_train(y_true, y_pred,fitted_lambda=-1.0008549422054305):\n",
        "  return penalized_MSE_helper(sci.special.inv_boxcox(y_true, fitted_lambda),sci.special.inv_boxcox(y_pred, fitted_lambda))"
      ],
      "metadata": {
        "id": "2cUHHVH9QUrV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Qpc5tgP0WX2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBRegressor(subsample = 0.8999999999999999, n_estimators= 500,\n",
        "                     max_depth = 20, learning_rate = 0.01, colsample_bytree = 0.7999999999999999, colsample_bylevel = 0.6, obj=penalized_MSE )\n",
        "model.fit(x_train, y_train,eval_metric=penalized_MSE_train)\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJWM9WCZBJyi",
        "outputId": "ca90cdaf-7cb8-46db-bfd8-bc2dea2fba0b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19:37:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = sci.special.inv_boxcox(predictions, fitted_lambda)"
      ],
      "metadata": {
        "id": "HDEbj2_dNrhk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('the MSE for tuned model XGB Regressor is',MSE(y_test, predictions))\n",
        "print('the weighted-MSE for tuned model XGB Regressor is',penalized_MSE(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCtO6NkiB3Xt",
        "outputId": "45f9977f-7c5f-46f1-8f33-7b67fbd9fd49"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the MSE for tuned model XGB Regressor is 0.0026053822638653096\n",
            "the weighted-MSE for tuned model XGB Regressor is 7.448454442809187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range_values = np.arange(0.05,1.05,0.1)\n",
        "mse_ranges = []\n",
        "print(range_values)\n",
        "for val in range_values:\n",
        "    labels_range = y_test[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    correspondent_predictions = predictions[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    mse_ranges.append(MSE(correspondent_predictions, labels_range))\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "intervals = ['0.0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4','0.4-0.5', '0.5-0.6', '0.6-0-7', '0.7-0.8', '0.8-0.9', '0.9-1.0']\n",
        "dict_mse = {'intervals': intervals, 'mse': mse_ranges}\n",
        "df_mse = pd.DataFrame.from_dict(dict_mse)\n",
        "sns.barplot(x = df_mse['intervals'], y = df_mse['mse'], color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "t2CZ38fgOmyj",
        "outputId": "ae15d789-df61-47b3-d18f-e6c796cbed9c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 842.4x595.44 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = { 'max_depth': [5, 10, 15, 20],\n",
        "           'learning_rate': [0.01, 0.1, 0.5],\n",
        "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
        "           'colsample_bytree': np.arange(0.5, 1.0, 0.1),\n",
        "           'colsample_bylevel': np.arange(0.5, 1.0, 0.1),\n",
        "           'n_estimators': [100, 500, 1000],\n",
        "            }\n",
        "score = make_scorer(penalized_MSE_train, greater_is_better=False)\n",
        "model = XGBRegressor(seed = 20)\n",
        "clf = RandomizedSearchCV(estimator = model,\n",
        "                         param_distributions = params,\n",
        "                         scoring = score,\n",
        "                         n_iter=10,\n",
        "                         verbose=10)\n",
        "clf.fit(x_train, y_train,eval_metric = penalized_MSE_train)\n",
        "print(\"Best parameters:\", clf.best_params_)\n",
        "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "FLKJunbtYxkS",
        "outputId": "cebe3a5d-4f56-4e1b-a1b7-7860f708f14a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5; 1/10] START colsample_bylevel=0.7, colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=1000, subsample=0.8999999999999999\n",
            "[19:50:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"<ipython-input-22-fc5a6eefbb96>\", line 5, in penalized_MSE_train\n",
            "    return penalized_MSE_helper(sci.special.inv_boxcox(y_true, fitted_lambda),sci.special.inv_boxcox(y_pred, fitted_lambda))\n",
            "  File \"<ipython-input-18-35a842ea6f90>\", line 7, in penalized_MSE_helper\n",
            "    return 1/2*MSE(critical_y, critical_predictions)+ 1/2*MSE(common_y, common_predictions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 424, in mean_squared_error\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 90, in _check_reg_targets\n",
            "    y_true = check_array(y_true, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 800, in check_array\n",
            "    % (n_samples, array.shape, ensure_min_samples, context)\n",
            "ValueError: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5; 1/10] END colsample_bylevel=0.7, colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=1000, subsample=0.8999999999999999;, score=nan total time= 3.8min\n",
            "[CV 2/5; 1/10] START colsample_bylevel=0.7, colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=1000, subsample=0.8999999999999999\n",
            "[19:53:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-995010bdf590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                          \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                          verbose=10)\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpenalized_MSE_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lowest RMSE: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}