{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Outliers_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVkUbtoxrZN3"
      },
      "source": [
        "Importing useful libraries and importing the drive for the dataset"
      ],
      "id": "OVkUbtoxrZN3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc466260"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "import math\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from scipy import stats\n",
        "import scipy as sci\n",
        "\n",
        "import random\n",
        "\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from scipy.spatial.distance import minkowski"
      ],
      "id": "dc466260",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjM2luKFSayr",
        "outputId": "6a54cf93-366c-40ac-823b-65c7b3a7697b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive"
      ],
      "id": "jjM2luKFSayr",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkcqxT8Eo-D2"
      },
      "source": [
        "Importing the data"
      ],
      "id": "FkcqxT8Eo-D2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6__FhQiuUag"
      },
      "source": [
        "pddata = pd.read_csv('GSM1586785_ScrH-12A_Exd_14mer_cg.csv.zip', compression='zip', error_bad_lines=False, skiprows=1)"
      ],
      "id": "z6__FhQiuUag",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Onini8BliWv"
      },
      "source": [
        "pddata = pddata.to_numpy()\n",
        "RelKa = pddata[:, -1]\n",
        "training_data = pddata[:, 2:-1]"
      ],
      "id": "7Onini8BliWv",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.kdeplot(RelKa, fill=True)\n",
        "plt.show()\n",
        "plt.savefig(\"RelKas.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Kv8aTKo2ZTmO",
        "outputId": "645d0da5-ed63-4e61-baaf-106d2eb9ccee"
      },
      "id": "Kv8aTKo2ZTmO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k3VzeutCXDe"
      },
      "source": [
        "Some helpers function for the analysis below"
      ],
      "id": "_k3VzeutCXDe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOBmnZCWDJEC"
      },
      "source": [
        "def drop_outliers(x, y, outliers):\n",
        "  x = np.delete(x, outliers, axis=0)\n",
        "  y = np.delete(y, outliers, axis=0)\n",
        "  return x, y"
      ],
      "id": "iOBmnZCWDJEC",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2AblynuDYKx"
      },
      "source": [
        "def split_RelKa(y, p):\n",
        "  return np.array([1 if value > p else 0 for value in y])"
      ],
      "id": "V2AblynuDYKx",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCehBG91D9S1"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def predict_with_Random_Forests(X_train, X_test, y_train, y_test):\n",
        "  clf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)  \n",
        "  return y_pred"
      ],
      "id": "LCehBG91D9S1",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGsyw7IyCpN7"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def return_accuracy(y_test, y_pred, verbose=1):\n",
        "  C = metrics.confusion_matrix(y_test, y_pred)\n",
        "  accuracy = np.trace(C) / len(y_test)\n",
        "  if verbose == 1:\n",
        "    print(\"The number of true negatives is:\", C[0, 0])\n",
        "    print(\"The number of false negatives is:\", C[1,0])\n",
        "    print(\"The number of false positives is:\", C[0,1])  \n",
        "    print(\"The number of true positives is:\", C[1,1])\n",
        "    print(\"The accuracy is:\", accuracy)\n",
        "    print(\"The accuracy on the 1's is \", 1 / np.sum(y_test == 1) * (np.sum(y_test == 1) - C[1, 0]))\n",
        "    print(\"The accuracy on the 0's is \", 1 / np.sum(y_test == 0) * (np.sum(y_test == 0) - C[0, 1]))\n",
        "  return accuracy"
      ],
      "id": "VGsyw7IyCpN7",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_VezXLPOxCd"
      },
      "source": [
        "def split_outliers(threshold, scores):\n",
        "  \"\"\"\n",
        "  As a consequence of the histogram below, we change the decision function \n",
        "  implemented in the isolation forests if the \n",
        "  Anomaly_Detection_Isolation_Forests function is told to do so\n",
        "  \"\"\"\n",
        "  outliers_indices = np.where(scores <= threshold)[0]\n",
        "  return outliers_indices"
      ],
      "id": "O_VezXLPOxCd",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1_1YDzeSwg_"
      },
      "source": [
        "import random\n",
        "\n",
        "def undersampling(X, y, ratios = np.array([0.1, 0.2, 0.2]), intervals = 0.2 * np.arange(0, 4)):\n",
        "  undersampled_training_data = np.zeros(training_data.shape[1])\n",
        "  undersampled_training_data = undersampled_training_data[..., np.newaxis].T\n",
        "  undersampled_RelKa = np.array([])\n",
        "  for i in range(len(intervals)-1):\n",
        "      indices = np.where(np.logical_and(intervals[i] <= RelKa, RelKa <= intervals[i+1]))[0]\n",
        "      sample_length = np.int(ratios[i]*len(indices))\n",
        "      random_picked = random.sample(list(np.arange(0, len(indices) + 1)), sample_length)\n",
        "      training_to_add = training_data[indices[0] + random_picked, :]\n",
        "      undersampled_training_data = np.concatenate([undersampled_training_data, training_to_add], axis=0)\n",
        "      RelKa_to_add = RelKa[indices[0] + random_picked]\n",
        "      undersampled_RelKa = np.concatenate([undersampled_RelKa, RelKa_to_add], axis=0)\n",
        "  critical_indices = np.where(RelKa >= 0.7)[0]\n",
        "  critical_RelKa = RelKa[critical_indices]\n",
        "  critical_samples = training_data[critical_indices, :]\n",
        "  undersampled_training_data = np.concatenate([undersampled_training_data, critical_samples], axis=0)\n",
        "  undersampled_RelKa = np.concatenate([undersampled_RelKa, critical_RelKa], axis=0)\n",
        "  undersampled_training_data = np.delete(undersampled_training_data, 0, axis=0)\n",
        "  return undersampled_training_data, undersampled_RelKa"
      ],
      "id": "M1_1YDzeSwg_",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def weighted_balance_average(y_true, y_pred):\n",
        "    ones_number = np.count_nonzero(y_true == 1.)\n",
        "    frequency_1 = ones_number / len(y_true)\n",
        "    frequency_0 = 1 - frequency_1\n",
        "    sum_inverse_frequencies = 1 / frequency_0 + 1 / frequency_1\n",
        "    weight_0 = 1 / (frequency_0 * sum_inverse_frequencies)\n",
        "    weight_1 = 1 / (frequency_1 * sum_inverse_frequencies)\n",
        "    C = metrics.confusion_matrix(y_true, y_pred)\n",
        "    return weight_0 * C[0, 0] / (C[0, 0] + C[0, 1]) + weight_1 * C[1, 1] / (C[1, 1] + C[1, 0])"
      ],
      "metadata": {
        "id": "9No2uLXpdZge"
      },
      "id": "9No2uLXpdZge",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def jaccard_score(y_true, y_pred):\n",
        "    C = metrics.confusion_matrix(y_true, y_pred)\n",
        "    return C[1, 1] / (C[1, 1] + C[1, 0] + C[0, 1])"
      ],
      "metadata": {
        "id": "Cx-n7wmHm3cy"
      },
      "id": "Cx-n7wmHm3cy",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxQsUtJxOGkA"
      },
      "source": [
        "WE FIRTS TRY TO DO A PREDICTION WITHOUT ANY OUTLIER REMOTION TO HAVE A COMPARISON"
      ],
      "id": "DxQsUtJxOGkA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL_SNdMdOMMT"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "RelKa_tilda = split_RelKa(RelKa, 0.7)\n",
        "indices = [i for i in range(len(training_data))]\n",
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(training_data, RelKa_tilda, indices, train_size=0.7, random_state=42)"
      ],
      "id": "qL_SNdMdOMMT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXWLj0eUOPil",
        "outputId": "ddb7e8bc-116e-4f59-d4a0-016ef213ab07"
      },
      "source": [
        "y_pred = predict_with_Random_Forests(X_train, X_test, y_train, y_test)\n",
        "accuracy = weighted_balance_average(y_test, y_pred)\n",
        "print(accuracy)"
      ],
      "id": "LXWLj0eUOPil",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8447460428034289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z07FC8x7PfIm"
      },
      "source": [
        "WE SEE THAT THE ACCURACY IS HIGH BUT WE ARE PREDICTING VERY POORLY THE CLASS 1"
      ],
      "id": "Z07FC8x7PfIm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV5aXOeq6mGI"
      },
      "source": [
        "ISOLATION FORESTS ANOMALY DETECTION"
      ],
      "id": "DV5aXOeq6mGI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec7aw0cE6rsV"
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def Anomaly_Detection_Isolation_Forests(x, change_split=True):\n",
        "  random_state = np.random.RandomState(42)\n",
        "  contamination = 'auto'\n",
        "  threshold = np.random.uniform(-0.03, -0.02, 1)\n",
        "  model = IsolationForest(n_estimators=120, max_samples='auto', contamination=contamination, random_state=random_state)\n",
        "  model.fit(x)\n",
        "  scores = model.decision_function(x)\n",
        "  if change_split == False:\n",
        "    anomaly_score = model.predict(x)\n",
        "    outliers_indices = np.where(anomaly_score == -1)[0]\n",
        "  if change_split == True:\n",
        "    outliers_indices = split_outliers(threshold, scores)\n",
        "  return contamination, scores, outliers_indices\n",
        "\n",
        "def check_Isolation_Forests(contamination, outliers_indices):\n",
        "  \"\"\"\n",
        "  Simply a check on the proper working of the IF algorithm\n",
        "  \"\"\"\n",
        "  tol = 1.0e-02\n",
        "  if contamination != 'auto':\n",
        "    outliers_percentage = 1 / len(RelKa) * len(outliers_indices)\n",
        "    assert np.abs(contamination-outliers_percentage) < tol\n",
        "\n",
        "def check_boundary_decision(scores, p, verbose=1):\n",
        "  \"\"\"\n",
        "  This function simply controls how many scores returned by the IF algorithm \n",
        "  are likely to be misclassified\n",
        "  \"\"\"\n",
        "  indecision_percentage = 1 / len(RelKa) * np.count_nonzero(np.abs(scores) <= p)\n",
        "  if verbose == 1:\n",
        "    plt.hist(scores)\n",
        "    plt.show()\n",
        "    print(\"The indecision percentage around\", p,  \"is\", indecision_percentage)\n",
        "    print(\"The percentage of outliers detected is\", 1 / len(scores) * len(np.where(scores < 0)[0]))"
      ],
      "id": "ec7aw0cE6rsV",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "T13n1dNv7ct7",
        "outputId": "cb5c4abb-6db2-4bb2-c07b-f696216911c7"
      },
      "source": [
        "contamination, scores, outliers_indices = Anomaly_Detection_Isolation_Forests(training_data, change_split=False)\n",
        "check_Isolation_Forests(contamination, outliers_indices)\n",
        "check_boundary_decision(scores, 0.02, verbose=1)"
      ],
      "id": "T13n1dNv7ct7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The indecision percentage around 0.02 is 0.5672001406964474\n",
            "The percentage of outliers detected is 0.10294290069175753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCG72D-4EhlD"
      },
      "source": [
        "training_data, RelKa = drop_outliers(training_data, RelKa, outliers_indices)\n",
        "RelKa_tilda = split_RelKa(RelKa, 0.7)"
      ],
      "id": "bCG72D-4EhlD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssEbARYX4S5-"
      },
      "source": [
        "indices = [i for i in range(len(training_data))]\n",
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(training_data, RelKa_tilda, indices, train_size=0.7, random_state=42)"
      ],
      "id": "ssEbARYX4S5-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nob2nvYFE3kj",
        "outputId": "7898e599-5dd3-4864-bc39-a484e0d42b50"
      },
      "source": [
        "y_pred = predict_with_Random_Forests(X_train, X_test, y_train, y_test)\n",
        "accuracy = return_accuracy(y_test, y_pred, verbose=1)"
      ],
      "id": "nob2nvYFE3kj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of true negatives is: 45799\n",
            "The number of false negatives is: 59\n",
            "The number of false positives is: 11\n",
            "The number of true positives is: 37\n",
            "The accuracy is: 0.9984751448612382\n",
            "The accuracy on the 1's is  0.38541666666666663\n",
            "The accuracy on the 0's is  0.9997598777559485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TyHT3NLfYy7"
      },
      "source": [
        "We see that we have a problem with a large number of false negatives, namely with incorrectly predictions of the negative class"
      ],
      "id": "4TyHT3NLfYy7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vAi22ydnFGR"
      },
      "source": [
        "# CROSS VALIDATION (5-FOLD) TO FINETUNE THE RF PARAMETERS"
      ],
      "id": "1vAi22ydnFGR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uySFlHwpoewE"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(training_data, RelKa_tilda, train_size=0.7, random_state=42)"
      ],
      "id": "uySFlHwpoewE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVKIvgRtnQZV"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 5)]\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf}"
      ],
      "id": "eVKIvgRtnQZV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiMsjYxCoBKC",
        "outputId": "72b8c6fb-2f5e-47ec-eb51-579310d72bc3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 3, cv = 5, scoring=make_scorer(weighted_balance_average), verbose=10)\n",
        "rf_random.fit(X_train, y_train)"
      ],
      "id": "DiMsjYxCoBKC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "[CV 1/5; 1/3] START min_samples_leaf=1, min_samples_split=5, n_estimators=200...\n",
            "[CV 1/5; 1/3] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.751 total time= 5.9min\n",
            "[CV 2/5; 1/3] START min_samples_leaf=1, min_samples_split=5, n_estimators=200...\n",
            "[CV 2/5; 1/3] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.941 total time= 5.5min\n",
            "[CV 3/5; 1/3] START min_samples_leaf=1, min_samples_split=5, n_estimators=200...\n",
            "[CV 3/5; 1/3] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.909 total time= 5.4min\n",
            "[CV 4/5; 1/3] START min_samples_leaf=1, min_samples_split=5, n_estimators=200...\n",
            "[CV 4/5; 1/3] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.737 total time= 5.2min\n",
            "[CV 5/5; 1/3] START min_samples_leaf=1, min_samples_split=5, n_estimators=200...\n",
            "[CV 5/5; 1/3] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=1.000 total time= 5.4min\n",
            "[CV 1/5; 2/3] START min_samples_leaf=2, min_samples_split=5, n_estimators=200...\n",
            "[CV 1/5; 2/3] END min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.715 total time= 5.6min\n",
            "[CV 2/5; 2/3] START min_samples_leaf=2, min_samples_split=5, n_estimators=200...\n",
            "[CV 2/5; 2/3] END min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.938 total time= 5.3min\n",
            "[CV 3/5; 2/3] START min_samples_leaf=2, min_samples_split=5, n_estimators=200...\n",
            "[CV 3/5; 2/3] END min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.857 total time= 5.3min\n",
            "[CV 4/5; 2/3] START min_samples_leaf=2, min_samples_split=5, n_estimators=200...\n",
            "[CV 4/5; 2/3] END min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.834 total time= 5.4min\n",
            "[CV 5/5; 2/3] START min_samples_leaf=2, min_samples_split=5, n_estimators=200...\n",
            "[CV 5/5; 2/3] END min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=1.000 total time= 5.4min\n",
            "[CV 1/5; 3/3] START min_samples_leaf=1, min_samples_split=2, n_estimators=200...\n",
            "[CV 1/5; 3/3] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.667 total time= 5.6min\n",
            "[CV 2/5; 3/3] START min_samples_leaf=1, min_samples_split=2, n_estimators=200...\n",
            "[CV 2/5; 3/3] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.933 total time= 5.4min\n",
            "[CV 3/5; 3/3] START min_samples_leaf=1, min_samples_split=2, n_estimators=200...\n",
            "[CV 3/5; 3/3] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.905 total time= 5.5min\n",
            "[CV 4/5; 3/3] START min_samples_leaf=1, min_samples_split=2, n_estimators=200...\n",
            "[CV 4/5; 3/3] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.778 total time= 5.7min\n",
            "[CV 5/5; 3/3] START min_samples_leaf=1, min_samples_split=2, n_estimators=200...\n",
            "[CV 5/5; 3/3] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=1.000 total time= 5.5min\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=3,\n",
              "                   param_distributions={'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [100, 125, 150, 175,\n",
              "                                                         200]},\n",
              "                   scoring=make_scorer(weighted_balance_average), verbose=10)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rf_random.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTpstojt80cn",
        "outputId": "05577788-3c87-40ac-85f0-70bae148acf0"
      },
      "id": "qTpstojt80cn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjUwQj2MFcvn",
        "outputId": "d95c21fa-4a80-433f-f910-39e0810954d8"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=200, min_samples_leaf=2, min_samples_split=5, criterion='entropy')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = return_accuracy(y_test, y_pred, verbose=1)"
      ],
      "id": "UjUwQj2MFcvn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of true negatives is: 45799\n",
            "The number of false negatives is: 60\n",
            "The number of false positives is: 11\n",
            "The number of true positives is: 36\n",
            "The accuracy is: 0.9984533612163987\n",
            "The accuracy on the 1's is  0.375\n",
            "The accuracy on the 0's is  0.9997598777559485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gEP6-_0DGAv"
      },
      "source": [
        "WE TRY PERFORMING K-MEANS CLUSTERING FIRST"
      ],
      "id": "3gEP6-_0DGAv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_3R8ZKODJeo"
      },
      "source": [
        "max_iters = 5\n",
        "threshold = 1.0e-02\n",
        "k = 5\n",
        "indices = np.where(RelKa <= 0.2)[0]\n",
        "redundant_training_data = training_data[indices, :]\n",
        "redundant_RelKa = RelKa[indices]\n",
        "\n",
        "average_loss, assignments = kmeans(redundant_training_data, k, max_iters, threshold)"
      ],
      "id": "s_3R8ZKODJeo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjwfhAHFDNVe"
      },
      "source": [
        "import random\n",
        "\n",
        "clustered_data = np.zeros(training_data.shape[1])\n",
        "clustered_data = clustered_data[..., np.newaxis].T\n",
        "clustered_RelKa = np.array([])\n",
        "for i in range(k):\n",
        "    # collect random_size casual samples from the i-th cluster\n",
        "    assigned_indices = np.where(assignments == i)[0]\n",
        "    # taking the samples and RelKa assigned to the i-th cluster\n",
        "    assigned_data = redundant_training_data[assigned_indices, :]\n",
        "    assigned_RelKa = redundant_RelKa[assigned_indices]\n",
        "    # taking a random subsample\n",
        "    random_picked = random.sample(list(np.arange(0, len(assigned_indices))), np.int(1/10 * len(assigned_indices)))\n",
        "    data_to_add = assigned_data[random_picked, :]\n",
        "    RelKa_to_add = assigned_RelKa[random_picked]\n",
        "    # concatenate the subsample to the old clustered_data and clustered_RelKa\n",
        "    clustered_data = np.concatenate([clustered_data, data_to_add])\n",
        "    clustered_RelKa = np.concatenate([clustered_RelKa, RelKa_to_add])\n",
        "# we delete the first row which was just for initialization\n",
        "clustered_data = np.delete(clustered_data, 0, axis = 0)"
      ],
      "id": "ZjwfhAHFDNVe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlqyar0mDQi4"
      },
      "source": [
        "# adding all the other samples (which represent less than 20% of the original dataset)\n",
        "indices = np.where(RelKa > 0.2)[0]\n",
        "clustered_data = np.concatenate([clustered_data, training_data[indices, :]])\n",
        "clustered_RelKa = np.concatenate([clustered_RelKa, RelKa[indices]])"
      ],
      "id": "Vlqyar0mDQi4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIVhN0vKDSlk"
      },
      "source": [
        "clustered_RelKa = split_RelKa(clustered_RelKa, 0.6)\n",
        "clustered_data = standardize(clustered_data)"
      ],
      "id": "zIVhN0vKDSlk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfZQH0vqDSo-"
      },
      "source": [
        "clustered_X_train, clustered_X_test, clustered_y_train, clustered_y_test = train_test_split(clustered_data, clustered_RelKa, train_size=0.7, random_state=42)\n",
        "clustered_y_pred = predict_with_Random_Forests(clustered_X_train, clustered_X_test, clustered_y_train, clustered_y_test)\n",
        "return_accuracy(clustered_y_test, clustered_y_pred, verbose=1)"
      ],
      "id": "BfZQH0vqDSo-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNDERSAMPLING AND OVERSAMPLING CROSS-VALIDATION TECHNIQUE"
      ],
      "metadata": {
        "id": "CBVNLwih0f-j"
      },
      "id": "CBVNLwih0f-j"
    },
    {
      "cell_type": "code",
      "source": [
        "def split_importance(x, y, importance_class=0.7):\n",
        "  \"\"\"\n",
        "  Split the samples into interesting ones and not interesting ones\n",
        "  :param x: numpy.ndarray:the feature vector of the initial dataset\n",
        "  :param y: numpy.ndarray: the value vector of the initial dataset\n",
        "  :param importance_class: float: the lower bound for the underepresented class\n",
        "  \"\"\"\n",
        "  return x[y >= importance_class], y[y >= importance_class], x[y < importance_class], y[y < importance_class]"
      ],
      "metadata": {
        "id": "d8eYszg3n53z"
      },
      "id": "d8eYszg3n53z",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_1, y_1, x_0, y_0 = split_importance(training_data, RelKa)"
      ],
      "metadata": {
        "id": "UuXU1lLfoAy1"
      },
      "id": "UuXU1lLfoAy1",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the two classes seperately into train and test set to ensure representation of the minority class\n",
        "# both in the test set and in the train set\n",
        "x_1_train, x_1_test, y_1_train, y_1_test = train_test_split(x_1, y_1, test_size=0.4, random_state=42)\n",
        "x_0_train, x_0_test, y_0_train, y_0_test = train_test_split(x_0, y_0, test_size=0.4, random_state=42)\n",
        "\n",
        "x_train = np.concatenate((x_1_train, x_0_train))\n",
        "y_train = np.concatenate((y_1_train, y_0_train))\n",
        "x_test = np.concatenate((x_1_test, x_0_test))\n",
        "y_test = np.concatenate((y_1_test, y_0_test))"
      ],
      "metadata": {
        "id": "wnZYvVZuoEXN"
      },
      "id": "wnZYvVZuoEXN",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "vO7-bhBsoMWO"
      },
      "id": "vO7-bhBsoMWO",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = split_RelKa(y_train, 0.7)\n",
        "y_test = split_RelKa(y_test, 0.7)"
      ],
      "metadata": {
        "id": "l7n7FedHrOpn"
      },
      "id": "l7n7FedHrOpn",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Fisher_Score(x_import, x_nimport):\n",
        "  \"\"\"\n",
        "  Given two arrays of two classes this function calculates the Fischer_scores to \n",
        "  measure the significance for all features\n",
        "  :param x_import: numpy.ndarray: the array containing the samples of one class\n",
        "  :param x_nimport: numpy.ndarray: the array containing the samples of the other class\n",
        "  :return: numpy.ndarray: returns an array containg the Fisher_Score for all features \n",
        "  \"\"\"\n",
        "  mean_import = np.mean(x_import,axis = 0)\n",
        "  mean_nimport = np.mean(x_nimport,axis = 0)\n",
        "  mean_dist = np.absolute(mean_import-mean_nimport)\n",
        "  std_import = np.std(x_import,axis=0)\n",
        "  std_nimport = np.std(x_nimport,axis=0)\n",
        "  std_sum = std_import+std_nimport\n",
        "  #return std_sum\n",
        "  return np.divide(mean_dist,std_sum)\n",
        "\n",
        "def calculate_distances(x, distance):\n",
        "  \"\"\"\n",
        "  Calculates the distance between any two pairs of the set x using \n",
        "  the Minkowski distance of degree distance.\n",
        "  :param x: numpy.ndarray: the vector for which we will calculate the distance \n",
        "                            between all of its elements \n",
        "  :param distance: float: the norm which should be used for the Minkowski distance\n",
        "  :return: numpy.ndarray: returns the Minkowski distance with the specified norm \n",
        "                          between all pairs of elements in x \n",
        "  \"\"\"\n",
        "  dist = np.array([[minkowski(a1,a2,distance) for a2 in x] for a1 in x])\n",
        "  np.fill_diagonal(dist,float('inf'))\n",
        "  return dist\n",
        "\n",
        "def random_sampler(x, y, randomsize):\n",
        "  \"\"\"\n",
        "  This function does random undersampling of vectors x,y and reduces them to \n",
        "  size random size\n",
        "  :param x: numpy.ndarray: the feature vector to be subsampled\n",
        "  :param y: numpy.ndarray: the label vector to be subsampled\n",
        "  :return: <class 'tuple'>: A tuple containing the two undersampled vectors\n",
        "  \"\"\"\n",
        "  p = np.random.permutation(len(y))\n",
        "  new_x = x[p]\n",
        "  new_y = y[p]\n",
        "  return new_x[:randomsize],new_y[:randomsize]\n",
        "\n",
        "def generate_samples(x, y, neighbors, N):\n",
        "  \"\"\"\n",
        "  This function generate N samples which are convex combinations of \n",
        "  the features of x and the labels of y\n",
        "  :param x: numpy.ndarray:\n",
        "  :param y: numpy.ndarray:\n",
        "  :return: <class 'tuple'>:\n",
        "  \"\"\"\n",
        "  new_samples_x = []\n",
        "  new_samples_y = []\n",
        "  for i in range(N):\n",
        "    random_sample_i = random.randint(0,y.shape[0]-1)\n",
        "    x_i = x[random_sample_i]\n",
        "    random_sample_j = random.randint(0,neighbors.shape[1]-1)\n",
        "    neigh_i = neighbors[random_sample_i,random_sample_j]\n",
        "    x_j = x[neigh_i]\n",
        "    lambda_ = random.uniform(0,1)\n",
        "    y_i = y[random_sample_i]\n",
        "    y_j = y[neigh_i]\n",
        "    new_x = x_i + lambda_*(x_j-x_i)\n",
        "    new_y = y_i + lambda_*(y_j-y_i)\n",
        "    new_samples_x.append(new_x)\n",
        "    new_samples_y.append(new_y)\n",
        "  return np.array(new_samples_x),np.array(new_samples_y)\n",
        "\n",
        "def random_sampler(x,y,randomsize):\n",
        "  \"\"\"\n",
        "  This function does random undersampling of vectors x,y and reduces them to \n",
        "  size random size\n",
        "  :param x: numpy.ndarray: the feature vector to be subsampled\n",
        "  :param y: numpy.ndarray: the label vector to be subsampled\n",
        "  :return: <class 'tuple'>: A tuple containing the two undersampled vectors\n",
        "  \"\"\"\n",
        "  p = np.random.permutation(len(y))\n",
        "  new_x = x[p]\n",
        "  new_y = y[p]\n",
        "  return new_x[:randomsize],new_y[:randomsize]\n",
        "\n",
        "def generate_samples(x,y,neighbors,N):\n",
        "  \"\"\"\n",
        "  This function generate N samples which are convex combinations of \n",
        "  the features of x and the labels of y\n",
        "  :param x: numpy.ndarray:\n",
        "  :param y: numpy.ndarray:\n",
        "  :return: <class 'tuple'>:\n",
        "  \"\"\"\n",
        "  new_samples_x = []\n",
        "  new_samples_y = []\n",
        "  for i in range(N):\n",
        "    random_sample_i = random.randint(0,y.shape[0]-1)\n",
        "    x_i = x[random_sample_i]\n",
        "    random_sample_j = random.randint(0,neighbors.shape[1]-1)\n",
        "    neigh_i = neighbors[random_sample_i,random_sample_j]\n",
        "    x_j = x[neigh_i]\n",
        "    lambda_ = random.uniform(0,1)\n",
        "    y_i = y[random_sample_i]\n",
        "    y_j = y[neigh_i]\n",
        "    new_x = x_i + lambda_*(x_j-x_i)\n",
        "    new_y = y_i + lambda_*(y_j-y_i)\n",
        "    new_samples_x.append(new_x)\n",
        "    new_samples_y.append(new_y)\n",
        "  return np.array(new_samples_x),np.array(new_samples_y)\n",
        "\n",
        "def smote_sf(x, y, undersample=0.5, oversample = 0.1, attribute_scorer=Fisher_Score, \n",
        "             attribute_number = 10, distance = float('inf'), kneighbors = 3,\n",
        "             undersampling = random_sampler, importance_class = 0.7):\n",
        "  \"\"\"\n",
        "  This function takes the complete input and produces a more balanced dataset based on the importance class\n",
        "  :param x: numpy.ndarray: the feature vector of the initial dataset\n",
        "  :param y: numpy.ndarray: the value vector of the initial dataset\n",
        "  :param undersample: float: the percentage of the dominant class that we want to keep\n",
        "  :param oversample: float: the percentage of the dataset that the small class will be at the end\n",
        "  :param attribute_scorer: function: a function which will be used to score the relevance of a feature\n",
        "  :param attribute_number: int: the number of attributes to keep according to their score\n",
        "  :param distance: float: the norm which should be used for the Minkowski distance\n",
        "  :param kneighbors: int: the number of samples which should be considered for each point \n",
        "  :param undersampling: function: the function to use for the undersampling of the majority class\n",
        "  :param importance_class: float: the lower bound for the underepresented class\n",
        "  :return: returns 2 new feature vectors and 2 new label vectors containing \n",
        "            the data for the importance class and the data for the non importance \n",
        "            class and their labels. \n",
        "  \"\"\"\n",
        "  x_import = x[y>=importance_class]\n",
        "  y_import = y[y>=importance_class]\n",
        "  x_nimport = x[y<importance_class]\n",
        "  y_nimport = y[y<importance_class]\n",
        "\n",
        "  feature_scores =  attribute_scorer(x_import,x_nimport)\n",
        "  #find the attribute_number highest coordinates of the feature_scores vector\n",
        "  indices = np.sort((-feature_scores).argsort()[:attribute_number])\n",
        "  x_import_filtered = x_import[:,indices]\n",
        "  #x_nimport = x_nimport[:,indices]\n",
        "  distances = calculate_distances(x_import_filtered,distance)\n",
        "  #find the k lowest indices\n",
        "  neighbors = np.array([ np.sort(d.argsort()[:(kneighbors)]) for d in distances])\n",
        "  #undersampling for the majority class\n",
        "  nimport_len = int(undersample*y_nimport.shape[0])\n",
        "  x_nimport,y_nimport = undersampling(x_nimport,y_nimport,nimport_len)\n",
        "  #Calculate the number of samples to be generated\n",
        "  N = int(oversample*(y_nimport.shape[0]) - y_import.shape[0])\n",
        "  #Generate N new samples\n",
        "  new_samples_x,new_samples_y = generate_samples(x_import, y_import, neighbors, N)\n",
        "  #merge the new samples of the minority class with its old samples\n",
        "  x_import = np.concatenate((x_import,new_samples_x))\n",
        "  y_import = np.concatenate((y_import,new_samples_y))\n",
        "\n",
        "  x_ret = np.concatenate((x_import, x_nimport))\n",
        "  y_ret = np.concatenate((y_import,y_nimport))\n",
        "  return x_ret, y_ret"
      ],
      "metadata": {
        "id": "uJq6YmmPoTM1"
      },
      "id": "uJq6YmmPoTM1",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = smote_sf(x_train, y_train, undersample=0.1, oversample=0.3, kneighbors=5)"
      ],
      "metadata": {
        "id": "4c4WT7AvpFRs"
      },
      "id": "4c4WT7AvpFRs",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 10)]\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf}"
      ],
      "metadata": {
        "id": "c-MTe2swpzDW"
      },
      "id": "c-MTe2swpzDW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 10, scoring=make_scorer(weighted_balance_average), verbose=10)\n",
        "rf_random.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy-76IRup2qQ",
        "outputId": "36c8f3d2-f268-499f-cd0e-125566ecc602"
      },
      "id": "hy-76IRup2qQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
            "[CV 1/10; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=188.\n",
            "[CV 1/10; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=188;, score=0.991 total time=  25.1s\n",
            "[CV 2/10; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=188.\n",
            "[CV 2/10; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=188;, score=0.982 total time=  24.5s\n",
            "[CV 3/10; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=188.\n",
            "[CV 3/10; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=188;, score=0.999 total time=  24.2s\n",
            "[CV 4/10; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=188.\n",
            "[CV 4/10; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=188;, score=0.988 total time=  23.9s\n",
            "[CV 5/10; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=188.\n",
            "[CV 5/10; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=188;, score=0.983 total time=  23.7s\n",
            "[CV 6/10; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=188.\n",
            "[CV 6/10; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=188;, score=0.986 total time=  24.4s\n",
            "[CV 7/10; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=188.\n",
            "[CV 7/10; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=188;, score=0.977 total time=  25.2s\n",
            "[CV 8/10; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=188.\n",
            "[CV 8/10; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=188;, score=0.996 total time=  24.7s\n",
            "[CV 9/10; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=188.\n",
            "[CV 9/10; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=188;, score=0.996 total time=  24.4s\n",
            "[CV 10/10; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=188\n",
            "[CV 10/10; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=188;, score=0.986 total time=  24.3s\n",
            "[CV 1/10; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=122.\n",
            "[CV 1/10; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=122;, score=0.991 total time=  16.1s\n",
            "[CV 2/10; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=122.\n",
            "[CV 2/10; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=122;, score=0.985 total time=  15.9s\n",
            "[CV 3/10; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=122.\n",
            "[CV 3/10; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=122;, score=0.997 total time=  16.2s\n",
            "[CV 4/10; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=122.\n",
            "[CV 4/10; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=122;, score=0.988 total time=  15.9s\n",
            "[CV 5/10; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=122.\n",
            "[CV 5/10; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=122;, score=0.991 total time=  16.1s\n",
            "[CV 6/10; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=122.\n",
            "[CV 6/10; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=122;, score=0.991 total time=  16.1s\n",
            "[CV 7/10; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=122.\n",
            "[CV 7/10; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=122;, score=0.980 total time=  15.8s\n",
            "[CV 8/10; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=122.\n",
            "[CV 8/10; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=122;, score=0.991 total time=  15.9s\n",
            "[CV 9/10; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=122.\n",
            "[CV 9/10; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=122;, score=1.000 total time=  16.4s\n",
            "[CV 10/10; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=122\n",
            "[CV 10/10; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=122;, score=0.986 total time=  16.1s\n",
            "[CV 1/10; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200.\n",
            "[CV 1/10; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.991 total time=  26.3s\n",
            "[CV 2/10; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200.\n",
            "[CV 2/10; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.985 total time=  26.2s\n",
            "[CV 3/10; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200.\n",
            "[CV 3/10; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=1.000 total time=  25.9s\n",
            "[CV 4/10; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200.\n",
            "[CV 4/10; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.988 total time=  25.6s\n",
            "[CV 5/10; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200.\n",
            "[CV 5/10; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.988 total time=  26.0s\n",
            "[CV 6/10; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200.\n",
            "[CV 6/10; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.991 total time=  26.3s\n",
            "[CV 7/10; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200.\n",
            "[CV 7/10; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.975 total time=  26.3s\n",
            "[CV 8/10; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200.\n",
            "[CV 8/10; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.991 total time=  26.1s\n",
            "[CV 9/10; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200.\n",
            "[CV 9/10; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=1.000 total time=  25.9s\n",
            "[CV 10/10; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200\n",
            "[CV 10/10; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.986 total time=  25.7s\n",
            "[CV 1/10; 4/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 1/10; 4/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.988 total time=  19.9s\n",
            "[CV 2/10; 4/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 2/10; 4/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.977 total time=  19.6s\n",
            "[CV 3/10; 4/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 3/10; 4/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.999 total time=  19.8s\n",
            "[CV 4/10; 4/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 4/10; 4/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.988 total time=  19.4s\n",
            "[CV 5/10; 4/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 5/10; 4/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.983 total time=  19.7s\n",
            "[CV 6/10; 4/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 6/10; 4/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.988 total time=  19.5s\n",
            "[CV 7/10; 4/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 7/10; 4/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.975 total time=  19.4s\n",
            "[CV 8/10; 4/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 8/10; 4/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.994 total time=  19.8s\n",
            "[CV 9/10; 4/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 9/10; 4/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.999 total time=  19.8s\n",
            "[CV 10/10; 4/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 10/10; 4/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.985 total time=  19.5s\n",
            "[CV 1/10; 5/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 1/10; 5/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.991 total time=  21.3s\n",
            "[CV 2/10; 5/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 2/10; 5/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.982 total time=  20.7s\n",
            "[CV 3/10; 5/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 3/10; 5/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.999 total time=  21.7s\n",
            "[CV 4/10; 5/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 4/10; 5/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.988 total time=  21.3s\n",
            "[CV 5/10; 5/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 5/10; 5/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.988 total time=  21.5s\n",
            "[CV 6/10; 5/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 6/10; 5/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.991 total time=  21.5s\n",
            "[CV 7/10; 5/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 7/10; 5/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.977 total time=  21.1s\n",
            "[CV 8/10; 5/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 8/10; 5/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.997 total time=  21.4s\n",
            "[CV 9/10; 5/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 9/10; 5/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.996 total time=  21.5s\n",
            "[CV 10/10; 5/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166\n",
            "[CV 10/10; 5/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.986 total time=  21.4s\n",
            "[CV 1/10; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200\n",
            "[CV 1/10; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.991 total time=  25.5s\n",
            "[CV 2/10; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200\n",
            "[CV 2/10; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.985 total time=  25.7s\n",
            "[CV 3/10; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200\n",
            "[CV 3/10; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.999 total time=  26.1s\n",
            "[CV 4/10; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200\n",
            "[CV 4/10; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.988 total time=  25.7s\n",
            "[CV 5/10; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200\n",
            "[CV 5/10; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.988 total time=  26.0s\n",
            "[CV 6/10; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200\n",
            "[CV 6/10; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.991 total time=  26.3s\n",
            "[CV 7/10; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200\n",
            "[CV 7/10; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.977 total time=  26.6s\n",
            "[CV 8/10; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200\n",
            "[CV 8/10; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.994 total time=  25.9s\n",
            "[CV 9/10; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200\n",
            "[CV 9/10; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.999 total time=  26.1s\n",
            "[CV 10/10; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200\n",
            "[CV 10/10; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.986 total time=  26.4s\n",
            "[CV 1/10; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=111.\n",
            "[CV 1/10; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=111;, score=0.992 total time=  14.5s\n",
            "[CV 2/10; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=111.\n",
            "[CV 2/10; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=111;, score=0.985 total time=  14.4s\n",
            "[CV 3/10; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=111.\n",
            "[CV 3/10; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=111;, score=1.000 total time=  15.1s\n",
            "[CV 4/10; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=111.\n",
            "[CV 4/10; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=111;, score=0.988 total time=  14.5s\n",
            "[CV 5/10; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=111.\n",
            "[CV 5/10; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=111;, score=0.988 total time=  14.7s\n",
            "[CV 6/10; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=111.\n",
            "[CV 6/10; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=111;, score=0.994 total time=  15.0s\n",
            "[CV 7/10; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=111.\n",
            "[CV 7/10; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=111;, score=0.978 total time=  15.1s\n",
            "[CV 8/10; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=111.\n",
            "[CV 8/10; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=111;, score=0.997 total time=  15.4s\n",
            "[CV 9/10; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=111.\n",
            "[CV 9/10; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=111;, score=1.000 total time=  15.2s\n",
            "[CV 10/10; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=111\n",
            "[CV 10/10; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=111;, score=0.986 total time=  15.2s\n",
            "[CV 1/10; 8/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 1/10; 8/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.994 total time=  15.8s\n",
            "[CV 2/10; 8/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 2/10; 8/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.980 total time=  15.5s\n",
            "[CV 3/10; 8/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 3/10; 8/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.999 total time=  16.1s\n",
            "[CV 4/10; 8/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 4/10; 8/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.988 total time=  15.7s\n",
            "[CV 5/10; 8/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 5/10; 8/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.983 total time=  15.9s\n",
            "[CV 6/10; 8/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 6/10; 8/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.988 total time=  16.4s\n",
            "[CV 7/10; 8/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 7/10; 8/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.977 total time=  16.3s\n",
            "[CV 8/10; 8/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 8/10; 8/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.988 total time=  16.3s\n",
            "[CV 9/10; 8/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 9/10; 8/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.996 total time=  16.7s\n",
            "[CV 10/10; 8/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122\n",
            "[CV 10/10; 8/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.983 total time=  16.5s\n",
            "[CV 1/10; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=144.\n",
            "[CV 1/10; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=144;, score=0.989 total time=  18.9s\n",
            "[CV 2/10; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=144.\n",
            "[CV 2/10; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=144;, score=0.988 total time=  19.3s\n",
            "[CV 3/10; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=144.\n",
            "[CV 3/10; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=144;, score=0.999 total time=  19.6s\n",
            "[CV 4/10; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=144.\n",
            "[CV 4/10; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=144;, score=0.988 total time=  19.0s\n",
            "[CV 5/10; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=144.\n",
            "[CV 5/10; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=144;, score=0.988 total time=  19.0s\n",
            "[CV 6/10; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=144.\n",
            "[CV 6/10; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=144;, score=0.991 total time=  18.8s\n",
            "[CV 7/10; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=144.\n",
            "[CV 7/10; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=144;, score=0.980 total time=  19.3s\n",
            "[CV 8/10; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=144.\n",
            "[CV 8/10; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=144;, score=0.996 total time=  19.4s\n",
            "[CV 9/10; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=144.\n",
            "[CV 9/10; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=144;, score=1.000 total time=  19.4s\n",
            "[CV 10/10; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=144\n",
            "[CV 10/10; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=144;, score=0.985 total time=  19.1s\n",
            "[CV 1/10; 10/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=188\n",
            "[CV 1/10; 10/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=188;, score=0.991 total time=  25.2s\n",
            "[CV 2/10; 10/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=188\n",
            "[CV 2/10; 10/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=188;, score=0.980 total time=  24.5s\n",
            "[CV 3/10; 10/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=188\n",
            "[CV 3/10; 10/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=188;, score=0.999 total time=  24.5s\n",
            "[CV 4/10; 10/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=188\n",
            "[CV 4/10; 10/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=188;, score=0.988 total time=  24.5s\n",
            "[CV 5/10; 10/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=188\n",
            "[CV 5/10; 10/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=188;, score=0.983 total time=  24.6s\n",
            "[CV 6/10; 10/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=188\n",
            "[CV 6/10; 10/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=188;, score=0.988 total time=  25.3s\n",
            "[CV 7/10; 10/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=188\n",
            "[CV 7/10; 10/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=188;, score=0.980 total time=  24.8s\n",
            "[CV 8/10; 10/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=188\n",
            "[CV 8/10; 10/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=188;, score=0.996 total time=  25.3s\n",
            "[CV 9/10; 10/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=188\n",
            "[CV 9/10; 10/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=188;, score=0.999 total time=  25.5s\n",
            "[CV 10/10; 10/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=188\n",
            "[CV 10/10; 10/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=188;, score=0.985 total time=  24.8s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, estimator=RandomForestClassifier(),\n",
              "                   param_distributions={'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [100, 111, 122, 133,\n",
              "                                                         144, 155, 166, 177,\n",
              "                                                         188, 200]},\n",
              "                   scoring=make_scorer(weighted_balance_average), verbose=10)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rf_random.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIVRmwfBr36T",
        "outputId": "2576e12d-af38-4b56-f1e2-83220c242cd3"
      },
      "id": "NIVRmwfBr36T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 111, 'min_samples_split': 2, 'min_samples_leaf': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = 111, min_samples_split = 2, min_samples_leaf = 1)\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "return_accuracy(y_test, y_pred, verbose=1)\n",
        "metrics.plot_confusion_matrix(clf, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "SxCPGlQVr7Od",
        "outputId": "3fc1e62d-cdb4-4431-f3e7-83f7abf07d16"
      },
      "id": "SxCPGlQVr7Od",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of true negatives is: 67867\n",
            "The number of false negatives is: 21\n",
            "The number of false positives is: 235\n",
            "The number of true positives is: 109\n",
            "The accuracy is: 0.9962480947356079\n",
            "The accuracy on the 1's is  0.8384615384615385\n",
            "The accuracy on the 0's is  0.996549293706499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f706987ac90>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOOKING FOR OUTLIERS IN THE BALANCED DATASETAND RETUNING THE PARAMETERS"
      ],
      "metadata": {
        "id": "RnJmX6d79LaR"
      },
      "id": "RnJmX6d79LaR"
    },
    {
      "cell_type": "code",
      "source": [
        "x_1, y_1, x_0, y_0 = split_importance(training_data, RelKa)"
      ],
      "metadata": {
        "id": "TViDApw2D7No"
      },
      "id": "TViDApw2D7No",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the two classes seperately into train and test set to ensure representation of the minority class\n",
        "# both in the test set and in the train set\n",
        "x_1_train, x_1_test, y_1_train, y_1_test = train_test_split(x_1, y_1, test_size=0.4, random_state=42)\n",
        "x_0_train, x_0_test, y_0_train, y_0_test = train_test_split(x_0, y_0, test_size=0.4, random_state=42)\n",
        "\n",
        "x_train = np.concatenate((x_1_train, x_0_train))\n",
        "y_train = np.concatenate((y_1_train, y_0_train))\n",
        "x_test = np.concatenate((x_1_test, x_0_test))\n",
        "y_test = np.concatenate((y_1_test, y_0_test))"
      ],
      "metadata": {
        "id": "OKqWKO0AEDWN"
      },
      "id": "OKqWKO0AEDWN",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contamination, scores, outliers_indices = Anomaly_Detection_Isolation_Forests(x_train, change_split=False)\n",
        "check_Isolation_Forests(contamination, outliers_indices)\n",
        "check_boundary_decision(scores, 0.02, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "HCZIu9xH9RF0",
        "outputId": "a5ad1b9a-2b36-43b7-d390-1cadc2a2e51e"
      },
      "id": "HCZIu9xH9RF0",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The indecision percentage around 0.02 is 0.37014890374018056\n",
            "The percentage of outliers detected is 0.1110134052448509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = drop_outliers(x_train, y_train, outliers_indices)"
      ],
      "metadata": {
        "id": "DKjma3Yo9jxD"
      },
      "execution_count": 31,
      "outputs": [],
      "id": "DKjma3Yo9jxD"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "emMqBe5hEHGt"
      },
      "id": "emMqBe5hEHGt",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = split_RelKa(y_train, 0.7)\n",
        "y_test = split_RelKa(y_test, 0.7)"
      ],
      "metadata": {
        "id": "m-HxeaP_ELtj"
      },
      "execution_count": 33,
      "outputs": [],
      "id": "m-HxeaP_ELtj"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = smote_sf(x_train, y_train, undersample=0.1, oversample=0.3, kneighbors=5)"
      ],
      "metadata": {
        "id": "qCMojIRp9PiQ"
      },
      "execution_count": 34,
      "outputs": [],
      "id": "qCMojIRp9PiQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 10)]\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf}"
      ],
      "metadata": {
        "id": "RQtc0nhC9nCX"
      },
      "execution_count": null,
      "outputs": [],
      "id": "RQtc0nhC9nCX"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 10, scoring=make_scorer(weighted_balance_average), verbose=10)\n",
        "rf_random.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea8a855-51a5-40b3-c4ae-ae5284ad7618",
        "id": "5wYVs4DS9qUF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
            "[CV 1/10; 1/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200.\n",
            "[CV 1/10; 1/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.977 total time=  24.7s\n",
            "[CV 2/10; 1/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200.\n",
            "[CV 2/10; 1/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.985 total time=  24.7s\n",
            "[CV 3/10; 1/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200.\n",
            "[CV 3/10; 1/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.996 total time=  25.1s\n",
            "[CV 4/10; 1/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200.\n",
            "[CV 4/10; 1/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.991 total time=  25.0s\n",
            "[CV 5/10; 1/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200.\n",
            "[CV 5/10; 1/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.993 total time=  24.6s\n",
            "[CV 6/10; 1/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200.\n",
            "[CV 6/10; 1/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.996 total time=  24.8s\n",
            "[CV 7/10; 1/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200.\n",
            "[CV 7/10; 1/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.999 total time=  25.4s\n",
            "[CV 8/10; 1/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200.\n",
            "[CV 8/10; 1/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.982 total time=  25.1s\n",
            "[CV 9/10; 1/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200.\n",
            "[CV 9/10; 1/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.991 total time=  24.7s\n",
            "[CV 10/10; 1/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200\n",
            "[CV 10/10; 1/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.994 total time=  24.8s\n",
            "[CV 1/10; 2/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=122.\n",
            "[CV 1/10; 2/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=122;, score=0.978 total time=  14.9s\n",
            "[CV 2/10; 2/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=122.\n",
            "[CV 2/10; 2/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=122;, score=0.988 total time=  15.0s\n",
            "[CV 3/10; 2/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=122.\n",
            "[CV 3/10; 2/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=122;, score=0.996 total time=  15.4s\n",
            "[CV 4/10; 2/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=122.\n",
            "[CV 4/10; 2/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=122;, score=0.990 total time=  15.1s\n",
            "[CV 5/10; 2/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=122.\n",
            "[CV 5/10; 2/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=122;, score=0.993 total time=  15.1s\n",
            "[CV 6/10; 2/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=122.\n",
            "[CV 6/10; 2/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=122;, score=0.997 total time=  15.3s\n",
            "[CV 7/10; 2/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=122.\n",
            "[CV 7/10; 2/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=122;, score=0.999 total time=  14.9s\n",
            "[CV 8/10; 2/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=122.\n",
            "[CV 8/10; 2/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=122;, score=0.982 total time=  15.0s\n",
            "[CV 9/10; 2/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=122.\n",
            "[CV 9/10; 2/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=122;, score=0.991 total time=  15.1s\n",
            "[CV 10/10; 2/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=122\n",
            "[CV 10/10; 2/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=122;, score=0.993 total time=  15.1s\n",
            "[CV 1/10; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 1/10; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.977 total time=  18.5s\n",
            "[CV 2/10; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 2/10; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.988 total time=  19.2s\n",
            "[CV 3/10; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 3/10; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.995 total time=  18.8s\n",
            "[CV 4/10; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 4/10; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.987 total time=  19.0s\n",
            "[CV 5/10; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 5/10; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.996 total time=  19.0s\n",
            "[CV 6/10; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 6/10; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.997 total time=  18.8s\n",
            "[CV 7/10; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 7/10; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.999 total time=  18.7s\n",
            "[CV 8/10; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 8/10; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.982 total time=  18.9s\n",
            "[CV 9/10; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 9/10; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.991 total time=  18.6s\n",
            "[CV 10/10; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=155\n",
            "[CV 10/10; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=155;, score=0.996 total time=  18.8s\n",
            "[CV 1/10; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 1/10; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.980 total time=  14.8s\n",
            "[CV 2/10; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 2/10; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.988 total time=  15.0s\n",
            "[CV 3/10; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 3/10; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.996 total time=  14.9s\n",
            "[CV 4/10; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 4/10; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.990 total time=  15.0s\n",
            "[CV 5/10; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 5/10; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.993 total time=  14.9s\n",
            "[CV 6/10; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 6/10; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.996 total time=  14.9s\n",
            "[CV 7/10; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 7/10; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.999 total time=  15.1s\n",
            "[CV 8/10; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 8/10; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.985 total time=  14.7s\n",
            "[CV 9/10; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122.\n",
            "[CV 9/10; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.991 total time=  15.0s\n",
            "[CV 10/10; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=122\n",
            "[CV 10/10; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=122;, score=0.996 total time=  15.0s\n",
            "[CV 1/10; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=166\n",
            "[CV 1/10; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=166;, score=0.981 total time=  20.2s\n",
            "[CV 2/10; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=166\n",
            "[CV 2/10; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=166;, score=0.988 total time=  20.8s\n",
            "[CV 3/10; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=166\n",
            "[CV 3/10; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=166;, score=0.996 total time=  21.0s\n",
            "[CV 4/10; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=166\n",
            "[CV 4/10; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=166;, score=0.990 total time=  21.2s\n",
            "[CV 5/10; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=166\n",
            "[CV 5/10; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=166;, score=0.993 total time=  20.3s\n",
            "[CV 6/10; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=166\n",
            "[CV 6/10; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=166;, score=0.996 total time=  20.7s\n",
            "[CV 7/10; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=166\n",
            "[CV 7/10; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=166;, score=0.999 total time=  20.8s\n",
            "[CV 8/10; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=166\n",
            "[CV 8/10; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=166;, score=0.985 total time=  20.7s\n",
            "[CV 9/10; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=166\n",
            "[CV 9/10; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=166;, score=0.991 total time=  20.9s\n",
            "[CV 10/10; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=166\n",
            "[CV 10/10; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=166;, score=0.996 total time=  20.4s\n",
            "[CV 1/10; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=155.\n",
            "[CV 1/10; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=155;, score=0.981 total time=  19.0s\n",
            "[CV 2/10; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=155.\n",
            "[CV 2/10; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=155;, score=0.991 total time=  19.4s\n",
            "[CV 3/10; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=155.\n",
            "[CV 3/10; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=155;, score=0.993 total time=  19.5s\n",
            "[CV 4/10; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=155.\n",
            "[CV 4/10; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=155;, score=0.991 total time=  19.5s\n",
            "[CV 5/10; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=155.\n",
            "[CV 5/10; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=155;, score=0.993 total time=  23.4s\n",
            "[CV 6/10; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=155.\n",
            "[CV 6/10; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=155;, score=0.997 total time=  19.5s\n",
            "[CV 7/10; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=155.\n",
            "[CV 7/10; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=155;, score=0.999 total time=  19.4s\n",
            "[CV 8/10; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=155.\n",
            "[CV 8/10; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=155;, score=0.982 total time=  19.5s\n",
            "[CV 9/10; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=155.\n",
            "[CV 9/10; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=155;, score=0.991 total time=  19.4s\n",
            "[CV 10/10; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=155\n",
            "[CV 10/10; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=155;, score=0.997 total time=  20.2s\n",
            "[CV 1/10; 7/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=111.\n",
            "[CV 1/10; 7/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=111;, score=0.979 total time=  13.3s\n",
            "[CV 2/10; 7/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=111.\n",
            "[CV 2/10; 7/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=111;, score=0.988 total time=  13.1s\n",
            "[CV 3/10; 7/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=111.\n",
            "[CV 3/10; 7/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=111;, score=0.992 total time=  13.7s\n",
            "[CV 4/10; 7/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=111.\n",
            "[CV 4/10; 7/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=111;, score=0.990 total time=  13.5s\n",
            "[CV 5/10; 7/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=111.\n",
            "[CV 5/10; 7/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=111;, score=0.996 total time=  13.1s\n",
            "[CV 6/10; 7/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=111.\n",
            "[CV 6/10; 7/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=111;, score=0.996 total time=  13.6s\n",
            "[CV 7/10; 7/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=111.\n",
            "[CV 7/10; 7/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=111;, score=0.999 total time=  13.7s\n",
            "[CV 8/10; 7/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=111.\n",
            "[CV 8/10; 7/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=111;, score=0.982 total time=  13.3s\n",
            "[CV 9/10; 7/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=111.\n",
            "[CV 9/10; 7/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=111;, score=0.991 total time=  13.2s\n",
            "[CV 10/10; 7/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=111\n",
            "[CV 10/10; 7/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=111;, score=0.996 total time=  12.8s\n",
            "[CV 1/10; 8/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 1/10; 8/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.983 total time=  18.5s\n",
            "[CV 2/10; 8/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 2/10; 8/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.988 total time=  18.3s\n",
            "[CV 3/10; 8/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 3/10; 8/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.993 total time=  18.6s\n",
            "[CV 4/10; 8/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 4/10; 8/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.990 total time=  18.3s\n",
            "[CV 5/10; 8/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 5/10; 8/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.993 total time=  18.3s\n",
            "[CV 6/10; 8/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 6/10; 8/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.996 total time=  18.2s\n",
            "[CV 7/10; 8/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 7/10; 8/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.999 total time=  18.0s\n",
            "[CV 8/10; 8/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 8/10; 8/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.982 total time=  18.7s\n",
            "[CV 9/10; 8/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166.\n",
            "[CV 9/10; 8/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.991 total time=  18.0s\n",
            "[CV 10/10; 8/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=166\n",
            "[CV 10/10; 8/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=166;, score=0.997 total time=  17.9s\n",
            "[CV 1/10; 9/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=133.\n",
            "[CV 1/10; 9/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=133;, score=0.978 total time=  14.5s\n",
            "[CV 2/10; 9/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=133.\n",
            "[CV 2/10; 9/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=133;, score=0.985 total time=  14.3s\n",
            "[CV 3/10; 9/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=133.\n",
            "[CV 3/10; 9/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=133;, score=0.993 total time=  14.9s\n",
            "[CV 4/10; 9/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=133.\n",
            "[CV 4/10; 9/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=133;, score=0.990 total time=  14.1s\n",
            "[CV 5/10; 9/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=133.\n",
            "[CV 5/10; 9/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=133;, score=0.996 total time=  14.2s\n",
            "[CV 6/10; 9/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=133.\n",
            "[CV 6/10; 9/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=133;, score=0.996 total time=  14.5s\n",
            "[CV 7/10; 9/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=133.\n",
            "[CV 7/10; 9/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=133;, score=0.999 total time=  14.6s\n",
            "[CV 8/10; 9/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=133.\n",
            "[CV 8/10; 9/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=133;, score=0.985 total time=  14.3s\n",
            "[CV 9/10; 9/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=133.\n",
            "[CV 9/10; 9/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=133;, score=0.991 total time=  14.4s\n",
            "[CV 10/10; 9/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=133\n",
            "[CV 10/10; 9/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=133;, score=0.997 total time=  14.5s\n",
            "[CV 1/10; 10/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=111\n",
            "[CV 1/10; 10/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=111;, score=0.980 total time=  12.0s\n",
            "[CV 2/10; 10/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=111\n",
            "[CV 2/10; 10/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=111;, score=0.991 total time=  12.1s\n",
            "[CV 3/10; 10/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=111\n",
            "[CV 3/10; 10/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=111;, score=0.993 total time=  12.1s\n",
            "[CV 4/10; 10/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=111\n",
            "[CV 4/10; 10/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=111;, score=0.991 total time=  12.2s\n",
            "[CV 5/10; 10/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=111\n",
            "[CV 5/10; 10/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=111;, score=0.993 total time=  12.3s\n",
            "[CV 6/10; 10/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=111\n",
            "[CV 6/10; 10/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=111;, score=0.996 total time=  11.9s\n",
            "[CV 7/10; 10/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=111\n",
            "[CV 7/10; 10/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=111;, score=0.999 total time=  11.9s\n",
            "[CV 8/10; 10/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=111\n",
            "[CV 8/10; 10/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=111;, score=0.985 total time=  11.9s\n",
            "[CV 9/10; 10/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=111\n",
            "[CV 9/10; 10/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=111;, score=0.991 total time=  11.9s\n",
            "[CV 10/10; 10/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=111\n",
            "[CV 10/10; 10/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=111;, score=0.993 total time=  12.1s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=10, estimator=RandomForestClassifier(),\n",
              "                   param_distributions={'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [100, 111, 122, 133,\n",
              "                                                         144, 155, 166, 177,\n",
              "                                                         188, 200]},\n",
              "                   scoring=make_scorer(weighted_balance_average), verbose=10)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "id": "5wYVs4DS9qUF"
    },
    {
      "cell_type": "code",
      "source": [
        "print(rf_random.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtQ3NAoH9vJY",
        "outputId": "35df1128-d584-42ec-b5c8-5a138ead036b"
      },
      "id": "jtQ3NAoH9vJY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 166, 'min_samples_split': 10, 'min_samples_leaf': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=166, min_samples_split=10, min_samples_leaf=2)\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "return_accuracy(y_test, y_pred)\n",
        "metrics.plot_confusion_matrix(clf, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "9xrzTwM29vO4",
        "outputId": "3e564753-9200-4846-fdd3-99749edba6ba"
      },
      "id": "9xrzTwM29vO4",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of true negatives is: 67852\n",
            "The number of false negatives is: 19\n",
            "The number of false positives is: 250\n",
            "The number of true positives is: 111\n",
            "The accuracy is: 0.9960575682964005\n",
            "The accuracy on the 1's is  0.8538461538461539\n",
            "The accuracy on the 0's is  0.9963290358579777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f6fef04b8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNDERSAMPLING BY RANDOM UNDER SAMPLER"
      ],
      "metadata": {
        "id": "00CnMWoctaEF"
      },
      "id": "00CnMWoctaEF"
    },
    {
      "cell_type": "code",
      "source": [
        "# we don't perform a classical random splitting of train and test as we want the majority of the 1's in the test to see the accuracy of the model on those\n",
        "import random\n",
        "\n",
        "\n",
        "critical_indices = np.where(RelKa >= 0.6)[0]\n",
        "random_subsample = random.sample(list(np.arange(len(critical_indices))), np.int(0.7 * len(critical_indices)))\n",
        "training_critical_indices = []\n",
        "for i in range(len(critical_indices)):\n",
        "    if i not in random_subsample:\n",
        "      training_critical_indices.append(i)\n",
        "critical_subsample = training_data[critical_indices[0] + random_subsample, :]\n",
        "critical_RelKa = RelKa[critical_indices[0] + random_subsample]\n",
        "X_test = np.zeros(training_data.shape[1])\n",
        "X_test = X_test[..., np.newaxis].T\n",
        "y_test = np.array([])\n",
        "X_train = np.zeros(training_data.shape[1])\n",
        "X_train = X_train[..., np.newaxis].T\n",
        "y_train = np.array([])\n",
        "X_test = np.concatenate([X_test, critical_subsample], axis=0)\n",
        "y_test = np.concatenate([y_test, critical_RelKa])\n",
        "X_train = np.concatenate([X_train, training_data[critical_indices[0] + training_critical_indices, :]], axis=0)\n",
        "y_train = np.concatenate([y_train, RelKa[critical_indices[0] + training_critical_indices]])\n",
        "X_test = np.delete(X_test, 0, axis=0)\n",
        "X_train = np.delete(X_train, 0, axis=0)"
      ],
      "metadata": {
        "id": "lthSQ4Bh0itS"
      },
      "id": "lthSQ4Bh0itS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbWWyGNp3ctE",
        "outputId": "e00a5c95-2003-41a7-ad40-77f451d336a8"
      },
      "id": "sbWWyGNp3ctE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(267, 318) (267,) (622, 318) (622,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_critical_indices = np.where(RelKa < 0.6)[0]\n",
        "non_critical_training_data = training_data[non_critical_indices, :]\n",
        "non_critical_RelKa = RelKa[non_critical_indices]\n",
        "non_critical_X_train, non_critical_X_test, non_critical_y_train, non_critical_y_test = train_test_split(non_critical_training_data, non_critical_RelKa, train_size=0.7, random_state=42) "
      ],
      "metadata": {
        "id": "be7hAjxY3rOm"
      },
      "id": "be7hAjxY3rOm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate([X_train, non_critical_X_train], axis=0)\n",
        "X_test = np.concatenate([X_test, non_critical_X_test], axis=0)\n",
        "y_train = np.concatenate([y_train, non_critical_y_train])\n",
        "y_test = np.concatenate([y_test, non_critical_y_test])\n",
        "y_train = split_RelKa(y_train, 0.6)\n",
        "y_test = split_RelKa(y_test, 0.6)"
      ],
      "metadata": {
        "id": "dyM0_rwB4MaZ"
      },
      "id": "dyM0_rwB4MaZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJditbVB6fEB"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 10)]\n",
        "min_samples_split = [2, 5, 10]\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "random_grid = {'classifier__n_estimators': n_estimators,\n",
        "               'classifier__min_samples_split': min_samples_split,\n",
        "               'classifier__min_samples_leaf': min_samples_leaf}"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "zJditbVB6fEB"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "rus = RandomUnderSampler\n",
        "smo = SMOTE()\n",
        "rfc = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "m78JrdiK5ttP"
      },
      "id": "m78JrdiK5ttP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validate(X, y, random_grid, undersampling=True, oversampling=True):\n",
        "    if oversampling is False:\n",
        "        pipeline = Pipeline([('undersampling', RandomUnderSampler(sampling_strategy = 0.02)), ('classifier', RandomForestClassifier())])\n",
        "    elif undersampling is False:\n",
        "        pipeline = Pipeline([('smt', SMOTE(sampling_strategy = 0.8)), ('classifier', RandomForestClassifier())])\n",
        "    else:\n",
        "        pipeline = Pipeline([('undersampling', RandomUnderSampler(sampling_strategy = 0.02)), ('smt',  SMOTE(sampling_strategy = 0.8)), ('classifier', RandomForestClassifier())])\n",
        "    \n",
        "    rf_random = RandomizedSearchCV(estimator=pipeline, param_distributions=random_grid, n_iter=5, cv=10, scoring='roc_auc', verbose=10)\n",
        "    rf_random.fit(X, y)\n",
        "    return rf_random.best_params_"
      ],
      "metadata": {
        "id": "G6zqxYNw8LBO"
      },
      "id": "G6zqxYNw8LBO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = cross_validate(X_train, y_train, random_grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpRUWUvjXc8v",
        "outputId": "3a781e0b-9c9f-4733-ddcd-37928b1b6317"
      },
      "id": "qpRUWUvjXc8v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'classifier__n_estimators': 122, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=122, min_samples_leaf=2, min_samples_split=2)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "mDWfZGh5MLoH",
        "outputId": "8052398f-13aa-43dd-c0eb-7c82677c067d"
      },
      "id": "mDWfZGh5MLoH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0505aff7eeef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreturn_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'return_accuracy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "return_accuracy(y_test, y_pred, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhCdYT5SBVKv",
        "outputId": "87500ce8-10d0-4bfe-d863-1b14d47e6199"
      },
      "id": "ZhCdYT5SBVKv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of true negatives is: 50904\n",
            "The number of false negatives is: 460\n",
            "The number of false positives is: 4\n",
            "The number of true positives is: 162\n",
            "The accuracy is: 0.9909955365806327\n",
            "The accuracy on the 1's is  0.2604501607717042\n",
            "The accuracy on the 0's is  0.999921426887719\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9909955365806327"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}