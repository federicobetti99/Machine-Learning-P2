{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Project_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVkUbtoxrZN3"
      },
      "source": [
        "Importing useful libraries and importing the drive for the dataset"
      ],
      "id": "OVkUbtoxrZN3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc466260"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "dc466260",
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjM2luKFSayr",
        "outputId": "35a00749-e327-4df9-a31e-699b302aa1f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive"
      ],
      "id": "jjM2luKFSayr",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/My Drive'\n",
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkcqxT8Eo-D2"
      },
      "source": [
        "Importing the data"
      ],
      "id": "FkcqxT8Eo-D2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6__FhQiuUag"
      },
      "source": [
        "pddata = pd.read_csv('GSM1586785_ScrH-12A_Exd_14mer_cg.csv.zip', compression='zip', error_bad_lines=False, skiprows=1)"
      ],
      "id": "z6__FhQiuUag",
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Onini8BliWv"
      },
      "source": [
        "# transforming into a numpy array\n",
        "pddata = pddata.to_numpy()\n",
        "# getting the labels as the last column and neglecting the DNA sequence feature\n",
        "RelKa = pddata[:, -1]\n",
        "training_data = pddata[:, 2:-1]"
      ],
      "id": "7Onini8BliWv",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_CsKxXSpITN"
      },
      "source": [
        "Implementation of Isolation Forest for anomaly detection"
      ],
      "id": "B_CsKxXSpITN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGFTBY6qQ-KJ",
        "outputId": "026b0abb-bd8f-4b35-d22c-77ad6c3417fc"
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "random_state = np.random.RandomState(42)\n",
        "# the contamination parameter is calculated by the program without loss of generality (as written in the paper about IF)\n",
        "model = IsolationForest(n_estimators=100, max_samples='auto', contamination='auto', random_state=random_state)\n",
        "model.fit(training_data)"
      ],
      "id": "ZGFTBY6qQ-KJ",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bootstrap': False, 'contamination': 'auto', 'max_features': 1.0, 'max_samples': 'auto', 'n_estimators': 100, 'n_jobs': None, 'random_state': RandomState(MT19937) at 0x7F16E7404050, 'verbose': 0, 'warm_start': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcPbnrOn2PtP"
      },
      "source": [
        "Getting the anomaly score for each sample"
      ],
      "id": "jcPbnrOn2PtP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pTvfS5s0esU"
      },
      "source": [
        "scores = model.decision_function(training_data)\n",
        "anomaly_score = model.predict(training_data)"
      ],
      "id": "9pTvfS5s0esU",
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVAqn8xv0vdx",
        "outputId": "4461f99e-8c2d-449d-b661-3f3b06fbd5af"
      },
      "source": [
        "outliers_number = 1 / anomaly_score.shape[0] * np.count_nonzero(anomaly_score == -1)\n",
        "print(\"Percentage of outliers detected\", outliers_number)"
      ],
      "id": "cVAqn8xv0vdx",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of outliers detected 0.12638058389025678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LbSjC-64KK1"
      },
      "source": [
        "Deleting the samples which are considered outliers by the Isolation Forest Algorithm"
      ],
      "id": "3LbSjC-64KK1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgauCTHM4rJ_",
        "outputId": "2194b3b4-f061-4972-8663-9a39717ca28c"
      },
      "source": [
        "outliers_indices = np.where(anomaly_score == -1)[0]\n",
        "# we check for debugging how many outliers have indeed a high RelKa value\n",
        "# print(len(outliers_indices > 110000))\n",
        "training_data = np.delete(training_data, outliers_indices, axis = 0)"
      ],
      "id": "SgauCTHM4rJ_",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    88    102    176 ... 170548 170549 170565]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-qpY5Hu59bz"
      },
      "source": [
        "RelKa = np.delete(RelKa, outliers_indices, axis = 0)"
      ],
      "id": "J-qpY5Hu59bz",
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJmP3ynMhYTw"
      },
      "source": [
        "Standardization of the data"
      ],
      "id": "dJmP3ynMhYTw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3tFfIiGhaLt"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(training_data)\n",
        "training_data = scaler.transform(training_data)"
      ],
      "id": "c3tFfIiGhaLt",
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1mtDkTMdTzq"
      },
      "source": [
        "We classify as \"good binding sequences\" the ones for which the value of RelKa is above 0.5 (this is kind of a hyperparameter)"
      ],
      "id": "A1mtDkTMdTzq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6nQZNDSdJgD"
      },
      "source": [
        "RelKa_tilda = np.array([1 if prob > 0.5 else 0 for prob in RelKa])"
      ],
      "id": "p6nQZNDSdJgD",
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssEbARYX4S5-"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(training_data, RelKa_tilda, test_size=0.7, random_state=42)"
      ],
      "id": "ssEbARYX4S5-",
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K06NJwGefTtJ"
      },
      "source": [
        "We to compute a classification prediction with Random Forests"
      ],
      "id": "K06NJwGefTtJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMxdbuCb4bJx"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)"
      ],
      "id": "eMxdbuCb4bJx",
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sxKuBy6vt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550c3316-5d47-4226-dccf-2ed1a829e4c3"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "C = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(y_test, y_pred)\n",
        "print(\"Accuracy:\", np.trace(C) / len(y_test))\n",
        "print(\"The number of true negatives is:\", C[0, 0])\n",
        "print(\"The number of false negatives is:\", C[1,0])\n",
        "print(\"The number of false positives is:\", C[0,1])\n",
        "print(\"The number of true positives is:\", C[1,1])"
      ],
      "id": "g2sxKuBy6vt5",
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 ... 0 0 0] [0 0 0 ... 0 0 0]\n",
            "Accuracy: 0.9900111200582844\n",
            "The number of true negatives is: 102764\n",
            "The number of false negatives is: 995\n",
            "The number of false positives is: 47\n",
            "The number of true positives is: 510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TyHT3NLfYy7"
      },
      "source": [
        "We see that we have a problem with a large number of false negatives, namely with incorrectly predictions of the negative class"
      ],
      "id": "4TyHT3NLfYy7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqcRaNgPqWlT"
      },
      "source": [
        "A further insight on the errors has to be done, but probably increasing the threshold 0.5 helps already a lot"
      ],
      "id": "GqcRaNgPqWlT"
    }
  ]
}