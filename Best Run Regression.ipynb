{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qeM593-TwcoM"
      },
      "outputs": [],
      "source": [
        "# for dealing with data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#for visualization\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as st\n",
        "import random\n",
        "\n",
        "\n",
        "#machine learning libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "#for mathematics and statistics\n",
        "import math\n",
        "from scipy import stats\n",
        "import scipy as sci\n",
        "from scipy.spatial.distance import minkowski\n",
        "from scipy.stats import spearmanr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DD9gASEwigQ",
        "outputId": "a36ddc41-f2bf-402b-8fde-3750b0b7315d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wcIPdcE4wlb1"
      },
      "outputs": [],
      "source": [
        "# we import the dataset using pandas\n",
        "pddata = pd.read_csv('GSM1586785_ScrH-12A_Exd_14mer_cg.csv.zip', compression='zip', error_bad_lines=False, skiprows=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FU9GUWIBwnDh"
      },
      "outputs": [],
      "source": [
        "# we visualize the first ten rows of our dataframe\n",
        "pddata = pddata.to_numpy()\n",
        "RelKa = pddata[:, -1]\n",
        "training_data = pddata[:, 2:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ec7aw0cE6rsV"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def split_outliers(threshold, scores):\n",
        "  outliers_indices = np.where(scores < threshold)[0]\n",
        "  return outliers_indices\n",
        "\n",
        "def Anomaly_Detection_Isolation_Forests(x, change_split=False):\n",
        "  random_state = np.random.RandomState(42)\n",
        "  contamination = 'auto'\n",
        "  threshold = np.random.uniform(-0.03, -0.02, 1)\n",
        "  model = IsolationForest(n_estimators=120, max_samples='auto', contamination=contamination, random_state=random_state)\n",
        "  model.fit(x)\n",
        "  scores = model.decision_function(x)\n",
        "  if change_split == False:\n",
        "    anomaly_score = model.predict(x)\n",
        "    outliers_indices = np.where(anomaly_score == -1)[0]\n",
        "  if change_split == True:\n",
        "    outliers_indices = split_outliers(threshold, scores)\n",
        "  return contamination, scores, outliers_indices\n",
        "\n",
        "def check_Isolation_Forests(contamination, outliers_indices):\n",
        "  \"\"\"\n",
        "  Simply a check on the proper working of the IF algorithm\n",
        "  \"\"\"\n",
        "  tol = 1.0e-02\n",
        "  if contamination != 'auto':\n",
        "    outliers_percentage = 1 / len(RelKa) * len(outliers_indices)\n",
        "    assert np.abs(contamination-outliers_percentage) < tol\n",
        "\n",
        "def check_boundary_decision(scores, p, verbose=1):\n",
        "  \"\"\"\n",
        "  This function simply controls how many scores returned by the IF algorithm \n",
        "  are likely to be misclassified\n",
        "  \"\"\"\n",
        "  indecision_percentage = 1 / len(RelKa) * np.count_nonzero(np.abs(scores) <= p)\n",
        "  if verbose == 1:\n",
        "    plt.hist(scores)\n",
        "    plt.show()\n",
        "    print(\"The indecision percentage around\", p,  \"is\", indecision_percentage)\n",
        "    print(\"The percentage of outliers detected is\", 1 / len(scores) * len(np.where(scores < 0)[0]))\n",
        "\n",
        "def drop_outliers(x, y, outliers):\n",
        "  x = np.delete(x, outliers, axis=0)\n",
        "  y = np.delete(y, outliers, axis=0)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d8eYszg3n53z"
      },
      "outputs": [],
      "source": [
        "def split_importance(x, y, importance_class=0.7):\n",
        "  \"\"\"\n",
        "  Split the samples into interesting ones and not interesting ones\n",
        "  :param x: numpy.ndarray:the feature vector of the initial dataset\n",
        "  :param y: numpy.ndarray: the value vector of the initial dataset\n",
        "  :param importance_class: float: the lower bound for the underepresented class\n",
        "  \"\"\"\n",
        "  return x[y >= importance_class], y[y >= importance_class], x[y < importance_class], y[y < importance_class]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UuXU1lLfoAy1"
      },
      "outputs": [],
      "source": [
        "x_1, y_1, x_0, y_0 = split_importance(training_data, RelKa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wnZYvVZuoEXN"
      },
      "outputs": [],
      "source": [
        "# split the two classes seperately into train and test set to ensure representation of the minority class\n",
        "# both in the test set and in the train set\n",
        "x_1_train, x_1_test, y_1_train, y_1_test = train_test_split(x_1, y_1, test_size=0.3, random_state=42)\n",
        "x_0_train, x_0_test, y_0_train, y_0_test = train_test_split(x_0, y_0, test_size=0.3, random_state=42)\n",
        "\n",
        "x_train = np.concatenate((x_1_train, x_0_train))\n",
        "y_train = np.concatenate((y_1_train, y_0_train))\n",
        "x_test = np.concatenate((x_1_test, x_0_test))\n",
        "y_test = np.concatenate((y_1_test, y_0_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vO7-bhBsoMWO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4fsfcd-qF3YL"
      },
      "outputs": [],
      "source": [
        "def random_undersampling(x, y, alpha, importance_boundary=0.7):\n",
        "  \"\"\"\n",
        "  alpha is a parameter bigger than 1/2\n",
        "  \"\"\"\n",
        "  count = 0\n",
        "  to_drop = []\n",
        "  for i in range(x.shape[0]):\n",
        "    print(\"Checking the \", i, \"sample\")\n",
        "    U = st.uniform.rvs(size=1)\n",
        "    if y[i] <= importance_boundary:\n",
        "      if U <= alpha:\n",
        "        to_drop.append(i)\n",
        "  x = np.delete(x, to_drop, axis=0)\n",
        "  y = np.delete(y, to_drop, axis=0)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JBdxcA968_G4"
      },
      "outputs": [],
      "source": [
        "def stratified_undersampling(x, y, intervals = 0.05 * np.arange(0, 15)):\n",
        "  \"\"\"\n",
        "  This function performs stratified undersampling on the majority class\n",
        "  by dropping samples in each strata with a probability equal to the frequency\n",
        "  :param x: the datapoints to be undersampled\n",
        "  :param y: the corresponding labels\n",
        "  :param alpha: a hyperparameter to choose the dropping probability \n",
        "  :param intervals: the stratification intervals\n",
        "  :return x and y undersampled  \n",
        "  \"\"\"\n",
        "  # just a check that we drop with high probability in the frequent strata\n",
        "  to_drop = []\n",
        "  # we do a cycle over all intervals\n",
        "  for i in range(len(intervals)-1):\n",
        "    # get the indices for which the label is in the i-th strata\n",
        "    indices = np.where(np.logical_and(intervals[i] < y, y < intervals[i+1]))[0]\n",
        "    # compute the frequency of the i-th strata\n",
        "    frequency = len(indices) / len(y)\n",
        "    # we do a cycle over all elements in such a stratum\n",
        "    for j in range(len(indices)):\n",
        "      # we draw a uniform random variable\n",
        "      U = st.uniform.rvs(size=1)\n",
        "      if U <= frequency:\n",
        "        # we drop every sample in the i-th strata with probability alpha * frequency\n",
        "        to_drop.append(indices[j])\n",
        "  # we drop from x and y the samples and the labels found before\n",
        "  x_new = np.delete(x, to_drop, axis=0)\n",
        "  y_new = np.delete(y, to_drop, axis=0)\n",
        "  return x_new, y_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4As9ODx8t6_H"
      },
      "outputs": [],
      "source": [
        "#quantization function required for some score functions\n",
        "def quantize(x,cuts=100):\n",
        "  ranges = np.sort(np.unique(pd.cut(x,cuts)))\n",
        "  for i in range(ranges.shape[0]):\n",
        "    ranges_i = ranges[i]\n",
        "    x[(x<=ranges_i.right)&(x>ranges_i.left)] = (ranges_i.left +ranges_i.right)/2\n",
        "  return x\n",
        "\n",
        "def quantize_features(x,cuts=100):\n",
        "  return np.apply_along_axis(quantize,0,x,cuts)\n",
        "\n",
        "#correlation scorers\n",
        "def Spearman(i,j):\n",
        "  ret,_ = spearmanr(i,j)\n",
        "  return ret\n",
        "\n",
        "def Correlation_Score(x,y):\n",
        "  x = x.T\n",
        "  score = [min([abs(Spearman(j,i)) for i in x]) for j in x]\n",
        "  return np.array(score)\n",
        "\n",
        "def Correlation_Score_Max(x,y):\n",
        "  x = x.T\n",
        "  score = [-max([abs(Spearman(j,i)) for i in x]) for j in x]\n",
        "  return np.array(score)\n",
        "\n",
        "def Closest(x, z):\n",
        "    \"\"\"\n",
        "    Returns the index of the sample in x which is the closest one to all the samples in z\n",
        "    :param x: numpy.ndarray: The array of the samples for which we seek to find the furthest\n",
        "    :param z: numpy.ndarray: The array of the samples which we use as a point of reference\n",
        "    :return: int: returns a single index corresponding to the furthest x\n",
        "    \"\"\"\n",
        "    distances = []\n",
        "    # we seek for the closest point to z in x\n",
        "    for i in range(x.shape[0]):\n",
        "        # for each sample in x we calculate the distance from all points in z and we take the minimum\n",
        "        distance = min([np.linalg.norm(j - x[i]) for j in z])\n",
        "        # we add the calculated distance to the list\n",
        "        distances.append(distance)\n",
        "    # we return the closest point by taking the argmin over all calculated distances\n",
        "    return np.argmin(distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JtmKdxD5xcMm"
      },
      "outputs": [],
      "source": [
        "def PSU_undersampling_regression(x, y, randomsize, xi, yi):\n",
        "    \"\"\"\n",
        "    This function performs the PSU undersampling of the samples in the x,y arrays\n",
        "    with regards to the set xi,yi. This version is a slight modification of the original proposed algorithm\n",
        "    which helps us improving in the prediction of the RelKa in the central intervals\n",
        "    :param x: numpy.ndarray: The array of samples on which we perform the undersampling\n",
        "    :param y: numpy.ndarray: The labels corresponding to the samples in x\n",
        "    :param randomsize: int: An integer corresponding to the number of samples to be left\n",
        "    :param xi: numpy.ndarray: The array with the samples to be used as a reference for distances\n",
        "    :param yi: numpy.ndarray: The labels of the samples in xi\n",
        "    :return: numpy.ndarray,numpy.ndarray: Returns 2 numpy arrays corresponding to the undersampled data\n",
        "    \"\"\"\n",
        "    # we calculate the centroid of the majority class data\n",
        "    C = np.mean(x, axis=0)\n",
        "    # for each sample in the majority class we calculate the l2 distance from the centroid\n",
        "    dist = np.linalg.norm(x - C, 2, axis=1)\n",
        "    # we sort the distances\n",
        "    indices = dist.argsort()\n",
        "    # we sort the samples and the corresponding labels according to the distances calculated before\n",
        "    x = x[indices]\n",
        "    y = y[indices]\n",
        "    # we split the samples and the corresponding labels in randomsize partitions\n",
        "    split_x = np.array_split(x, randomsize)\n",
        "    split_y = np.array_split(y, randomsize)\n",
        "    # for each partition we calculate the closest point to the minority class xi\n",
        "    indices = [Closest(split_x[i], xi) for i in range(randomsize)]\n",
        "    # the collection of the randomsize closest points calculated above represents the undersampled data\n",
        "    x_resample = np.array([split_x[i][indices[i]] for i in range(randomsize)])\n",
        "    # the corresponding labels of the undersampled data are also returned\n",
        "    y_resample = np.array([split_y[i][indices[i]] for i in range(randomsize)])\n",
        "    return x_resample, y_resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FcGYPv2Cvwoe"
      },
      "outputs": [],
      "source": [
        "def PSU_stratified_undersampling(x, y, randomsize, intervals, xi, yi):\n",
        "    \"\"\"\n",
        "    This function performs the PSU undersampling of the samples in the x,y arrays\n",
        "    with regards to the set xi,yi. This version is a slight modification of the original proposed algorithm\n",
        "    which helps us improving in the prediction of the RelKa in the central intervals\n",
        "    :param x: numpy.ndarray: The array of samples on which we perform the undersampling\n",
        "    :param y: numpy.ndarray: The labels corresponding to the samples in x\n",
        "    :param randomsize: int: An integer corresponding to the number of samples to be left\n",
        "    :param intervals: the intervals for stratification\n",
        "    :param xi: the reference points\n",
        "    :param yi: the corresponding labels to xi\n",
        "    :return: numpy.ndarray,numpy.ndarray: Returns 2 numpy arrays corresponding to the undersampled data\n",
        "    \"\"\"\n",
        "    # we calculate the number of strata\n",
        "    k = intervals.shape[0]\n",
        "    print(k)\n",
        "    # we initialize the lists for undersampling\n",
        "    x_resample = np.zeros(x.shape[1])\n",
        "    x_resample = x_resample[..., np.newaxis].T\n",
        "    y_resample = []\n",
        "    for i in range(len(intervals)-1):\n",
        "        indices = np.where(np.logical_and(intervals[i] < y, y < intervals[i+1]))[0]\n",
        "        # we get the samples and the labels in the i-th strata\n",
        "        x_ = x[indices]\n",
        "        y_ = y[indices]\n",
        "        frequency = len(indices) / len(y)\n",
        "        # we perform the modified PSU undersampling on the i-th strata\n",
        "        x_, y_ = PSU_undersampling_regression(x_, y_, int(randomsize*frequency), xi, yi)\n",
        "        # we add the samples and the corresponding labels\n",
        "        x_resample = np.concatenate([x_resample, x_], axis=0)\n",
        "        y_resample = np.concatenate([y_resample, y_], axis=0)\n",
        "    # we drop the first row used only for initialization\n",
        "    x_resample = np.delete(x_resample, 0, axis=0)\n",
        "    return x_resample, y_resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "t5MjEsO7t-y-"
      },
      "outputs": [],
      "source": [
        "def Furthest(x, z):\n",
        "    \"\"\"\n",
        "    Returns the index of the sample in x which is furthest from all the samples in z\n",
        "    :param x: numpy.ndarray: The array of the samples for which we seek to find the furthest\n",
        "    :param z: numpy.ndarray: The array of the samples which we use as a point of reference\n",
        "    :return: int: returns a single index corresponding to the furthest x\n",
        "    \"\"\"\n",
        "    # we initialize the maximum distance to be -1 and the furthest sample to have index 0\n",
        "    max_dist_i = 0\n",
        "    max_dist = -1\n",
        "    # we seek for the furthest point from z in x\n",
        "    for i in range(x.shape[0]):\n",
        "        # for each sample in x we calculate the distance from all points in z and we take the minimum\n",
        "        distance = min([np.linalg.norm(j - x[i]) for j in z])\n",
        "        # we update the distance if the current distance is larger than the old one\n",
        "        if max_dist < distance:\n",
        "            max_dist = distance\n",
        "            # we save the current sample i as the candidate furthest point from z\n",
        "            max_dist_i = i\n",
        "    return max_dist_i\n",
        "\n",
        "def PSU_undersampling(x,y,randomsize,xi,yi):\n",
        "  \"\"\"\n",
        "  This function calculates the PSU undersampling of the samples in the x,y arrays\n",
        "  with regards to the set xi,yi\n",
        "  :param x: numpy.ndarray: The array of samples, which we want to undersample\n",
        "  :param y: numpy.ndarray: The array with the labels corresponding to the samples in x\n",
        "  :param randomsize: int: An int corresponding to the number of samples to be left\n",
        "  :param xi: numpy.ndarray: The array with the samples to be used as a reference for distances\n",
        "  :param yi: numpy.ndarray: The labels of these samples\n",
        "  :return: numpy.ndarray,numpy.ndarray: Returns 2 numpy arrays corresponding to the undersampled data\n",
        "  \"\"\"\n",
        "  C = np.mean(x,axis = 0)\n",
        "  dist = np.linalg.norm(x-C,2,axis = 1)\n",
        "  indices = dist.argsort()\n",
        "  x = x[indices]\n",
        "  y = y[indices]\n",
        "  split_x = np.array_split(x,randomsize)\n",
        "  split_y = np.array_split(y,randomsize)\n",
        "  indices = [Furthest(split_x[i],xi) for i in range(randomsize)]\n",
        "  x_resample = np.array([split_x[i][indices[i]] for i in range(randomsize)])\n",
        "  y_resample = np.array([split_y[i][indices[i]] for i in range(randomsize)])\n",
        "  return x_resample, y_resample\n",
        "\n",
        "def PSU_undersampling_reduced_dim(x,y,randomsize,xi,yi):\n",
        "  \"\"\"\n",
        "  This function calculates the PSU undersampling by first doing a dimensionality reduction\n",
        "  of the samples in the x,y arrays with regards to the set xi,yi\n",
        "  :param x: numpy.ndarray: The array of samples, which we want to undersample\n",
        "  :param y: numpy.ndarray: The array with the labels corresponding to the samples in x\n",
        "  :param randomsize: int: An int corresponding to the number of samples to be left\n",
        "  :param xi: numpy.ndarray: The array with the samples to be used as a reference for distances\n",
        "  :param yi: numpy.ndarray: The labels of these samples\n",
        "  :return: numpy.ndarray,numpy.ndarray: Returns 2 numpy arrays corresponding to the undersampled data\n",
        "  \"\"\"\n",
        "  feature_scores =  Fisher_Score(xi,x)\n",
        "  indices = np.sort((-feature_scores).argsort()[:10])\n",
        "  x_filtered = x[:,indices]\n",
        "  x_i = xi[:,indices]\n",
        "  C = np.mean(x_filtered,axis = 0)\n",
        "  dist = np.linalg.norm(x_filtered-C,2,axis = 1)\n",
        "  indices = dist.argsort()\n",
        "  x_filtered = x_filtered[indices]\n",
        "  y = y[indices]\n",
        "  split_x = np.array_split(x_filtered,randomsize)\n",
        "  split_y = np.array_split(y,randomsize)\n",
        "  indices = [Furthest(split_x[i],x_i) for i in range(randomsize)]\n",
        "  split_x = np.array_split(x,randomsize)\n",
        "  x_resample = np.array([split_x[i][indices[i]] for i in range(randomsize)])\n",
        "  y_resample = np.array([split_y[i][indices[i]] for i in range(randomsize)])\n",
        "  return x_resample, y_resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uJq6YmmPoTM1"
      },
      "outputs": [],
      "source": [
        "def Fisher_Score(x_import, x_nimport):\n",
        "  \"\"\"\n",
        "  Given two arrays of two classes this function calculates the Fischer_scores to \n",
        "  measure the significance for all features\n",
        "  :param x_import: numpy.ndarray: the array containing the samples of one class\n",
        "  :param x_nimport: numpy.ndarray: the array containing the samples of the other class\n",
        "  :return: numpy.ndarray: returns an array containg the Fisher_Score for all features \n",
        "  \"\"\"\n",
        "  mean_import = np.mean(x_import, axis = 0)\n",
        "  mean_nimport = np.mean(x_nimport, axis = 0)\n",
        "  mean_dist = np.absolute(mean_import - mean_nimport)\n",
        "  std_import = np.std(x_import, axis=0)\n",
        "  std_nimport = np.std(x_nimport, axis=0)\n",
        "  std_sum = std_import+std_nimport\n",
        "  #return std_sum\n",
        "  return np.divide(mean_dist,std_sum)\n",
        "\n",
        "def calculate_distances(x, distance):\n",
        "  \"\"\"\n",
        "  Calculates the distance between any two pairs of the set x using \n",
        "  the Minkowski distance of degree distance.\n",
        "  :param x: numpy.ndarray: the vector for which we will calculate the distance \n",
        "                            between all of its elements \n",
        "  :param distance: float: the norm which should be used for the Minkowski distance\n",
        "  :return: numpy.ndarray: returns the Minkowski distance with the specified norm \n",
        "                          between all pairs of elements in x \n",
        "  \"\"\"\n",
        "  dist = np.array([[minkowski(a1,a2,distance) for a2 in x] for a1 in x])\n",
        "  np.fill_diagonal(dist,float('inf'))\n",
        "  return dist\n",
        "\n",
        "def random_sampler(x, y, randomsize):\n",
        "  \"\"\"\n",
        "  This function does random undersampling of vectors x,y and reduces them to \n",
        "  size random size\n",
        "  :param x: numpy.ndarray: the feature vector to be subsampled\n",
        "  :param y: numpy.ndarray: the label vector to be subsampled\n",
        "  :return: <class 'tuple'>: A tuple containing the two undersampled vectors\n",
        "  \"\"\"\n",
        "  p = np.random.permutation(len(y))\n",
        "  new_x = x[p]\n",
        "  new_y = y[p]\n",
        "  return new_x[:randomsize],new_y[:randomsize]\n",
        "\n",
        "def generate_samples(x, y, neighbors, N):\n",
        "  \"\"\"\n",
        "  This function generate N samples which are convex combinations of \n",
        "  the features of x and the labels of y\n",
        "  :param x: numpy.ndarray:\n",
        "  :param y: numpy.ndarray:\n",
        "  :return: <class 'tuple'>:\n",
        "  \"\"\"\n",
        "  new_samples_x = []\n",
        "  new_samples_y = []\n",
        "  for i in range(N):\n",
        "    random_sample_i = random.randint(0,y.shape[0]-1)\n",
        "    x_i = x[random_sample_i]\n",
        "    random_sample_j = random.randint(0,neighbors.shape[1]-1)\n",
        "    neigh_i = neighbors[random_sample_i,random_sample_j]\n",
        "    x_j = x[neigh_i]\n",
        "    lambda_ = random.uniform(0,1)\n",
        "    y_i = y[random_sample_i]\n",
        "    y_j = y[neigh_i]\n",
        "    new_x = x_i + lambda_*(x_j-x_i)\n",
        "    new_y = y_i + lambda_*(y_j-y_i)\n",
        "    new_samples_x.append(new_x)\n",
        "    new_samples_y.append(new_y)\n",
        "  return np.array(new_samples_x),np.array(new_samples_y)\n",
        "\n",
        "def random_sampler(x,y,randomsize):\n",
        "  \"\"\"\n",
        "  This function does random undersampling of vectors x,y and reduces them to \n",
        "  size random size\n",
        "  :param x: numpy.ndarray: the feature vector to be subsampled\n",
        "  :param y: numpy.ndarray: the label vector to be subsampled\n",
        "  :return: <class 'tuple'>: A tuple containing the two undersampled vectors\n",
        "  \"\"\"\n",
        "  p = np.random.permutation(len(y))\n",
        "  new_x = x[p]\n",
        "  new_y = y[p]\n",
        "  return new_x[:randomsize],new_y[:randomsize]\n",
        "\n",
        "def generate_samples(x,y,neighbors,N):\n",
        "  \"\"\"\n",
        "  This function generate N samples which are convex combinations of \n",
        "  the features of x and the labels of y\n",
        "  :param x: numpy.ndarray:\n",
        "  :param y: numpy.ndarray:\n",
        "  :return: <class 'tuple'>:\n",
        "  \"\"\"\n",
        "  new_samples_x = []\n",
        "  new_samples_y = []\n",
        "  for i in range(N):\n",
        "    random_sample_i = random.randint(0,y.shape[0]-1)\n",
        "    x_i = x[random_sample_i]\n",
        "    random_sample_j = random.randint(0,neighbors.shape[1]-1)\n",
        "    neigh_i = neighbors[random_sample_i,random_sample_j]\n",
        "    x_j = x[neigh_i]\n",
        "    lambda_ = random.uniform(0,1)\n",
        "    y_i = y[random_sample_i]\n",
        "    y_j = y[neigh_i]\n",
        "    new_x = x_i + lambda_*(x_j-x_i)\n",
        "    new_y = y_i + lambda_*(y_j-y_i)\n",
        "    new_samples_x.append(new_x)\n",
        "    new_samples_y.append(new_y)\n",
        "  return np.array(new_samples_x),np.array(new_samples_y)\n",
        "\n",
        "def smote_sf_classification(x, y, undersample=0.1, oversample=0.3, attribute_scorer=Fisher_Score,\n",
        "                            attribute_number=10, distance=float('inf'), kneighbors=3, importance_class=0.7):\n",
        "    \"\"\"\n",
        "    This function takes the complete input and produces a more balanced dataset based on the importance class\n",
        "    :param x: numpy.ndarray: the feature vector of the initial dataset\n",
        "    :param y: numpy.ndarray: the value vector of the initial dataset\n",
        "    :param undersample: float: the percentage of the dominant class that we want to keep\n",
        "    :param oversample: float: the percentage of the dataset that the minority class will be at the end\n",
        "    :param attribute_scorer: function: a function which will be used to score the relevance of a feature\n",
        "    :param attribute_number: int: the number of attributes to keep according to their score\n",
        "    :param distance: float: the norm which should be used for the Minkowski distance\n",
        "    :param kneighbors: int: the number of nearest neighbours to be considered for each point\n",
        "    :param importance_class: float: the lower bound for the under-represented class\n",
        "    :return: returns 2 new feature vectors and 2 new label vectors containing\n",
        "            the data for the importance class and the data for the non importance\n",
        "            class and their labels.\n",
        "    \"\"\"\n",
        "    # we split the training set into majority and minority class according to the value of the label\n",
        "    x_import = x[y >= importance_class]\n",
        "    y_import = y[y >= importance_class]\n",
        "    x_nimport = x[y < importance_class]\n",
        "    y_nimport = y[y < importance_class]\n",
        "\n",
        "    # we calculate the Fisher score for all the features\n",
        "    feature_scores = attribute_scorer(x_import, x_nimport)\n",
        "    # we find the attribute_number highest coordinates of the feature_scores vector\n",
        "    indices = np.sort((-feature_scores).argsort()[:attribute_number])\n",
        "    # we filter the samples to be represented only by the attribute number highest scored features\n",
        "    x_import_filtered = x_import[:, indices]\n",
        "    # we calculate the distances between the datapoints considering only the important features as otherwise we\n",
        "    # fall into the curse of dimensionality\n",
        "    distances = calculate_distances(x_import_filtered, distance)\n",
        "    # we find the kneighbors lowest indices of the distances of each sample, the corresponding datapoints are the\n",
        "    # nearest neighbours to be drawn randomly for the oversampling procedure\n",
        "    neighbors = np.array([np.sort(d.argsort()[:kneighbors]) for d in distances])\n",
        "    # we first undersample the the majority class\n",
        "    # we calculate the final size of the undersampled data\n",
        "    nimport_len = int(undersample * y_nimport.shape[0])\n",
        "    # we perform undersampling\n",
        "    x_nimport, y_nimport = PSU_undersampling(x_nimport, y_nimport, nimport_len, x_import, y_import)\n",
        "    # we calculate the number of samples to be generated by the oversampling algorithm\n",
        "    N = int(oversample * (y_nimport.shape[0]) - y_import.shape[0])\n",
        "    # we perform oversampling\n",
        "    new_samples_x, new_samples_y = generate_samples(x_import, y_import, neighbors, N)\n",
        "    # we merge the new samples with the old samples of the minority class and their labels\n",
        "    x_import = np.concatenate((x_import, new_samples_x))\n",
        "    y_import = np.concatenate((y_import, new_samples_y))\n",
        "    # we stack the samples and the labels of the majority and minority class\n",
        "    x_ret = np.concatenate((x_import, x_nimport))\n",
        "    y_ret = np.concatenate((y_import, y_nimport))\n",
        "    # x_ret represents the balanced dataset and y_ret the corresponding labels\n",
        "    return x_ret, y_ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RzW1M9AHv8Dk"
      },
      "outputs": [],
      "source": [
        "def smote_sf_regression(x, y, undersample=0.1, oversample=0.3, attribute_scorer=Fisher_Score,\n",
        "                        attribute_number=10, distance=float('inf'), kneighbors=3,\n",
        "                        importance_class=0.7, width_strata=0.1):\n",
        "    \"\"\"\n",
        "    This function performs stratified undersampling and SMOTE oversampling for the regression task\n",
        "    @param x: the initial dataset\n",
        "    @param y: the corresponding labels\n",
        "    @param undersample: the undersampling rate\n",
        "    @param oversample: the oversampling rate\n",
        "    @param attribute_scorer: the scorer for the features\n",
        "    @param attribute_number: the number of features to be considered for the distances between samples\n",
        "    @param distance: the degree of the Minkowski distance to be used\n",
        "    @param kneighbors: the number of nearest neighbours for the oversampling algorithm\n",
        "    @param importance_class: the importance boundary between majority and minority class\n",
        "    @param width_strata: the width of the strata for the stratified undersampling\n",
        "    @return: x and y rebalanced\n",
        "    \"\"\"\n",
        "    # we split the training set into majority and minority class according to the value of the label\n",
        "    x_import = x[y >= importance_class]\n",
        "    y_import = y[y >= importance_class]\n",
        "    x_nimport = x[y < importance_class]\n",
        "    y_nimport = y[y < importance_class]\n",
        "\n",
        "    # we calculate the Fisher score for all the features\n",
        "    feature_scores = attribute_scorer(x_import, x_nimport)\n",
        "    # we find the attribute_number highest coordinates of the feature_scores vector\n",
        "    indices = np.sort((-feature_scores).argsort()[:attribute_number])\n",
        "    # we filter the samples to be represented only by the attribute number highest scored features\n",
        "    x_import_filtered = x_import[:, indices]\n",
        "    # we calculate the distances between the datapoints considering only the important features as otherwise we\n",
        "    # fall into the curse of dimensionality\n",
        "    distances = calculate_distances(x_import_filtered, distance)\n",
        "    # we find the kneighbors lowest indices of the distances of each sample, the corresponding datapoints are the\n",
        "    # nearest neighbours to be drawn randomly for the oversampling procedure\n",
        "    neighbors = np.array([np.sort(d.argsort()[:kneighbors]) for d in distances])\n",
        "    # we get the undersampled datasize\n",
        "    nimport_len = int(undersample * y_nimport.shape[0])\n",
        "    print(nimport_len)\n",
        "    # we perform stratified undersampling\n",
        "    intervals = width_strata * np.arange(int(importance_class / width_strata))\n",
        "    print(intervals)\n",
        "    x_nimport, y_nimport = stratified_undersampling(x_nimport, y_nimport, intervals)\n",
        "    # we compute the number of new samples to be generated\n",
        "    N = int(oversample * (y_nimport.shape[0]) - y_import.shape[0])\n",
        "    new_samples_x, new_samples_y = generate_samples(x_import, y_import, neighbors, N)\n",
        "    # we merge the new samples with the old samples of the minority class and their labels\n",
        "    x_import = np.concatenate((x_import, new_samples_x))\n",
        "    y_import = np.concatenate((y_import, new_samples_y))\n",
        "    # we stack the samples and the labels of the majority and minority class\n",
        "    x_ret = np.concatenate((x_import, x_nimport))\n",
        "    y_ret = np.concatenate((y_import, y_nimport))\n",
        "    # x_ret represents the balanced dataset and y_ret the corresponding labels\n",
        "    return x_ret, y_ret"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contamination, scores, outliers_indices = Anomaly_Detection_Isolation_Forests(x_train, change_split=False)\n",
        "check_Isolation_Forests(contamination, outliers_indices)\n",
        "check_boundary_decision(scores, 0.02, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "DfZ34TkFCG_w",
        "outputId": "5aaf71aa-3cd6-47bc-d9d2-b7d380f241f9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAU3ElEQVR4nO3df6zd9X3f8ecrNhCyLLWBG+bZ3kwTT5VBiyEuuGr/oLAYQ7TZ7bIIpBWLsbhbjNRu7RbTTCOBIEGmlAmVMLnDw0xtDCONsIIzz6VUWaTx40IcgyHMN4YIew7cYH6UoRJB3/vjfLyeOOf6Ht9zf/hynw/pq/P9vr+f7/f7+dwLfp3vj3NuqgpJ0tz2vpnugCRp5hkGkiTDQJJkGEiSMAwkScD8me7ARJ111lm1bNmyme6GJM0qTzzxxI+raujY+qwNg2XLljE8PDzT3ZCkWSXJD3vVvUwkSTIMJEmGgSQJw0CShGEgScIwkCTRRxgkeX+Sx5J8L8m+JF9s9buTPJ9kT5tWtnqS3J5kJMneJBd07WtDkv1t2tBV/3iSp9o2tyfJVAxWktRbP58zeBu4pKreTHIK8J0k32rr/k1V3X9M+8uB5W26CLgTuCjJGcANwCqggCeS7KiqV1ubzwCPAjuBtcC3kCRNi3HPDKrjzbZ4SpuO90cQ1gH3tO0eARYkWQRcBuyuqiMtAHYDa9u6D1XVI9X54wr3AOsHGJMk6QT19QnkJPOAJ4CPAndU1aNJ/iVwc5J/DzwEbK6qt4HFwItdmx9stePVD/aoS7PSss0PztixX7jlkzN2bM1ufd1Arqp3q2olsAS4MMl5wPXALwC/CJwBfG7Ketkk2ZhkOMnw6OjoVB9OkuaME3qaqKpeAx4G1lbV4XYp6G3gvwAXtmaHgKVdmy1ptePVl/So9zr+lqpaVVWrhoZ+5nuWJEkT1M/TRENJFrT504FPAN9v1/ppT/6sB55um+wArm5PFa0GXq+qw8AuYE2ShUkWAmuAXW3dG0lWt31dDTwwucOUJB1PP/cMFgHb2n2D9wH3VdU3k/xZkiEgwB7gX7T2O4ErgBHgLeAagKo6kuQm4PHW7saqOtLmPwvcDZxO5ykinySSpGk0bhhU1V7g/B71S8ZoX8CmMdZtBbb2qA8D543XF0nS1PATyJIkw0CSZBhIkjAMJEkYBpIkDANJEn1+N5Gk2WGmvhfJ70Sa/TwzkCQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkugjDJK8P8ljSb6XZF+SL7b6OUkeTTKS5N4kp7b6aW15pK1f1rWv61v9uSSXddXXttpIks2TP0xJ0vH0c2bwNnBJVX0MWAmsTbIauBW4rao+CrwKXNvaXwu82uq3tXYkWQFcCZwLrAW+mmReknnAHcDlwArgqtZWkjRNxg2D6nizLZ7SpgIuAe5v9W3A+ja/ri3T1l+aJK2+varerqrngRHgwjaNVNWBqvoJsL21lSRNk77uGbR38HuAl4HdwA+A16rqndbkILC4zS8GXgRo618HzuyuH7PNWPVe/diYZDjJ8OjoaD9dlyT1oa8wqKp3q2olsITOO/lfmNJejd2PLVW1qqpWDQ0NzUQXJOk96YSeJqqq14CHgV8CFiQ5+jeUlwCH2vwhYClAW/9zwCvd9WO2GasuSZom/TxNNJRkQZs/HfgE8CydUPhUa7YBeKDN72jLtPV/VlXV6le2p43OAZYDjwGPA8vb00mn0rnJvGMyBidJ6s/88ZuwCNjWnvp5H3BfVX0zyTPA9iRfAr4L3NXa3wX81yQjwBE6/7hTVfuS3Ac8A7wDbKqqdwGSXAfsAuYBW6tq36SNUJI0rnHDoKr2Auf3qB+gc//g2PpfAv9kjH3dDNzco74T2NlHfyVJU8BPIEuSDANJkmEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJNFHGCRZmuThJM8k2Zfkt1r9C0kOJdnTpiu6trk+yUiS55Jc1lVf22ojSTZ31c9J8mir35vk1MkeqCRpbP2cGbwD/E5VrQBWA5uSrGjrbquqlW3aCdDWXQmcC6wFvppkXpJ5wB3A5cAK4Kqu/dza9vVR4FXg2kkanySpD+OGQVUdrqon2/xfAM8Ci4+zyTpge1W9XVXPAyPAhW0aqaoDVfUTYDuwLkmAS4D72/bbgPUTHZAk6cSd0D2DJMuA84FHW+m6JHuTbE2ysNUWAy92bXaw1caqnwm8VlXvHFOXJE2TvsMgyQeBrwO/XVVvAHcCHwFWAoeBr0xJD3+6DxuTDCcZHh0dnerDSdKc0VcYJDmFThD8UVX9CUBVvVRV71bVXwF/SOcyEMAhYGnX5ktabaz6K8CCJPOPqf+MqtpSVauqatXQ0FA/XZck9aGfp4kC3AU8W1W/31Vf1NXs14Cn2/wO4MokpyU5B1gOPAY8DixvTw6dSucm846qKuBh4FNt+w3AA4MNS5J0IuaP34RfBn4DeCrJnlb7PTpPA60ECngB+E2AqtqX5D7gGTpPIm2qqncBklwH7ALmAVural/b3+eA7Um+BHyXTvhIkqbJuGFQVd8B0mPVzuNsczNwc4/6zl7bVdUB/voykyRpmvkJZEmSYSBJMgwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJJEf3/cRpqVlm1+cKa7IM0anhlIkgwDSZJhIEnCMJAkYRhIkugjDJIsTfJwkmeS7EvyW61+RpLdSfa314WtniS3JxlJsjfJBV372tDa70+yoav+8SRPtW1uT5KpGKwkqbd+zgzeAX6nqlYAq4FNSVYAm4GHqmo58FBbBrgcWN6mjcCd0AkP4AbgIuBC4IajAdLafKZru7WDD02S1K9xw6CqDlfVk23+L4BngcXAOmBba7YNWN/m1wH3VMcjwIIki4DLgN1VdaSqXgV2A2vbug9V1SNVVcA9XfuSJE2DE7pnkGQZcD7wKHB2VR1uq34EnN3mFwMvdm12sNWOVz/Yo97r+BuTDCcZHh0dPZGuS5KOo+8wSPJB4OvAb1fVG93r2jv6muS+/Yyq2lJVq6pq1dDQ0FQfTpLmjL7CIMkpdILgj6rqT1r5pXaJh/b6cqsfApZ2bb6k1Y5XX9KjLkmaJv08TRTgLuDZqvr9rlU7gKNPBG0AHuiqX92eKloNvN4uJ+0C1iRZ2G4crwF2tXVvJFndjnV1174kSdOgny+q+2XgN4Cnkuxptd8DbgHuS3It8EPg023dTuAKYAR4C7gGoKqOJLkJeLy1u7GqjrT5zwJ3A6cD32qTJGmajBsGVfUdYKzn/i/t0b6ATWPsayuwtUd9GDhvvL5IkqaGn0CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSfT3x20k6biWbX5wRo77wi2fnJHjvhd5ZiBJMgwkSYaBJAnDQJJEH2GQZGuSl5M83VX7QpJDSfa06YquddcnGUnyXJLLuuprW20kyeau+jlJHm31e5OcOpkDlCSNr58zg7uBtT3qt1XVyjbtBEiyArgSOLdt89Uk85LMA+4ALgdWAFe1tgC3tn19FHgVuHaQAUmSTty4YVBV3waO9Lm/dcD2qnq7qp4HRoAL2zRSVQeq6ifAdmBdkgCXAPe37bcB609wDJKkAQ1yz+C6JHvbZaSFrbYYeLGrzcFWG6t+JvBaVb1zTL2nJBuTDCcZHh0dHaDrkqRuEw2DO4GPACuBw8BXJq1Hx1FVW6pqVVWtGhoamo5DStKcMKFPIFfVS0fnk/wh8M22eAhY2tV0SasxRv0VYEGS+e3soLu9JGmaTOjMIMmirsVfA44+abQDuDLJaUnOAZYDjwGPA8vbk0On0rnJvKOqCngY+FTbfgPwwET6JEmauHHPDJJ8DbgYOCvJQeAG4OIkK4ECXgB+E6Cq9iW5D3gGeAfYVFXvtv1cB+wC5gFbq2pfO8TngO1JvgR8F7hr0kYnSerLuGFQVVf1KI/5D3ZV3Qzc3KO+E9jZo36AztNGkqQZ4ieQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSfQRBkm2Jnk5ydNdtTOS7E6yv70ubPUkuT3JSJK9SS7o2mZDa78/yYau+seTPNW2uT1JJnuQkqTj6+fM4G5g7TG1zcBDVbUceKgtA1wOLG/TRuBO6IQHcANwEXAhcMPRAGltPtO13bHHkiRNsXHDoKq+DRw5prwO2NbmtwHru+r3VMcjwIIki4DLgN1VdaSqXgV2A2vbug9V1SNVVcA9XfuSJE2Tid4zOLuqDrf5HwFnt/nFwItd7Q622vHqB3vUe0qyMclwkuHR0dEJdl2SdKyBbyC3d/Q1CX3p51hbqmpVVa0aGhqajkNK0pww0TB4qV3iob2+3OqHgKVd7Za02vHqS3rUJUnTaKJhsAM4+kTQBuCBrvrV7ami1cDr7XLSLmBNkoXtxvEaYFdb90aS1e0poqu79iVJmibzx2uQ5GvAxcBZSQ7SeSroFuC+JNcCPwQ+3ZrvBK4ARoC3gGsAqupIkpuAx1u7G6vq6E3pz9J5Yul04FttkiRNo3HDoKquGmPVpT3aFrBpjP1sBbb2qA8D543XD0nS1PETyJIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJJEHx86kwaxbPODM90FSX3wzECSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSA4ZBkheSPJVkT5LhVjsjye4k+9vrwlZPktuTjCTZm+SCrv1saO33J9kw2JAkSSdqMs4MfrWqVlbVqra8GXioqpYDD7VlgMuB5W3aCNwJnfAAbgAuAi4EbjgaIJKk6TEVl4nWAdva/DZgfVf9nup4BFiQZBFwGbC7qo5U1avAbmDtFPRLkjSGQcOggP+R5IkkG1vt7Ko63OZ/BJzd5hcDL3Zte7DVxqr/jCQbkwwnGR4dHR2w65Kkowb9ewa/UlWHknwY2J3k+90rq6qS1IDH6N7fFmALwKpVqyZtv5I01w10ZlBVh9rry8A36Fzzf6ld/qG9vtyaHwKWdm2+pNXGqkuSpsmEwyDJ30jyN4/OA2uAp4EdwNEngjYAD7T5HcDV7ami1cDr7XLSLmBNkoXtxvGaVpMkTZNBLhOdDXwjydH9/HFV/fckjwP3JbkW+CHw6dZ+J3AFMAK8BVwDUFVHktwEPN7a3VhVRwbolyTpBE04DKrqAPCxHvVXgEt71AvYNMa+tgJbJ9oXSdJg/ASyJMkwkCQZBpIkDANJEoN/6EySZsyyzQ/O2LFfuOWTM3bsqeCZgSTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSfh1FHPGTH5sX9LJzzMDSZJhIEkyDCRJGAaSJAwDSRInURgkWZvkuSQjSTbPdH8kaS45KcIgyTzgDuByYAVwVZIVM9srSZo7TpbPGVwIjFTVAYAk24F1wDMz2qtJ5rP+0nvHTP3/PFV/bvNkCYPFwItdyweBi45tlGQjsLEtvpnkuTH2dxbw40nt4cnPMc8Nc23Mc228MM6Yc+vA+/+7vYonSxj0paq2AFvGa5dkuKpWTUOXThqOeW6Ya2Oea+OFmRvzSXHPADgELO1aXtJqkqRpcLKEwePA8iTnJDkVuBLYMcN9kqQ546S4TFRV7yS5DtgFzAO2VtW+AXY57qWk9yDHPDfMtTHPtfHCDI05VTUTx5UknUROlstEkqQZZBhIkmZvGCQ5I8nuJPvb68Ix2m1obfYn2dBj/Y4kT099jwc3yJiTfCDJg0m+n2Rfklumt/f9G++rSZKcluTetv7RJMu61l3f6s8luWw6+z2IiY45ySeSPJHkqfZ6yXT3faIG+T239X8nyZtJfne6+jyoAf/b/vtJ/lf7//epJO+f1M5V1aycgC8Dm9v8ZuDWHm3OAA6014VtfmHX+l8H/hh4eqbHM9VjBj4A/GprcyrwP4HLZ3pMPfo/D/gB8POtn98DVhzT5rPAf2rzVwL3tvkVrf1pwDltP/NmekxTPObzgb/d5s8DDs30eKZ6zF3r7wf+G/C7Mz2eafg9zwf2Ah9ry2dO9n/bs/bMgM7XVWxr89uA9T3aXAbsrqojVfUqsBtYC5Dkg8C/Br40DX2dLBMec1W9VVUPA1TVT4An6Xye42Tz/7+apPXz6FeTdOv+OdwPXJokrb69qt6uqueBkba/k92Ex1xV362q/9Pq+4DTk5w2Lb0ezCC/Z5KsB56nM+bZYpAxrwH2VtX3AKrqlap6dzI7N5vD4OyqOtzmfwSc3aNNr6+5WNzmbwK+Arw1ZT2cfIOOGYAkC4B/CDw0FZ0c0Lj9725TVe8Ar9N5p9TPtiejQcbc7R8DT1bV21PUz8k04TG3N3KfA744Df2cTIP8nv8eUEl2JXkyyb+d7M6dFJ8zGEuSPwX+Vo9Vn+9eqKpK0vczsklWAh+pqn917HXImTZVY+7a/3zga8Dt1b4YULNfknOBW+m8g3yv+wJwW1W92U4U5oL5wK8Av0jnDexDSZ6oqkl7Q3dSh0FV/YOx1iV5KcmiqjqcZBHwco9mh4CLu5aXAH8O/BKwKskLdH4GH07y51V1MTNsCsd81BZgf1X9x0no7lTo56tJjrY52MLt54BX+tz2ZDTImEmyBPgGcHVV/WDquzspBhnzRcCnknwZWAD8VZK/rKo/mPpuD2SQMR8Evl1VPwZIshO4gMk8u5/pmyoD3Iz5D/z0zdQv92hzBp3rigvb9DxwxjFtljF7biAPNGY690e+DrxvpsdynDHOp3PT+xz++ibbuce02cRP32S7r82fy0/fQD7A7LiBPMiYF7T2vz7T45iuMR/T5gvMnhvIg/yeF9K5z/eBtp8/BT45qf2b6R/QAD/YM+mk4v72gzn6D94q4D93tftndG4kjgDX9NjPbAqDCY+ZzruQAp4F9rTpn8/0mMYY5xXA/6bz5MXnW+1G4B+1+ffTeYpkBHgM+PmubT/ftnuOk/BpqckeM/DvgP/b9TvdA3x4pscz1b/nrn3MmjAYdMzAP6Vzw/xperwRHHTy6ygkSbP6aSJJ0iQxDCRJhoEkyTCQJGEYSJIwDCRJGAaSJOD/Ad3CaMtHZGaHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The indecision percentage around 0.02 is 0.3294876304373314\n",
            "The percentage of outliers detected is 0.05331435032033834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = drop_outliers(x_train, y_train, outliers_indices)"
      ],
      "metadata": {
        "id": "LGryUawLCfGL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c4WT7AvpFRs",
        "outputId": "729ecb42-df34-4cd5-8b7b-7c05707902f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11281\n",
            "[0.  0.1 0.2 0.3 0.4 0.5]\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = smote_sf_regression(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ESd8q6QBxvdu",
        "outputId": "593ad954-84c8-4efa-fc9b-7426d76f732e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe2bcb52550>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD5CAYAAAAqaDI/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhc9XXw8e8Z7fs6WizZlndjgzfE6rAHAllMUpIGWpKSkhKyNGmapUnevpTQ9m2TNm2ztYRAGkITQiAhmCUhLGY3xrKx5R3L8ibJ2qWRRvty3j9m1AhFskf23LmznM/zzMNo7tWdcx/hOfP7nd8iqooxxpjE5XE7AGOMMe6yRGCMMQnOEoExxiQ4SwTGGJPgLBEYY0yCs0RgjDEJLtnpNxCRJKAGaFTV9045lgb8BDgX6AA+rKpHTna94uJiraqqciZYY4yJU9u2bWtXVe90xxxPBMDngH1A7jTHbgW6VHWxiNwIfAP48MkuVlVVRU1NTfijNMaYOCYiR2c65mjXkIhUAu8B7p3hlOuB+4PPHwGuEhFxMiZjjDFv53SN4D+ALwPjMxyvAI4DqOoo4AOKHI7JGGPMJI4lAhF5L9CqqtvCcK3bRKRGRGra2trCEJ0xxpgJTrYI1gMbROQI8HPgShH5nynnNAJzAUQkGcgjUDR+G1W9R1WrVbXa65221mGMMeY0OZYIVPWrqlqpqlXAjcDzqnrzlNM2An8WfP7B4Dm2Cp4xxkRQJEYNvY2I3AXUqOpG4D7gARGpAzoJJAxjjDERFJFEoKovAC8En98x6fVB4EORiMEYY8z0bGaxMcYkOEsEUWxkbJxtRztp6h5wOxRjTByLeI3AhO6bv93PYzuaGBwZ45OXL+KTly92OyRjTByyRBClXq/v4FfbG/l/HziHkbFx/u9ju7lgYRHr5hW4HZoxJs5Y11CU+vrje/izi6rIzUihKDuNWy5ewOcf2sHYuI2uNcaElyWCKNTQ1U9T9yDnzv/9t//zqgrISEnid3uaXYzMGBOPLBFEoef2tbJ2Xj4ez+/X3xMR3n1OOd/fVIfNuTPGhJMlgij0m93NrJv7h7WAc+cX0D0wwhuHO12IyhgTrywRRJmewRFqG7o5pzLvD455RHjnWaU88PqMy4obY8ysWSKIMpsPdbCsNIf0lKRpj69fVMwLB9ro7h+OcGTGmHhliSDK7GrwsaA4a8bj2enJrJ2Xz6NvNkYwKmNMPLNEEGV2NfqoKpo5EQBcusTLg28cs6KxMSYsLBFEmb1NPVQVZ570nBVzcukZGGV3Y0+EojLGxDNLBFGk3T/E4OgYxdlpJz3PI8KlS4v5+dZjEYrMGBPPLBFEkT1NPSwozkJETnnuJUu8PL4zsA6RMcacCUsEUWR3YzfzCk/eLTShODuNRd5snraZxsaYM2SJIIrsauhh/ikKxZNdvqyE+1874lxAxpiEYIkgiuxr7mF+iC0CCMw0PtbZz74TVjQ2xpw+xxKBiKSLyBsislNE9ojI16c55xYRaRORHcHHx52KJ9qNjSsnugcpzU0P+XeSPMIV1iowxpwhJ1sEQ8CVqroaWANcKyIXTnPeQ6q6Jvi418F4olpT9wB5mSmkJs/uT3LF8hKe3HWCrj6baWyMOT2OJQIN8Ad/TAk+bAbUDI529FOeF3prYEJBZioXLCjkR68ediAqY0wicLRGICJJIrIDaAWeUdUt05x2g4jUisgjIjJ3huvcJiI1IlLT1tbmZMiuOdLRR0nOyecPzOQ958zhgc1H6R0cCXNUxphE4GgiUNUxVV0DVALni8jZU055HKhS1VXAM8D9M1znHlWtVtVqr9frZMiuOdzehzdn9i0CgLK8dM6uyOPHrx4Jb1DGmIQQkVFDqtoNbAKunfJ6h6oOBX+8Fzg3EvFEo/o2P2WzKBRPdcO6Su595TBtvUOnPtkYYyZxctSQV0Tyg88zgKuB/VPOKZ/04wZgn1PxRLujHf2UnUaNYEJZXjqXLCnmW787EMaojDGJwMkWQTmwSURqga0EagRPiMhdIrIheM5ng0NLdwKfBW5xMJ6oNT6uNHQPnHaNYML1ayp4ek8zuxt9YYrMGJMIkp26sKrWAmunef2OSc+/CnzVqRhiRXPPIDnpyTNuRhOq7LRkPnzePL78SC0bP7Oe5CSbL2iMOTX7pIgCR9r7KD+D+sBkly4pxuPBJpkZY0JmiSAKHO/qx3uG3UITRISPXbyA7zxfR1P3QFiuaYyJb5YIokBj1wAFWalhu96c/AyuXlHKHY/tDts1jTHxyxJBFGjoHqAoKzwtggkbVs9h74keXnorPifgGWPCxxJBFGjqHqAojC0CgJQkD39cPZd/fHIfY+O2socxZmaWCKJAU/cgRdnhTQQA51cVIgK/frMx7Nc2xsQPSwQuU1VaegbD3jUEgcLxB8+t5LvPH2TcWgXGmBlYInBZd/8IKUkeMlLPbA7BTFaU55LkEV54q9WR6xtjYp8lApc1dg+EbejodESEd60s4wcv1jv2HsaY2GaJwGUnfINhLxRPddHCIupa/Rxs6XX0fYwxsckSgctO+AYodDgRJCd5WL+4mF9ub3D0fYwxsckSgcsawjyZbCYXLyri0TcbrWhsjPkDlghc1tgV/jkE05lflEVGShJvHOl0/L2MMbHFEoHLmroHKMp2rlg82cWLivnVdptTYIx5O0sELmvucb5YPOG8qkKe29di3UPGmLexROAiVaXdP0RBZmQSQVleOhmpSexuso1rjDG/Z4nARd39I6SnJJGaHLk/w5q5+Ty3zyaXGWN+zxKBi1p6BymMUGtgwpq5+Ty7ryWi72mMiW5Obl6fLiJviMjO4L7EX5/mnDQReUhE6kRki4hUORVPNGrtGYrI0NHJlpXlcLSjn9aewYi+rzEmejnZIhgCrlTV1cAa4FoRuXDKObcCXaq6GPh34BsOxhN1WnoGyctIieh7Jns8rJyTy+b6joi+rzEmejmWCDTAH/wxJfiYOlzleuD+4PNHgKtERJyKKdq09g6RH+FEALC8LIdXDrZH/H2NMdHJ0RqBiCSJyA6gFXhGVbdMOaUCOA6gqqOADyia5jq3iUiNiNS0tcXPjlvNvkHyMiOfCFbMyeN1axEYY4IcTQSqOqaqa4BK4HwROfs0r3OPqlararXX6w1vkC5q6RmM2NDRySoLMugZHOWEzza3N8ZEaNSQqnYDm4BrpxxqBOYCiEgykAckzFfVlp5B8l1oEXhEWDEn11oFxhjA2VFDXhHJDz7PAK4G9k85bSPwZ8HnHwSeV9WEmfba2hu5yWRTLSvN4dWDlgiMMc62CMqBTSJSC2wlUCN4QkTuEpENwXPuA4pEpA74a+ArDsYTVVSVDv+wa4lgeVkOW20BOmMMkOzUhVW1Flg7zet3THo+CHzIqRiimW9ghJRkieis4snmFmTS7h+is2/Y8f0QjDHRzWYWu6SlZ8iRDetD5fEIS0pzePNYl2sxGGOigyUCl7T2ulMonmyRN4uaI5YIjEl0lghc0tLjzmSyyRaX5FBz1OoExiQ6SwQuaesdivjyElMtKclmT1MPI2PjrsZhjHGXJQKXtPUOkutyIshKS6Y4O439J3pdjcMY4y5LBC5p6XG/RQCwuCSbHQ3dbodhjHGRJQKXtPmjIxFUFWXZyCFjEpwlApd0+IfId2ky2WSLvFnUHretK41JZJYIXNLuH46KFsG8wkwauvvpGxp1OxRjjEssEbhgZGwc/9AoOWmOTewOWXKSh/mFWexutFaBMYnKEoELOvsCrQGPJzr24FngzaK2wRKBMYnKEoEL2nqHKHB5VvFkC6xgbExCs0TggmgZMTRhkTebndYiMCZhWSJwQXvvkOuTySYrz0uns28YX/+I26EYY1xgicAFbf4hctPdLxRP8HiEhd4sdjdZq8CYRGSJwAWtPUPkprs/h2Cy+UWZ7LKRQ8YkJEsELoiGJainqirKYsdxW2rCmERkicAF0bDy6FQLi7NtLoExCcrJzevnisgmEdkrIntE5HPTnHO5iPhEZEfwccd014o3HVEyq3iy8rx0OvxWMDYmETlZsRwFvqCq20UkB9gmIs+o6t4p572squ91MI6o0x5lw0fh7QXj9YuL3Q7HGBNBjrUIVPWEqm4PPu8F9gEVTr1frBgZG6dveIzsKBo1NMEKxsYkpojUCESkClgLbJnm8EUislNEfiMiK2f4/dtEpEZEatra2hyM1Hn/u7yERMfyEpNVFWVRawVjYxKO44lARLKBXwJ/pao9Uw5vB+ar6mrgu8Cvp7uGqt6jqtWqWu31ep0N2GHtfvf3Kp5JVVGWtQiMSUCOJgIRSSGQBH6qqr+aelxVe1TVH3z+FJAiInHdQR0ty09PpyI/g3b/ED2DVjA2JpE4OWpIgPuAfar6bzOcUxY8DxE5PxhPh1MxRYMOf3QtLzGZxyNU2TBSYxKOkxXL9cBHgF0isiP42teAeQCqejfwQeCTIjIKDAA3qqo6GJPr2v1D5ERhoXhCVVEmexp7uHhRXDfMjDGTOPaJpKqvACetiKrq94DvORVDNGrtHSInPTpbBBAYOWQzjI1JLDazOMICs4qjt0WwwLqGjEk4lggirD0Kl5eYrCI/g9beIXqtYGxMwrBEEGEdfcPkRnHXUJJHqCrKZHfj1JG+xph4FVIiEJFfich7RMQSxxmKxnWGpqoqzmJXo9UJjEkUoX6w/yfwJ8BBEflnEVnmYExxS1Xp6h+O2uGjE2xJamMSS0iJQFWfVdU/BdYBR4BnReQ1EflYcNKYCYFvYIT0lCRSkqK7YbWgOItdtoexMQkj5E8kESkCbgE+DrwJfJtAYnjGkcjiULt/OOo2pJlOYIbxML4BKxgbkwhCrRE8CrwMZALvU9UNqvqQqv4lkO1kgPEkGpefno7HIywozrJhpMYkiFBbBD9U1RWq+k+qegJARNIAVLXasejiTIc/+usDE6qKs6htsDqBMYkg1ETwD9O8tjmcgSSCdv8QuVG8vMRkC4uzePOYJQJjEsFJP5VEpIzAZjIZIrKW3y8ZkUugm8jMQlvvENlpsdEiWOTN5uFtx90OwxgTAaf6evouAgXiSmDyCqK9BBaQM7MQjZvWz6Q0N43+4TFaewYpyU13OxxjjINOmghU9X7gfhG5QVV/GaGY4labf4g5+RluhxESEWFJSTY7G3xcvcISgTHx7FRdQzer6v8AVSLy11OPz7TPgJletK8zNNWC4ix2HOvi6hWlbodijHHQqbqGsoL/tSGiYdDRF/3LS0y2sDibVw+1ux2GMcZhp+oa+kHwv1+PTDjxrbNvmNwoXoJ6qkUl2dz90iHGxxWP56RbSxhjYlioE8q+KSK5IpIiIs+JSJuI3Ox0cPGkf3iUMVUyUpLcDiVkeRkpZKclc6jN73YoxhgHhTqP4BpV7QHeS2CtocXAl072CyIyV0Q2icheEdkjIp+b5hwRke+ISJ2I1IrIutneQKzo8A+Tn5FCcIvmmLGkJJvtx7rcDsMY46BQE8FEf8Z7gIdVNZS1B0aBL6jqCuBC4NMismLKOdcBS4KP24D/CjGemNPmH4qJdYamWuTNZusRSwTGxLNQE8ETIrIfOBd4TkS8wODJfkFVT6jq9uDzXmAfgclpk10P/EQDXgfyRaR8VncQI2JhH4LpLCnNYftRSwTGxLNQl6H+CnAxUK2qI0AfgQ/xkIhIFbAW2DLlUAUwefpqA3+YLOJCuz+6N62fybzCTE74BvH120qkxsSr2QxhWU5gPsHk3/nJqX5JRLKBXwJ/FawzzJqI3Eag64h58+adziVc194bO+sMTZbkERaXZPPm8S4uX1bidjjGGAeEOmroAeBfgXcA5wUfp1x1NLhpzS+Bn6rqr6Y5pRGYO+nnyuBrb6Oq96hqtapWe73eUEKOOm3+oZhZeXSqxd4saqxOYEzcCvUrajWwQlU11AtLYHjMfcC+k8xA3gh8RkR+DlwA+CaWuY43rb1DLPbG5ry8ZWW5PLuvxe0wjDEOCbVYvBsom+W11wMfAa4UkR3Bx7tF5HYRuT14zlNAPVAH/BD41CzfI2bEyqY001lamsOeph6GRsfcDsUY44BQWwTFwF4ReQMYmnhRVTfM9Auq+gq/X7Z6pnMU+HSIMcS0WB01BJCRmkRlQQa1DT7Oqyp0OxxjTJiFmgjudDKIRNARwy0CCLQKttR3WCIwJg6FOnz0RQIzilOCz7cC2x2MK66MjI3TNzxGdgyOGpqwrCyHzfUdbodhjHFAqKOG/gJ4BPhB8KUK4NdOBRVvJrqFPDG2vMRky8py2HG8m5GxcbdDMcaEWajF4k8TKP72AKjqQcAGlYeo3T9EQQwuLzFZbnoKpTnptqG9MXEo1EQwpKrDEz8EJ5WFPJQ00cXSFpUns2JOLq8ctP0JjIk3oSaCF0XkawQ2sb8aeBh43Lmw4ktbjBeKJ6yck8tLlgiMiTuhJoKvAG3ALuATBMb//61TQcWbtt4hcmK4UDxheVkue5t66B8edTsUY0wYhfTppKrjIvJr4Neq2uZwTHGnrXeQvIxUt8M4Y+kpSSz0ZvHG4U5bd8iYOHLSFkFw45g7RaQdOAAcCO5OdkdkwosPLT3x0TUEgTrBS2/ZdwFj4smpuoY+T2C00HmqWqiqhQTWBFovIp93PLo4ES81AoDVlfk8v7/V7TCMMWF0qkTwEeAmVT088YKq1gM3Ax91MrB40h4no4YAFhRn4RsY4VhHv9uhGGPC5FSJIEVV/2CYSLBOEB+fbBHQ2Tcck9tUTscjwpq5+Ww6YK0CY+LFqRLB8GkeM0FDo2P0D4+RlRb7o4YmrKrMt2WpjYkjp/p0Wi0i0+0qJkC6A/HEnQ5/oDUQy8tLTLWqMo8fvlxP//Aomanxk+CMSVQnbRGoapKq5k7zyFHV+OjrcFhb7xD5mbE/dHSyzNRklpbm8OIBGz2UqFp7B9l2tIum7gG3QzFhYF/nHNbuHyI/TgrFk62bV8CTu05w3TnlbodiIkhVueelev7zhUOU5aZzomeADavm8LX3nGWtwxgW6sxic5raemN3r+KTqa4q4MW32hgetdVIE8mPXzvCz7ce5873reTODSv51ofWcKSjj5vv3WI72MUwSwQOa/cPkRsHy0tMVZCZytyCTF47ZGsPJYrdjT6+/dxBPnfVEsryAiXC7LRkPnn5YtKSk/jSw7XMYltzE0UcSwQi8iMRaRWR3TMcv1xEfJP2M47L2crNvsG4mUMw1bnzC3hi5wm3wzARcsdju7nxvLmU5r59nIhHhE9ctpBdjd1s3NnkUnTmTDjZIvgxcO0pznlZVdcEH3c5GItrWnoH465YPOHChUX8bm8zgyPWJRDvao50csI3yDsWe6c9npacxJ+vX8hdj++lu99GlscaxxKBqr4EdDp1/VjR4huiIE4TQWFWKvOLsnjBRg/Fve9vquO6c8pI8sw8DHpxSTbnLSjkG7/dH8HITDi4XSO4SER2ishvRGTlTCeJyG0iUiMiNW1tsfWh0+YfiptZxdO5YGEhj77Z4HYYxkFHO/p481g3ly059YqzN6yt5KldJzja0ReByEy4uJkItgPzVXU18F1Osgeyqt6jqtWqWu31Tt80jUaqSod/OG5bBAAXVBXxysF2fAMjbodiHLJxZxMXLCwkNfnUHxfZ6clcvaKMf3vmrQhEZsLFtUSgqj2q6g8+fwpIEZFit+Jxgm9ghNRkT0j/gGJVdnoyqyrzeNyKhHFr444mLlxQFPL5151dxosH2jjU5ncwKhNOrn1CiUiZSGDdBRE5PxhLh1vxOKGlZ4jCrPhtDUy4dKmXB9845nYYxgEHW3rp6h9maVlOyL+TmZrMO88q4Z6X6h2MzISTk8NHHwQ2A8tEpEFEbhWR20Xk9uApHwR2i8hO4DvAjRpng5Bbewfjuj4wYVVFPi09g+xvnm5ZKhPLHt/ZxAULima9VtbVK8p4atcJ2nqHHIrMhJOTo4ZuUtVyVU1R1UpVvU9V71bVu4PHv6eqK1V1tapeqKqvORWLW1p74nfE0GQej3DJEi8PbrFWQbx5dl8L6+YXzPr3cjNSuGhhEfe/diT8QZmwi9/O6yjQ0jsYl7OKp3PFshIefbPRNraPI519wxzt6GdpSfZp/f41K8v42ZajtvREDLBE4KAWX/xOJpvKm5PGsrIcNu6wonG8eLWunRVzcklOOr2PiYr8DOYWZvLb3c1hjsyEmyUCB7X0DFGQADWCCVctL+W/Xzti683EiRcPtLGiPO+MrnHV8lL++9Uj4QnIOMYSgYOaexKnRQBwTmUe/sFRth7pcjsUc4ZUlZcOtrGq8swSwbr5BTR29bO3yQYSRDNLBA5q602MYvEEjwjXrCzlhzZsMObVt/ehQHnemW1EmOQRLltWws+2HA1PYMYRlggcoqqBTWkSqGsI4NIlXrYc6bAlBmLc1sOdrCjPRcKwxerlS71s3NnEwLAVjaOVJQKH9AyOkuQR0lOS3A4lotJTkrhyWQn3vXLY7VDMGXjjcCeLvKc3Wmiqouw0lpTm8OQuW7I8WlkicEizbxBvdprbYbji6hVlPPpmI119thxxrNp6pJPls5hNfCqXLfXy09eteyhaWSJwyAnfAIXZiVMfmKwwK5Xzqwr5sU0mikltvUN09Y9QUZARtmuunZfPkY4+6m39oahkicAhzb7BhCoUT/Xuc8r5yeYjNsEsBm07GmgNzHZZiZNJ9nh4x+JiflFzPGzXNOFjicAhTd0DCTWHYKo5+RksK8uxZSdi0NYjXSw6zdnEJ3PpUi+PbGtgdGw87Nc2Z8YSgUMauwcozErMGsGEDasruPvFeltiIMbUHOk87WUlTqayIJOi7DRefCu2NpdKBJYIHHLCN5gQS1CfzILiLOYVZfJIje1gFitGxsY50NLLwjCNGJrqkiXF/HyrdQ9FG0sEDmn2DVKU4IkAYMPqOXxvUx3Do9YdEAsONPdSlpvu2LDnixYWsflQBx1+W546mlgicEhLr7UIAJaW5lCSk8avtlurIBbsON7NQm+WY9fPTE3m3PkF/PrNRsfew8yeJQIH9A6OMD6uZKYm1mSymbx/bQXffb6OESsSRr3tx7pYUOxMt9CES5YU8+DW47Y4YRSxROCAZt8gxTlpYZmeHw+Wl+VSlJ1qrYIYsPN4d9hmFM/krPJc+oZGqW3wOfo+JnSWCBxwwjdIUYKPGJrqA2sr+PazB61WEMX8Q6M0dg8wtzB8E8mm4xEJFo1taHG0cHLP4h+JSKuI7J7huIjId0SkTkRqRWSdU7FEWmAyWeLOIZjO8rJcSnLTeXibjRiJVrsafFQVZZHscf774aVLvDxRe8IWoosSTv7Ffwxce5Lj1wFLgo/bgP9yMJaIauoeSKh9CEL1R2sr+M5zBxkcsX/80WhXYzcLip0rFE9WlJ3G0pIcnrKF6KKCk5vXvwR0nuSU64GfaMDrQL6IlDsVTyQ1dA/YiKFpLCnNYW5BJg++YV0C0WjH8W7mF0UmEUBwITrbpyAquFkjqAAm9xM0BF/7AyJym4jUiEhNW1v0z0o83tlPSY7VCKbzR+sq+f6mOusSiEK7GnwsjFCLAGDt/HyOdvRT19obsfc004uJYrGq3qOq1apa7fV63Q7nlBq7BxJ2CepTWVCcxZLSHP77VduvIJr4BkZo9w9Rke9soXiyZI+HS5Z4+amtR+U6NxNBIzB30s+Vwddi2ti40tITGD5qpvfBdZXc81I9vv4Rt0MxQXsafSwozsbjieyQ58uXeXl0e6PVjVzmZiLYCHw0OHroQsCnqjFfOWrpGSQ3I4WUpJhobLliTn4G1VUF/NeLdW6HYoJ2NfqYX5QZ8fctzU1nkTebJ2pj/p9+THNy+OiDwGZgmYg0iMitInK7iNwePOUpoB6oA34IfMqpWCKpoWuAkpwz2/A7Ebx/TQU/23KMZt+g26EYAhPJIjViaKorl5fw49esq9BNTo4auklVy1U1RVUrVfU+Vb1bVe8OHldV/bSqLlLVc1S1xqlYIul4Zz/eBN2ZbDaKstO4YnkJ//q7A26HYoDaRp9riWDN3Hzaeoeobeh25f1NjBSLY0lDVz9FVigOyftWzeHZvS0caLZRI27yDYzQ4R9mTl7kCsWTeTzCVctL+dEr1ipwiyWCMDva2U+xJYKQZKUls2HNHP7+ib1uh5LQ9jT6WOjNiniheLIrlpXw3P5WWnutq9ANlgjC7HhnP14bMRSyq1eUcrijj00HWt0OJWHVulQoniw7PZmLFxbxwGabYOYGSwRh1tBlcwhmI9nj4U/Om8ddj++1BelcsuN4N1URnFE8k6tXlvE/rx+1oaQusEQQRqNj47T7hyi2YvGsrJ2XT0Fmio0cccluFwvFk1XkZ7C4JJtf2FaWEWeJIIxO+AbJz0gl2eYQzIqIcPOF8/n+pkO09FgfcST5+t0tFE/13lVzuPvFQ4zaJkYRZZ9YYXS4vY/yfJtDcDrK8zK4cnkJf/fYHrdDSSi7m9wvFE+2tDSHgqxUnrRVSSPKEkEY1bf5Kcu1RHC63r+mgp0N3Ty/v8XtUBLGziipD0z2vlVz+PazBxkbt60sI8USQRgdauuj1BLBaUtN9vCx9Qv42q920zto6xBFwvZjXY5uVn86VlXmkZLksb0KIsgSQRgdavNTnmeJ4EycU5HHyjm5/MMT+9wOJSHUNvgc36N4tkSE96+dw78/+5a1CiLEEkEYHW7vozxKim6x7E8umMemA628YHMLHNXSM8jgyFhU7p2xujKf1CQPG3fG/ILEMcESQZgMjozR4R+2yWRhkJmazF9cspAvPVxLu3/I7XDi1s7j3SwuyUEkOgrFk4kIH6qey7/89oDNL4kASwRhcrSjn9K8NJKiZPRFrDu7Io/1i4v4wi92Mm7dA47YebybqmJ3ZxSfzIryXMry0m07ywiwRBAmh9v91i0UZjecW0mzb5C7XzzkdihxafuxbhYVR1d9YKo/rp7Ld547aJsYOcwSQZjUt/fZ0NEwS/Z4+MsrF3PvK4d5ra7d7XDiyti4sqvRx6KS6E4E84uyOHd+Ad95/qDbocQ1SwRhUtfit6GjDijKTuOTly3iMw++ybGOfrfDiRsHW3vJy0ghLyPF7VBO6YZ1lbB4xxsAAA+DSURBVDyy7TiH2vxuhxK3LBGEyb7mHuYWWNeQE86uyGPD6jl87Mdv0GPzC8Ki5kgXS0ujuzUwIT8zlQ2rK7jj17tRtXqREywRhMHo2DiH2/uYWxi9hbdYd82KUhaXZPOJn2yzUSRhsPVwZ9R3C012zcpSGroG+M3uZrdDiUuOJgIRuVZEDohInYh8ZZrjt4hIm4jsCD4+7mQ8Tjnc3kdhVirpKUluhxK3RISPXljF6Pg4X3zYRhKdqZqjXSwrzXE7jJAlezzccnEVd27cY61CBzi5eX0S8H3gOmAFcJOIrJjm1IdUdU3wca9T8ThpX3Mv86NsvZZ45PEIn75iMXWtfu58fI91E5ym1t5BegZHmJMfW12Zy8tzWV2Zxz89ZbPOw83JFsH5QJ2q1qvqMPBz4HoH3881e5t8VMbYP6pYlZacxF9fvZRX69r5xm/3WzI4DduOBFoDniicSHYqHz5vHs/sbWHzoQ63Q4krTiaCCmDyDhMNwdemukFEakXkERGZO92FROQ2EakRkZq2tjYnYj0je5p6mGf1gYjJSkvmy9cu5ze7m/nW796yZDBLr9S1s6wsdrqFJstKS+Zj6xfwhYd34B8adTucuOF2sfhxoEpVVwHPAPdPd5Kq3qOq1apa7fV6IxpgKA4091oiiLDc9BS+et1ZPF7bxDefPmDJYBZerWtn5Zw8t8M4bevmFbC8LIe/f3yv26HEDScTQSMw+Rt+ZfC1/6WqHao6sZjMvcC5DsbjiK6+YfqGRm2NIRfkZaTwtevO4re7m/n643usgByCZt8gnX3Drm9Wf6b+9IL5vHSwjd/YUtVh4WQi2AosEZEFIpIK3AhsnHyCiJRP+nEDEHNVoNrgfq/RuHBXIsjNSOFr7z6L1+s7+eLDO22Lw1N47VA7KyvyYrI+MFlmajKfunwxX3t0F8c7baLhmXIsEajqKPAZ4GkCH/C/UNU9InKXiGwInvZZEdkjIjuBzwK3OBWPU2oOd7I4hsZjx6PstGT+5trlHO7o49b7a+gftr7jmbx8sI3lMVofmGpxSTbvXTWHTzywjcGRMbfDiWmO1ghU9SlVXaqqi1T1H4Ov3aGqG4PPv6qqK1V1tapeoar7nYzHCW8c6WRJDI3HjlfpKYHRRB6BD/7XZlp7Bt0OKeqoKq/WdXB2DNcHprru7DLyMlL420dt1vGZcLtYHNNGx8bZ1ehjaYklgmiQ7PHwF5cs5JyKPN73vVeobeh2O6Sosruxh5QkT1ztoici3HbpQrYd6+IHL9a7HU7MskRwBvY391KcnUZ2erLboZigwDaHFfzJ+fP5yH1v8NDWY26HFDWe3tPMufML4q6elZ6SxBeuXsq9r9Tz+M4mt8OJSZYIzsD2Y10ssfpAVDp/QSF/+56z+N7zdfzVz3fQa8sS8PSeZtbNK3A7DEcUZafxxWuWccdju9m037Y4nS1LBGdgS31sLdyVaCoLMrnr+rPpHRzh2v94mdfrE3c26rGOftr8Q3H9xWV+URaff+dSPv+LHTy7t8XtcGKKJYLTNDauvFrXzjkV8VN4i0fpKUl8/JKF3HT+PD7zs+38zS9r6eobdjusiHtyVxPV8wvwxPlWqktKc/jiNcv40iM7eaTm+Kl/wQCWCE7bjuNd5GelUJxtE8liwbnzC/jGDavoGRjhym+9wI9eOczQaGIMOVRVHtrawPrFxW6HEhGLvNn8n3ev4FvPvMU//2YfYzbR8JQsEZym5/a1sqYy3+0wzCxkpibz0Yuq+Mp1Z/HkrhNc8S8v8LMtx+I+IWw/1sXo+HhMLTt9pioKMrjzfSvZfKiDG+/ZzAnfgNshRTVLBKfpmb0trJkbn4W3eDevMJMvXrOM2y5dxCPbjrP+n5/nu88dpN0/dOpfjkEPbjnOpUu8cTda6FRyM1L48ruWs8ibzXX/8TI/3XLUliGZgY17PA2N3QO09A7GdeEtESwry+FLZcs52tHH7/Y284OX6rl0aTE3nT+PixcVkxQH/ekd/iGe3tvMN25Y5XYorvB4hOvXVLB2XgE/euUwD245xtevX8m58wvdDi2qSKzNxquurtaamhpXY/j+poO8eaybW9+x0NU4THj5h0Z5ta6dlw+20Ts4yoY1c7h+dQVnV+TG7Lfpf3pqH4fb+/jY+gVuh+K6cQ0M8Hh4WwNnz8nlC9cs4+wEGuwhIttUtXraY5YIZmd8XLnkm5u4/bJFtsZQHDve2c/m+g621HcgIrxnVTnXnV3G6sr8mBl50+Ef4op/fYF//MA5NqhhkuHRcZ7b38KTtSdYMzefz161hNVz47/ed7JEYF1Ds/R6fQepyR4WeW1ryng2tzCTuYWZfOjcSo509LP1cAefffBNBkfGeeeKEt61soyLFhWRlhy9+1R/63dvcdGiIksCU6Qme7ju7HKuWl7KpgOtfPz+rSwtzeFz71zK+QsSs8vIWgSz9Mn/2UZpbjrvWlnmWgzGPY3dA2w72smO490c6+znwoVFXH1WKZct81KeFz3blb5ysJ3P/2IH//SBc8hKs+97JzMyNs7LB9t5oraJivwMPn/1Ui5eVBSz3YEzsa6hMNnb1MOf3vs6//qh1WSm2j+uRNczMMLOhm5qG7qpbfBRnJ3GpUuLecdiL+cvLCQ3PcWVuJp9g1z//Vf48/ULWGVDnEM2Nq68dqidx3Y2UZITWLIinhKCJYIw+ch9W1jkzbbWgPkD4+PK4Y4+djX62H+ih7da/MwvyuT8BYVUVxWydm4+lQUZjn+otPUO8aG7X+PiRcW8b/UcR98rXo2PK68eauexHU2U56XzxXct48KFRW6HdcYsEYTBpv2tfO3RXXzzhlUkJ9n0C3Nyo2Pj1Lf38VZLL3Wtfupa/YyNKysrcjmnIo+Vc/I4qzyH+UVZpITp/6cXDrTy5UdquXJ5CdevqQjLNRPZ2LjySl07j+1oZF5hJl+4ZllM1xAsEZyhhq5+NnzvVT5zxWLOKs+N6Hub+KCqdPWPUN/u52hHPw1d/Rzr7KfdP0xFfgYLvVksKs5mXlEmFfkZlOWlU5qbTn5GyoyjlMbHlYauATbXt/PgG8dp9g1y6zsWJNSQyEgYHQ/UEB7f2URFQQZ/eeUSLl1SHHNdRq4lAhG5Fvg2kATcq6r/POV4GvATApvWdwAfVtUjJ7tmpBNBu3+Im+/dQvX8At6zypraJryGR8c54RugqXuQlt5BOvxDdPiH6ewbpqNvmIGRMbLTkslOSyYjNYlkjzA2rvQNj9HuHyInLZmzynOpriqgen5hXEyCi1aj4+NsPtTBU7tOkJLk4dZ3LOB9q+fETDHelUQgIknAW8DVQAOBzexvUtW9k875FLBKVW8XkRuBD6jqh0923Ugmgr1NPXzigRrOX1DIDesqY+4bgIl9o2Pj9A+P0T88xtDoGOMKIpCenER+ZgrpKdE7fDVeqSq7Gn08u6+F/c29XLOilPevreDChUVh6+ZzglvzCM4H6lS1PhjEz4Hrgb2TzrkeuDP4/BHgeyIi6mJ/laqyp6mHBzYf5Xd7m7np/HlcssTrVjgmwSUnecjN8JCb4c4IJPOHRIRVlfmsqsyns2+Y1+s7+Icn9tHkG+CCBYWsX1zM6rn5LC/LiZnRhU5GWQFMXhC8AbhgpnNUdVREfEAR0O5EQF19wzxe28TImDIyNs7QyDj9w6N09Q9zwjdIfVsfjd2BVQrXzcvn9ssWkZ2WTH2b34lwjDFxYHlZDsvLcujuH2FPk48HXj/K1x///ffd7LRkyvPSKc5OozArlZz0ZLLSkklP8ZCWnERKkodkj+DxCEkSSDQeAUSY6IOY6IxYv6iYquLwT2aNiXQlIrcBtwV/9IvIgdO5jiczryg511sFMNbvIylzmqKajo/r2NhQE8oTpxlvNBgf8Cd7MrJH3Y7DCfF8b2D3F+t+f38ikpSUing8B8N07bGB3rYxX8vpbsQ9f6YDTiaCRmDupJ8rg69Nd06DiCQDeQSKxm+jqvcA94QzOBGpGfW1TttfFg9EpGbU3xGX9xfP9wZ2f7EuFu/PycrGVmCJiCwQkVTgRmDjlHM2An8WfP5B4Hk36wPGGJOIHGsRBPv8PwM8TWD46I9UdY+I3AXUqOpG4D7gARGpAzoJJAtjjDER5GiNQFWfAp6a8todk54PAh9yMoaTCGtXUxSK5/uL53sDu79YF3P3F3Mzi40xxoRX9M5+MMYYExFxnQhE5FoROSAidSLylWmOp4nIQ8HjW0SkKvJRnr4Q7u+vRWSviNSKyHMiMuPwsWh0qvubdN4NIqIiElMjNUK5PxH54+DfcI+I/CzSMZ6JEP7/nCcim0TkzeD/o+92I87TISI/EpFWEdk9w3ERke8E771WRNZFOsZZUdW4fBAoUB8CFgKpwE5gxZRzPgXcHXx+I/CQ23GH+f6uADKDzz8Zb/cXPC8HeAl4Hah2O+4w//2WAG8CBcGfS9yOO8z3dw/wyeDzFcARt+Oexf1dCqwDds9w/N3AbwABLgS2uB3zyR7x3CL43yUuVHUYmFjiYrLrgfuDzx8BrpLYWVDolPenqptUtT/44+sE5nLEilD+fgB/D3wDGIxkcGEQyv39BfB9Ve0CUNXWCMd4JkK5PwUmlvPNA5oiGN8ZUdWXCIx0nMn1wE804HUgX0TKIxPd7MVzIphuiYupi7S/bYkLYGKJi1gQyv1NdiuBbyix4pT3F2xuz1XVJyMZWJiE8vdbCiwVkVdF5PXgar6xIpT7uxO4WUQaCIwu/MvIhBYRs/336aqYWGLCnBkRuRmoBi5zO5ZwEREP8G/ALS6H4qRkAt1DlxNozb0kIueoarerUYXPTcCPVfVbInIRgTlFZ6vquNuBJZp4bhHMZokLTrbERZQK5f4QkXcC/wfYoKpDEYotHE51fznA2cALInKEQD/sxhgqGIfy92sANqrqiKoeJrCs+5IIxXemQrm/W4FfAKjqZiAdKI5IdM4L6d9ntIjnRBDvS1yc8v5EZC3wAwJJIJb6l+EU96eqPlUtVtUqVa0iUAPZoKrubGg9e6H8//lrAq0BRKSYQFdRfSSDPAOh3N8x4CoAETmLQCJoi2iUztkIfDQ4euhCwKeqJ9wOaiZx2zWkcb7ERYj39y9ANvBwsAZ+TFU3uBb0LIR4fzErxPt7GrhGRPYCY8CXVDUmWqwh3t8XgB+KyOcJFI5viZUvYiLyIIEkXRyscfwdkAKgqncTqHm8G6gD+oGPuRNpaGxmsTHGJLh47hoyxhgTAksExhiT4CwRGGNMgrNEYIwxCc4SgTHGJDhLBMYYk+AsERhjTIKzRGCMMQnu/wOKcaBYb+v8QwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.kdeplot(y_train, fill=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a63d2612",
        "outputId": "44cc600d-4c70-4a7d-afa7-01b5b64a6542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:16:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ],
      "source": [
        "# we use XGB regressor model with the following hyperparameters\n",
        "\n",
        "model = XGBRegressor(subsample = 0.8999999999999999, n_estimators= 500,\n",
        "                     max_depth = 20, learning_rate = 0.01, colsample_bytree = 0.7999999999999999, colsample_bylevel = 0.6, obj=MSE)\n",
        "model.fit(x_train, y_train,eval_metric=MSE)\n",
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "b6898c6e",
        "outputId": "6e348cbb-d0dc-4205-a95f-e91e136b0f02"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 842.4x595.44 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "range_values = np.arange(0.05,1.05,0.1)\n",
        "mse_ranges = []\n",
        "for val in range_values:\n",
        "    labels_range = y_test[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    correspondent_predictions = predictions[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    mse_ranges.append(MSE(correspondent_predictions, labels_range))\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "intervals = ['0.0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4','0.4-0.5', '0.5-0.6', '0.6-0-7', '0.7-0.8', '0.8-0.9', '0.9-1.0']\n",
        "dict_mse = {'intervals': intervals, 'mse': mse_ranges}\n",
        "df_mse = pd.DataFrame.from_dict(dict_mse)\n",
        "sns.barplot(x = df_mse['intervals'], y = df_mse['mse'], color='blue')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}