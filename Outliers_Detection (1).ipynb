{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "OVkUbtoxrZN3",
   "metadata": {
    "id": "OVkUbtoxrZN3"
   },
   "source": [
    "Importing useful libraries and importing the drive for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc466260",
   "metadata": {
    "id": "dc466260"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import io\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "jjM2luKFSayr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjM2luKFSayr",
    "outputId": "b985c4f6-23b5-4579-ef5e-35787b7dcae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FkcqxT8Eo-D2",
   "metadata": {
    "id": "FkcqxT8Eo-D2"
   },
   "source": [
    "Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "z6__FhQiuUag",
   "metadata": {
    "id": "z6__FhQiuUag"
   },
   "outputs": [],
   "source": [
    "pddata = pd.read_csv('GSM1586785_ScrH-12A_Exd_14mer_cg.csv.zip', compression='zip', error_bad_lines=False, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7Onini8BliWv",
   "metadata": {
    "id": "7Onini8BliWv"
   },
   "outputs": [],
   "source": [
    "pddata = pddata.to_numpy()\n",
    "RelKa = pddata[:, -1]\n",
    "training_data = pddata[:, 2:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_k3VzeutCXDe",
   "metadata": {
    "id": "_k3VzeutCXDe"
   },
   "source": [
    "Some helpers function for the analysis below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "iOBmnZCWDJEC",
   "metadata": {
    "id": "iOBmnZCWDJEC"
   },
   "outputs": [],
   "source": [
    "def drop_outliers(x, y, outliers):\n",
    "    x = np.delete(x, outliers, axis=0)\n",
    "    y = np.delete(y, outliers, axis=0)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4K442J2Cbu5",
   "metadata": {
    "id": "c4K442J2Cbu5"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def standardize(x):\n",
    "    scaler = preprocessing.StandardScaler().fit(training_data)\n",
    "    x = scaler.transform(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "V2AblynuDYKx",
   "metadata": {
    "id": "V2AblynuDYKx"
   },
   "outputs": [],
   "source": [
    "def split_RelKa(y, p):\n",
    "  return np.array([1 if value > p else 0 for value in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "LCehBG91D9S1",
   "metadata": {
    "id": "LCehBG91D9S1"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def predict_with_Random_Forests(X_train, X_test, y_train, y_test):\n",
    "    clf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)  \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "VGsyw7IyCpN7",
   "metadata": {
    "id": "VGsyw7IyCpN7"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def return_accuracy(y_test, y_pred, verbose=1):\n",
    "    C = metrics.confusion_matrix(y_test, y_pred)\n",
    "    accuracy = np.trace(C) / len(y_test)\n",
    "    if verbose == 1:\n",
    "        print(\"The number of true negatives is:\", C[0, 0])\n",
    "        print(\"The number of false negatives is:\", C[1,0])\n",
    "        print(\"The number of false positives is:\", C[0,1])  \n",
    "        print(\"The number of true positives is:\", C[1,1])\n",
    "        print(\"The accuracy is:\", accuracy)\n",
    "        print(\"The accuracy on the 1's is \", 1 / np.sum(y_test == 1) * (np.sum(y_test == 1) - C[1, 0]))\n",
    "        print(\"The accuracy on the 0's is \", 1 / np.sum(y_test == 0) * (np.sum(y_test == 0) - C[0, 1]))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "M1_1YDzeSwg_",
   "metadata": {
    "id": "M1_1YDzeSwg_"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def undersampling(X, y, ratios, intervals):\n",
    "    undersampled_training_data = np.zeros(training_data.shape[1])\n",
    "    undersampled_training_data = undersampled_training_data[..., np.newaxis].T\n",
    "    undersampled_RelKa = np.array([])\n",
    "    for i in range(len(intervals)-1):\n",
    "        indices = np.where(np.logical_and(intervals[i] <= RelKa, RelKa <= intervals[i+1]))[0]\n",
    "        sample_length = np.int(ratios[i]*len(indices))\n",
    "        random_picked = random.sample(list(np.arange(0, len(indices) + 1)), sample_length)\n",
    "        training_to_add = training_data[indices[0] + random_picked, :]\n",
    "        undersampled_training_data = np.concatenate([undersampled_training_data, training_to_add], axis=0)\n",
    "        RelKa_to_add = RelKa[indices[0] + random_picked]\n",
    "        undersampled_RelKa = np.concatenate([undersampled_RelKa, RelKa_to_add], axis=0)\n",
    "    critical_indices = np.where(RelKa >= 0.7)[0]\n",
    "    critical_RelKa = RelKa[critical_indices]\n",
    "    critical_samples = training_data[critical_indices, :]\n",
    "    undersampled_training_data = np.concatenate([undersampled_training_data, critical_samples], axis=0)\n",
    "    undersampled_RelKa = np.concatenate([undersampled_RelKa, critical_RelKa], axis=0)\n",
    "    undersampled_training_data = np.delete(undersampled_training_data, 0, axis=0)\n",
    "    return undersampled_training_data, undersampled_RelKa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kdztV9dvhWxQ",
   "metadata": {
    "id": "kdztV9dvhWxQ"
   },
   "outputs": [],
   "source": [
    "def initialize_clusters(data, k):\n",
    "    \"\"\"randomly initialize the k cluster centers (the means). Make sure you choose k clusters from the data itself,\n",
    "             or ensure otherwise that your initializations have the same scale as the data\n",
    "    \n",
    "    Args:\n",
    "        data: shape = (N, d). original data. \n",
    "        k: integer number. predefined number of clusters for the k-means algorithm. \n",
    "    Returns:\n",
    "        numpy array with shape (k, d) which corresponds to the k initial clusters.\n",
    "    \"\"\"\n",
    "    uniform_choice = random.sample(list(np.arange(0, data.shape[0])), k)\n",
    "    d = data.shape[1]\n",
    "    cluster_means = np.zeros((k, d))\n",
    "    for i in range(len(uniform_choice)):\n",
    "        cluster_means[i, :] = data[uniform_choice[i], :]\n",
    "    return cluster_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gd1qxnJAhbn7",
   "metadata": {
    "id": "gd1qxnJAhbn7"
   },
   "outputs": [],
   "source": [
    "def build_distance_matrix(data, mu):\n",
    "    \"\"\"builds a distance matrix.\n",
    "    \n",
    "    Args:\n",
    "        data: numpy array of shape = (N, d). original data. \n",
    "        mu:   numpy array of shape = (k, d). Each row corresponds to a cluster center.\n",
    "    Returns:\n",
    "        numpy array of shape (N, k):\n",
    "            squared distances matrix,  \n",
    "            the value row i column j corresponds to the squared distance of datapoint i with cluster center j.\n",
    "    \"\"\"\n",
    "    M = np.zeros((data.shape[0], mu.shape[0]))\n",
    "    for i in range(M.shape[0]):\n",
    "        for j in range(M.shape[1]):\n",
    "            M[i,j] = np.linalg.norm(data[i, :] - mu[j, :])\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FicQG--_hJOS",
   "metadata": {
    "id": "FicQG--_hJOS"
   },
   "outputs": [],
   "source": [
    "def update_kmeans_parameters(data, mu_old):\n",
    "    \"\"\"compute one step of the kmeans algorithm: using mu_old, find to which cluster each datapoint belongs to, \n",
    "            then update the parameter cluster centers.\n",
    "    \n",
    "    Args:\n",
    "        data:   numpy array of shape = (N, d). original data. \n",
    "        mu_old: numpy array of shape = (k, d). Each row corresponds to a cluster center.\n",
    "    Returns:\n",
    "        losses: shape (N, ), contains the (old) squared distances of each data point to its (old) cluster mean (computed from mu_old).\n",
    "        assignments: vector of shape (N, ) which contains the cluster associated to each data point.\n",
    "        mu: updated vector mu of shape (k, d) where each row corresponds to the new cluster center.\n",
    "    \"\"\"\n",
    "    k = mu_old.shape[0]\n",
    "    d = mu_old.shape[1]\n",
    "    N = data.shape[0]\n",
    "    all_losses = build_distance_matrix(data, mu_old)\n",
    "    mu = np.zeros((k, d))\n",
    "    assignments = np.array([np.argmin(all_losses[i, :]) for i in range(N)])\n",
    "    losses = np.array([np.linalg.norm(data[i,:] - mu_old[assignments[i], :]) for i in range(N)])\n",
    "    for i in range(k):\n",
    "        assigned_indices = np.where(assignments == i)[0]\n",
    "        mu[i, :] = np.mean(data[assigned_indices, :], axis=0)\n",
    "    return losses, assignments, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JLYMp5o2hd35",
   "metadata": {
    "id": "JLYMp5o2hd35"
   },
   "outputs": [],
   "source": [
    "def kmeans(data, k, max_iters, threshold, verbose = True):\n",
    "    \"\"\"run the k-means algorithm.\"\"\"\n",
    "    output_figure = \"kmeans_figures/\"\n",
    "    # initialize the cluster.\n",
    "    mu_old = initialize_clusters(data, k)\n",
    "    # init some empty lists to store the result.\n",
    "    loss_list = []\n",
    "\n",
    "    # start the kmeans algorithm.\n",
    "    for iteration in range(max_iters):\n",
    "        # update z and mu\n",
    "        losses, assignments, mu = update_kmeans_parameters(data, mu_old)\n",
    "        # calculate the average loss over all points\n",
    "        average_loss = np.mean(losses)\n",
    "        loss_list.append(average_loss)\n",
    "        if verbose:\n",
    "            print(\"The current iteration of k-means is: {i}, \\\n",
    "                   the average loss is {l}.\".format(i=iteration, l=average_loss))\n",
    "        # check convergence\n",
    "        if iteration > 0 and np.abs(loss_list[-1] - loss_list[-2]) < threshold:\n",
    "            break\n",
    "        # update k-means information.\n",
    "        mu_old = mu\n",
    "    return average_loss, assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DxQsUtJxOGkA",
   "metadata": {
    "id": "DxQsUtJxOGkA"
   },
   "source": [
    "WE FIRTS TRY TO DO A PREDICTION WITHOUT ANY OUTLIER REMOTION TO HAVE A COMPARISON AND WITHOUT ANY CLUSTERING TO HAVE A COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "qL_SNdMdOMMT",
   "metadata": {
    "id": "qL_SNdMdOMMT"
   },
   "outputs": [],
   "source": [
    "training_data = standardize(training_data)\n",
    "RelKa_tilda = split_RelKa(RelKa, 0.8)\n",
    "indices = [i for i in range(len(training_data))]\n",
    "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(training_data, RelKa_tilda, indices, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "LXWLj0eUOPil",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXWLj0eUOPil",
    "outputId": "b6766b4e-c1fc-4df0-cf09-ff542e5c9a63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true negatives is: 51150\n",
      "The number of false negatives is: 22\n",
      "The number of false positives is: 0\n",
      "The number of true positives is: 3\n",
      "The accuracy is: 0.9995701025891549\n",
      "The accuracy on the 1's is  0.12\n",
      "The accuracy on the 0's is  1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_with_Random_Forests(X_train, X_test, y_train, y_test)\n",
    "accuracy = return_accuracy(y_test, y_pred, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z07FC8x7PfIm",
   "metadata": {
    "id": "Z07FC8x7PfIm"
   },
   "source": [
    "WE SEE THAT THE ACCURACY IS HIGH BUT WE ARE PREDICTING VERY POORLY THE CLASS 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XfIslhQMRnNA",
   "metadata": {
    "id": "XfIslhQMRnNA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 120, num = 5)]\n",
    "min_samples_split = [2, 5, 8]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1HVEF-N3Szsu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HVEF-N3Szsu",
    "outputId": "0119cd69-aefa-4b0b-f31b-cf3aec009c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "[CV 1/4; 1/3] START min_samples_leaf=1, min_samples_split=5, n_estimators=110...\n",
      "[CV 1/4; 1/3] END min_samples_leaf=1, min_samples_split=5, n_estimators=110;, score=0.993 total time= 3.9min\n",
      "[CV 2/4; 1/3] START min_samples_leaf=1, min_samples_split=5, n_estimators=110...\n",
      "[CV 2/4; 1/3] END min_samples_leaf=1, min_samples_split=5, n_estimators=110;, score=0.993 total time= 4.0min\n",
      "[CV 3/4; 1/3] START min_samples_leaf=1, min_samples_split=5, n_estimators=110...\n",
      "[CV 3/4; 1/3] END min_samples_leaf=1, min_samples_split=5, n_estimators=110;, score=0.992 total time= 4.0min\n",
      "[CV 4/4; 1/3] START min_samples_leaf=1, min_samples_split=5, n_estimators=110...\n",
      "[CV 4/4; 1/3] END min_samples_leaf=1, min_samples_split=5, n_estimators=110;, score=0.993 total time= 4.1min\n",
      "[CV 1/4; 2/3] START min_samples_leaf=2, min_samples_split=8, n_estimators=100...\n",
      "[CV 1/4; 2/3] END min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=0.993 total time= 3.7min\n",
      "[CV 2/4; 2/3] START min_samples_leaf=2, min_samples_split=8, n_estimators=100...\n",
      "[CV 2/4; 2/3] END min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=0.993 total time= 3.6min\n",
      "[CV 3/4; 2/3] START min_samples_leaf=2, min_samples_split=8, n_estimators=100...\n",
      "[CV 3/4; 2/3] END min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=0.992 total time= 3.7min\n",
      "[CV 4/4; 2/3] START min_samples_leaf=2, min_samples_split=8, n_estimators=100...\n",
      "[CV 4/4; 2/3] END min_samples_leaf=2, min_samples_split=8, n_estimators=100;, score=0.993 total time= 3.7min\n",
      "[CV 1/4; 3/3] START min_samples_leaf=2, min_samples_split=5, n_estimators=110...\n",
      "[CV 1/4; 3/3] END min_samples_leaf=2, min_samples_split=5, n_estimators=110;, score=0.993 total time= 4.1min\n",
      "[CV 2/4; 3/3] START min_samples_leaf=2, min_samples_split=5, n_estimators=110...\n",
      "[CV 2/4; 3/3] END min_samples_leaf=2, min_samples_split=5, n_estimators=110;, score=0.993 total time= 4.2min\n",
      "[CV 3/4; 3/3] START min_samples_leaf=2, min_samples_split=5, n_estimators=110...\n",
      "[CV 3/4; 3/3] END min_samples_leaf=2, min_samples_split=5, n_estimators=110;, score=0.993 total time= 4.1min\n",
      "[CV 4/4; 3/3] START min_samples_leaf=2, min_samples_split=5, n_estimators=110...\n",
      "[CV 4/4; 3/3] END min_samples_leaf=2, min_samples_split=5, n_estimators=110;, score=0.993 total time= 4.3min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(), n_iter=3,\n",
       "                   param_distributions={'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 8],\n",
       "                                        'n_estimators': [100, 105, 110, 115,\n",
       "                                                         120]},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 3, cv = 4, verbose=10, scoring=make_scorer(f1_score, average='weigthed'))\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8H2NteSFUU8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8H2NteSFUU8b",
    "outputId": "735a0ddd-e293-4903-abe6-26cc76e550f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true negatives is: 46447\n",
      "The number of false negatives is: 263\n",
      "The number of false positives is: 36\n",
      "The number of true positives is: 408\n",
      "The accuracy is: 0.9936590745217797\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=110, min_samples_leaf=2, min_samples_split=5, criterion='entropy')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = return_accuracy(y_test, y_pred, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HKe56WQGrs_H",
   "metadata": {
    "id": "HKe56WQGrs_H"
   },
   "source": [
    "After tuning the parameters we see that the accuracy goes up to 60% on the 1's, but this value is still not satisfying (we want at least 80%-85%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DV5aXOeq6mGI",
   "metadata": {
    "id": "DV5aXOeq6mGI"
   },
   "source": [
    "ISOLATION FORESTS ANOMALY DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec7aw0cE6rsV",
   "metadata": {
    "id": "ec7aw0cE6rsV"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def Anomaly_Detection_Isolation_Forests(x, change_split=True):\n",
    "    random_state = np.random.RandomState(42)\n",
    "    contamination = 'auto'\n",
    "    threshold = np.random.uniform(-0.03, -0.02, 1)\n",
    "    model = IsolationForest(n_estimators=120, max_samples='auto', contamination=contamination, random_state=random_state)\n",
    "    model.fit(x)\n",
    "    scores = model.decision_function(x)\n",
    "    if change_split == False:\n",
    "        anomaly_score = model.predict(x)\n",
    "        outliers_indices = np.where(anomaly_score == -1)[0]\n",
    "    if change_split == True:\n",
    "        outliers_indices = split_outliers(threshold, scores)\n",
    "    return contamination, scores, outliers_indices\n",
    "\n",
    "def check_Isolation_Forests(contamination, outliers_indices):\n",
    "  \"\"\"\n",
    "  Simply a check on the proper working of the IF algorithm\n",
    "  \"\"\"\n",
    "    tol = 1.0e-02\n",
    "    if contamination != 'auto':\n",
    "        outliers_percentage = 1 / len(RelKa) * len(outliers_indices)\n",
    "    assert np.abs(contamination-outliers_percentage) < tol\n",
    "\n",
    "def check_boundary_decision(scores, p, verbose=1):\n",
    "  \"\"\"\n",
    "  This function simply controls how many scores returned by the IF algorithm \n",
    "  are likely to be misclassified\n",
    "  \"\"\"\n",
    "    indecision_percentage = 1 / len(RelKa) * np.count_nonzero(np.abs(scores) <= p)\n",
    "    if verbose == 1:\n",
    "        plt.hist(scores)\n",
    "        plt.show()\n",
    "        print(\"The indecision percentage around\", p,  \"is\", indecision_percentage)\n",
    "        print(\"The percentage of outliers detected is\", 1 / len(scores) * len(np.where(scores < 0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T13n1dNv7ct7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "T13n1dNv7ct7",
    "outputId": "37250b74-68d7-430e-aa06-fd65922b93cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indecision percentage around 0.02 is 0.5672001406964474\n",
      "The percentage of outliers detected is 0.10294290069175753\n"
     ]
    }
   ],
   "source": [
    "contamination, scores, outliers_indices = Anomaly_Detection_Isolation_Forests(training_data, change_split=False)\n",
    "check_Isolation_Forests(contamination, outliers_indices)\n",
    "check_boundary_decision(scores, 0.02, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bCG72D-4EhlD",
   "metadata": {
    "id": "bCG72D-4EhlD"
   },
   "outputs": [],
   "source": [
    "training_data, RelKa = drop_outliers(training_data, RelKa, outliers_indices)\n",
    "training_data = standardize(training_data)\n",
    "RelKa_tilda = split_RelKa(RelKa, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ssEbARYX4S5-",
   "metadata": {
    "id": "ssEbARYX4S5-"
   },
   "outputs": [],
   "source": [
    "indices = [i for i in range(len(training_data))]\n",
    "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(training_data, RelKa_tilda, indices, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nob2nvYFE3kj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nob2nvYFE3kj",
    "outputId": "978c622d-c8b8-4737-c98c-49e0ddf298d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true negatives is: 45880\n",
      "The number of false negatives is: 24\n",
      "The number of false positives is: 1\n",
      "The number of true positives is: 1\n",
      "The accuracy is: 0.9994554088790136\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_with_Random_Forests(X_train, X_test, y_train, y_test)\n",
    "accuracy = return_accuracy(y_test, y_pred, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4TyHT3NLfYy7",
   "metadata": {
    "id": "4TyHT3NLfYy7"
   },
   "source": [
    "We see that we have a problem with a large number of false negatives, namely with incorrectly predictions of the negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uySFlHwpoewE",
   "metadata": {
    "id": "uySFlHwpoewE"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_data, RelKa_tilda, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eVKIvgRtnQZV",
   "metadata": {
    "id": "eVKIvgRtnQZV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 5)]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DiMsjYxCoBKC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiMsjYxCoBKC",
    "outputId": "60c7d597-c021-4fc2-9f3b-d55c33e03f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5; 1/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=100..\n",
      "[CV 1/5; 1/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.991 total time= 1.5min\n",
      "[CV 2/5; 1/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=100..\n",
      "[CV 2/5; 1/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.992 total time= 1.6min\n",
      "[CV 3/5; 1/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=100..\n",
      "[CV 3/5; 1/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.991 total time= 1.6min\n",
      "[CV 4/5; 1/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=100..\n",
      "[CV 4/5; 1/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.991 total time= 1.6min\n",
      "[CV 5/5; 1/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=100..\n",
      "[CV 5/5; 1/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.992 total time= 1.6min\n",
      "[CV 1/5; 2/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=100.\n",
      "[CV 1/5; 2/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.991 total time= 1.4min\n",
      "[CV 2/5; 2/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=100.\n",
      "[CV 2/5; 2/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.991 total time= 1.5min\n",
      "[CV 3/5; 2/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=100.\n",
      "[CV 3/5; 2/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.990 total time= 1.5min\n",
      "[CV 4/5; 2/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=100.\n",
      "[CV 4/5; 2/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.990 total time= 1.5min\n",
      "[CV 5/5; 2/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=100.\n",
      "[CV 5/5; 2/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.991 total time= 1.5min\n",
      "[CV 1/5; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 1/5; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.991 total time= 1.5min\n",
      "[CV 2/5; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 2/5; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.990 total time= 1.5min\n",
      "[CV 3/5; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 3/5; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.990 total time= 1.5min\n",
      "[CV 4/5; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 4/5; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.990 total time= 1.6min\n",
      "[CV 5/5; 3/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 5/5; 3/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.991 total time= 1.5min\n",
      "[CV 1/5; 4/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=175.\n",
      "[CV 1/5; 4/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=175;, score=0.991 total time= 2.6min\n",
      "[CV 2/5; 4/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=175.\n",
      "[CV 2/5; 4/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=175;, score=0.990 total time= 2.7min\n",
      "[CV 3/5; 4/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=175.\n",
      "[CV 3/5; 4/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=175;, score=0.990 total time= 2.6min\n",
      "[CV 4/5; 4/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=175.\n",
      "[CV 4/5; 4/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=175;, score=0.991 total time= 2.7min\n",
      "[CV 5/5; 4/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=175.\n",
      "[CV 5/5; 4/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=175;, score=0.991 total time= 2.6min\n",
      "[CV 1/5; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=150.\n",
      "[CV 1/5; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=150;, score=0.990 total time= 2.3min\n",
      "[CV 2/5; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=150.\n",
      "[CV 2/5; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=150;, score=0.991 total time= 2.2min\n",
      "[CV 3/5; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=150.\n",
      "[CV 3/5; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=150;, score=0.990 total time= 2.3min\n",
      "[CV 4/5; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=150.\n",
      "[CV 4/5; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=150;, score=0.991 total time= 2.4min\n",
      "[CV 5/5; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=150.\n",
      "[CV 5/5; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=150;, score=0.991 total time= 2.3min\n",
      "[CV 1/5; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=150.\n",
      "[CV 1/5; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=0.991 total time= 2.2min\n",
      "[CV 2/5; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=150.\n",
      "[CV 2/5; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=0.991 total time= 2.4min\n",
      "[CV 3/5; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=150.\n",
      "[CV 3/5; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=0.991 total time= 2.4min\n",
      "[CV 4/5; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=150.\n",
      "[CV 4/5; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=0.991 total time= 2.3min\n",
      "[CV 5/5; 6/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=150.\n",
      "[CV 5/5; 6/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=0.992 total time= 2.3min\n",
      "[CV 1/5; 7/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=150..\n",
      "[CV 1/5; 7/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=150;, score=0.991 total time= 2.2min\n",
      "[CV 2/5; 7/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=150..\n",
      "[CV 2/5; 7/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=150;, score=0.991 total time= 2.3min\n",
      "[CV 3/5; 7/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=150..\n",
      "[CV 3/5; 7/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=150;, score=0.991 total time= 2.3min\n",
      "[CV 4/5; 7/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=150..\n",
      "[CV 4/5; 7/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=150;, score=0.991 total time= 2.4min\n",
      "[CV 5/5; 7/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=150..\n",
      "[CV 5/5; 7/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=150;, score=0.991 total time= 2.4min\n",
      "[CV 1/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 1/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.991 total time= 1.9min\n",
      "[CV 2/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 2/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.991 total time= 2.0min\n",
      "[CV 3/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 3/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.990 total time= 2.0min\n",
      "[CV 4/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 4/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.991 total time= 2.0min\n",
      "[CV 5/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 5/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.991 total time= 2.0min\n",
      "[CV 1/5; 9/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200.\n",
      "[CV 1/5; 9/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.991 total time= 3.0min\n",
      "[CV 2/5; 9/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200.\n",
      "[CV 2/5; 9/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.991 total time= 3.2min\n",
      "[CV 3/5; 9/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200.\n",
      "[CV 3/5; 9/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.990 total time= 3.1min\n",
      "[CV 4/5; 9/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200.\n",
      "[CV 4/5; 9/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.991 total time= 3.1min\n",
      "[CV 5/5; 9/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=200.\n",
      "[CV 5/5; 9/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.992 total time= 3.0min\n",
      "[CV 1/5; 10/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=150.\n",
      "[CV 1/5; 10/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.991 total time= 2.2min\n",
      "[CV 2/5; 10/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=150.\n",
      "[CV 2/5; 10/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.991 total time= 2.3min\n",
      "[CV 3/5; 10/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=150.\n",
      "[CV 3/5; 10/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.991 total time= 2.4min\n",
      "[CV 4/5; 10/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=150.\n",
      "[CV 4/5; 10/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.991 total time= 2.4min\n",
      "[CV 5/5; 10/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=150.\n",
      "[CV 5/5; 10/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=150;, score=0.993 total time= 2.2min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 125, 150, 175,\n",
       "                                                         200]},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=10, scoring=make_scorer(f1_score, average=\"weighted\"))\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "UjUwQj2MFcvn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UjUwQj2MFcvn",
    "outputId": "bcb5bb45-6c1f-4d94-d03c-e9f4767148bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "# print(rf_random.best_params_)\n",
    "clf = RandomForestClassifier(n_estimators=200, min_samples_leaf=1, min_samples_split=2, criterion='entropy')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = return_accuracy(y_test, y_pred, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lESSLic6cP90",
   "metadata": {
    "id": "lESSLic6cP90"
   },
   "source": [
    "UNDERSAMPLING TECHNIQUE TO BALANCE THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "uNeZk7J5mVNI",
   "metadata": {
    "id": "uNeZk7J5mVNI"
   },
   "outputs": [],
   "source": [
    "ratios = np.array([0.1])\n",
    "intervals = 0.2 * np.arange(0, 2)\n",
    "undersampled_training_data, undersampled_RelKa = undersampling(training_data, RelKa, ratios, intervals)\n",
    "undersampled_training_data = standardize(undersampled_training_data)\n",
    "undersampled_RelKa = split_RelKa(undersampled_RelKa, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "oSiiXxs8mpS0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSiiXxs8mpS0",
    "outputId": "6f91429c-40df-4511-f4d9-537a8e501a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true negatives is: 3553\n",
      "The number of false negatives is: 7\n",
      "The number of false positives is: 1\n",
      "The number of true positives is: 95\n",
      "The accuracy is: 0.9978118161925602\n",
      "The accuracy on the 1's is  0.9313725490196079\n",
      "The accuracy on the 0's is  0.9997186268992685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9978118161925602"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_X_train, undersampled_X_test, undersampled_y_train, undersampled_y_test = train_test_split(undersampled_training_data, undersampled_RelKa, train_size=0.7, random_state=42)\n",
    "undersampled_y_pred = predict_with_Random_Forests(undersampled_X_train, undersampled_X_test, undersampled_y_train, undersampled_y_test)\n",
    "return_accuracy(undersampled_y_test, undersampled_y_pred, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HUJCp56B4WIr",
   "metadata": {
    "id": "HUJCp56B4WIr"
   },
   "source": [
    "WE SEE THAT INCREASING THE NUMBER OF SAMPLES CRITICAL WE ALMOST HAVE 100 % ACCURACY BOTH ON 0'S AND 1'S AT THE COST OF DOING THE UNDERSAMPLING AND THE OVERSAMPLING OF THE PREVIOUS PARAGRAPH. WE TRY NOW TO ACHIEVE SIMILAR RESULTS BY PENALIZING ERRORS ON 1'S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TBcYywbW-P6Q",
   "metadata": {
    "id": "TBcYywbW-P6Q"
   },
   "source": [
    "WE PERFORM CROSS VALIDATION TO TUNE THE HYPERPARAMETERS OF THE RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "v4sUtR9N-Q-F",
   "metadata": {
    "id": "v4sUtR9N-Q-F"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 5)]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "k3nrhqFp-Yep",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3nrhqFp-Yep",
    "outputId": "271b1b1c-a690-44d2-b37c-a596b2855cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5; 1/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=100..\n",
      "[CV 1/5; 1/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.995 total time=   9.1s\n",
      "[CV 2/5; 1/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=100..\n",
      "[CV 2/5; 1/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.992 total time=   8.7s\n",
      "[CV 3/5; 1/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=100..\n",
      "[CV 3/5; 1/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.995 total time=   9.0s\n",
      "[CV 4/5; 1/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=100..\n",
      "[CV 4/5; 1/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.994 total time=   8.9s\n",
      "[CV 5/5; 1/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=100..\n",
      "[CV 5/5; 1/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.995 total time=   8.8s\n",
      "[CV 1/5; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=100..\n",
      "[CV 1/5; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.995 total time=   9.6s\n",
      "[CV 2/5; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=100..\n",
      "[CV 2/5; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.992 total time=   9.2s\n",
      "[CV 3/5; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=100..\n",
      "[CV 3/5; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.997 total time=   9.2s\n",
      "[CV 4/5; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=100..\n",
      "[CV 4/5; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.996 total time=   9.1s\n",
      "[CV 5/5; 2/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=100..\n",
      "[CV 5/5; 2/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.996 total time=   9.2s\n",
      "[CV 1/5; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200..\n",
      "[CV 1/5; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.995 total time=  18.2s\n",
      "[CV 2/5; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200..\n",
      "[CV 2/5; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.995 total time=  18.9s\n",
      "[CV 3/5; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200..\n",
      "[CV 3/5; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.997 total time=  18.2s\n",
      "[CV 4/5; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200..\n",
      "[CV 4/5; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.996 total time=  19.1s\n",
      "[CV 5/5; 3/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200..\n",
      "[CV 5/5; 3/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.996 total time=  19.0s\n",
      "[CV 1/5; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=125..\n",
      "[CV 1/5; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=0.995 total time=  11.5s\n",
      "[CV 2/5; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=125..\n",
      "[CV 2/5; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=0.991 total time=  11.0s\n",
      "[CV 3/5; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=125..\n",
      "[CV 3/5; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=0.995 total time=  11.5s\n",
      "[CV 4/5; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=125..\n",
      "[CV 4/5; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=0.994 total time=  11.1s\n",
      "[CV 5/5; 4/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=125..\n",
      "[CV 5/5; 4/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=125;, score=0.995 total time=  11.5s\n",
      "[CV 1/5; 5/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200..\n",
      "[CV 1/5; 5/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.995 total time=  20.1s\n",
      "[CV 2/5; 5/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200..\n",
      "[CV 2/5; 5/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.995 total time=  19.1s\n",
      "[CV 3/5; 5/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200..\n",
      "[CV 3/5; 5/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.995 total time=  18.8s\n",
      "[CV 4/5; 5/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200..\n",
      "[CV 4/5; 5/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.996 total time=  18.9s\n",
      "[CV 5/5; 5/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=200..\n",
      "[CV 5/5; 5/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.996 total time=  17.9s\n",
      "[CV 1/5; 6/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=150..\n",
      "[CV 1/5; 6/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=150;, score=0.994 total time=  14.0s\n",
      "[CV 2/5; 6/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=150..\n",
      "[CV 2/5; 6/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=150;, score=0.995 total time=  12.8s\n",
      "[CV 3/5; 6/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=150..\n",
      "[CV 3/5; 6/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=150;, score=0.995 total time=  13.4s\n",
      "[CV 4/5; 6/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=150..\n",
      "[CV 4/5; 6/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=150;, score=0.994 total time=  13.7s\n",
      "[CV 5/5; 6/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=150..\n",
      "[CV 5/5; 6/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=150;, score=0.995 total time=  12.9s\n",
      "[CV 1/5; 7/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=175..\n",
      "[CV 1/5; 7/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=175;, score=0.995 total time=  16.1s\n",
      "[CV 2/5; 7/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=175..\n",
      "[CV 2/5; 7/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=175;, score=0.994 total time=  15.5s\n",
      "[CV 3/5; 7/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=175..\n",
      "[CV 3/5; 7/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=175;, score=0.996 total time=  16.1s\n",
      "[CV 4/5; 7/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=175..\n",
      "[CV 4/5; 7/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=175;, score=0.996 total time=  15.8s\n",
      "[CV 5/5; 7/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=175..\n",
      "[CV 5/5; 7/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=175;, score=0.996 total time=  15.7s\n",
      "[CV 1/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 1/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.995 total time=  11.7s\n",
      "[CV 2/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 2/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.994 total time=  10.7s\n",
      "[CV 3/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 3/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.994 total time=  11.3s\n",
      "[CV 4/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 4/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.996 total time=  11.0s\n",
      "[CV 5/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 5/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.995 total time=  10.2s\n",
      "[CV 1/5; 9/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=100..\n",
      "[CV 1/5; 9/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.995 total time=   8.4s\n",
      "[CV 2/5; 9/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=100..\n",
      "[CV 2/5; 9/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.994 total time=   8.7s\n",
      "[CV 3/5; 9/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=100..\n",
      "[CV 3/5; 9/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.995 total time=   8.3s\n",
      "[CV 4/5; 9/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=100..\n",
      "[CV 4/5; 9/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.996 total time=   9.1s\n",
      "[CV 5/5; 9/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=100..\n",
      "[CV 5/5; 9/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.996 total time=   9.2s\n",
      "[CV 1/5; 10/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=125\n",
      "[CV 1/5; 10/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=125;, score=0.995 total time=  11.2s\n",
      "[CV 2/5; 10/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=125\n",
      "[CV 2/5; 10/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=125;, score=0.995 total time=  10.7s\n",
      "[CV 3/5; 10/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=125\n",
      "[CV 3/5; 10/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=125;, score=0.995 total time=  10.6s\n",
      "[CV 4/5; 10/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=125\n",
      "[CV 4/5; 10/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=125;, score=0.996 total time=  11.2s\n",
      "[CV 5/5; 10/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=125\n",
      "[CV 5/5; 10/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=125;, score=0.996 total time=  10.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 125, 150, 175,\n",
       "                                                         200]},\n",
       "                   scoring=make_scorer(f1_score, average=micro), verbose=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=10, scoring=make_scorer(f1_score, average='weighted'))\n",
    "rf_random.fit(undersampled_X_train, undersampled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "gpYQrUNa-lSL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpYQrUNa-lSL",
    "outputId": "0157f33e-054f-4eb8-c7d0-d4276b13f8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true negatives is: 3554\n",
      "The number of false negatives is: 8\n",
      "The number of false positives is: 0\n",
      "The number of true positives is: 94\n",
      "The accuracy is: 0.9978118161925602\n",
      "The accuracy on the 1's is  0.9215686274509803\n",
      "The accuracy on the 0's is  1.0\n"
     ]
    }
   ],
   "source": [
    "# print(rf_random.best_params_)\n",
    "clf = RandomForestClassifier(n_estimators=200, min_samples_leaf=1, min_samples_split=2, criterion='entropy')\n",
    "clf.fit(undersampled_X_train, undersampled_y_train)\n",
    "undersampled_y_pred = clf.predict(undersampled_X_test)\n",
    "accuracy = return_accuracy(undersampled_y_test, undersampled_y_pred, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hU88rC0WC_6N",
   "metadata": {
    "id": "hU88rC0WC_6N"
   },
   "source": [
    "TUNING THE PARAMETERS IN THE STANDARD WAY IS SLIGHTLY INCREASING THE ACCURACY ON THE 1'S, SO WE SHOULD TRY TO DO CROSS-VALIDATION USING THE F1 SCORE TO FURTHER IMPROVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dSfmRCkSROOz",
   "metadata": {
    "id": "dSfmRCkSROOz"
   },
   "source": [
    "WE TRY NOW TO DETECT AND DROP OUTLIERS ON THE BALANCED DATASET TO SEE WHETHER THE PERFORMANCE IS IMPROVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ROwaaxTNRSI-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "ROwaaxTNRSI-",
    "outputId": "e2e7d250-ec91-4259-e584-35b34be6011a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indecision percentage around 0.02 is 0.026187126275061555\n",
      "The percentage of outliers detected is 0.030860144451739985\n"
     ]
    }
   ],
   "source": [
    "contamination, scores, outliers_indices = Anomaly_Detection_Isolation_Forests(undersampled_training_data, change_split=False)\n",
    "check_Isolation_Forests(contamination, outliers_indices)\n",
    "check_boundary_decision(scores, 0.02, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "VJGx8hvZRVes",
   "metadata": {
    "id": "VJGx8hvZRVes"
   },
   "outputs": [],
   "source": [
    "undersampled_training_data, undersampled_RelKa = drop_outliers(undersampled_training_data, undersampled_RelKa, outliers_indices)\n",
    "undersampled_training_data = standardize(undersampled_training_data)\n",
    "undersampled_RelKa = split_RelKa(undersampled_RelKa, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "E_Oiw79XRVib",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_Oiw79XRVib",
    "outputId": "d488b233-db96-4ef0-e388-40518433bd2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true negatives is: 3443\n",
      "The number of false negatives is: 7\n",
      "The number of false positives is: 0\n",
      "The number of true positives is: 93\n",
      "The accuracy is: 0.9980242732147897\n",
      "The accuracy on the 1's is  0.93\n",
      "The accuracy on the 0's is  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9980242732147897"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_X_train, undersampled_X_test, undersampled_y_train, undersampled_y_test = train_test_split(undersampled_training_data, undersampled_RelKa, train_size=0.7, random_state=42)\n",
    "undersampled_y_pred = predict_with_Random_Forests(undersampled_X_train, undersampled_X_test, undersampled_y_train, undersampled_y_test)\n",
    "return_accuracy(undersampled_y_test, undersampled_y_pred, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "vvnnn-e3glzg",
   "metadata": {
    "id": "vvnnn-e3glzg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 5)]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9D9B5-ZzgtnQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9D9B5-ZzgtnQ",
    "outputId": "6b940f0b-3d80-4a9a-9779-7db027f5d5a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5; 1/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 1/5; 1/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.992 total time=   8.3s\n",
      "[CV 2/5; 1/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 2/5; 1/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.995 total time=   8.0s\n",
      "[CV 3/5; 1/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 3/5; 1/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.995 total time=   8.8s\n",
      "[CV 4/5; 1/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 4/5; 1/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.993 total time=   8.4s\n",
      "[CV 5/5; 1/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 5/5; 1/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.993 total time=   8.7s\n",
      "[CV 1/5; 2/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=150..\n",
      "[CV 1/5; 2/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=150;, score=0.992 total time=  12.8s\n",
      "[CV 2/5; 2/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=150..\n",
      "[CV 2/5; 2/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=150;, score=0.996 total time=  11.8s\n",
      "[CV 3/5; 2/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=150..\n",
      "[CV 3/5; 2/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=150;, score=0.995 total time=  12.5s\n",
      "[CV 4/5; 2/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=150..\n",
      "[CV 4/5; 2/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=150;, score=0.992 total time=  12.5s\n",
      "[CV 5/5; 2/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=150..\n",
      "[CV 5/5; 2/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=150;, score=0.994 total time=  12.8s\n",
      "[CV 1/5; 3/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=150..\n",
      "[CV 1/5; 3/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=150;, score=0.994 total time=  13.1s\n",
      "[CV 2/5; 3/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=150..\n",
      "[CV 2/5; 3/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=150;, score=0.996 total time=  12.5s\n",
      "[CV 3/5; 3/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=150..\n",
      "[CV 3/5; 3/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=150;, score=0.995 total time=  13.1s\n",
      "[CV 4/5; 3/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=150..\n",
      "[CV 4/5; 3/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=150;, score=0.993 total time=  12.8s\n",
      "[CV 5/5; 3/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=150..\n",
      "[CV 5/5; 3/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=150;, score=0.995 total time=  12.9s\n",
      "[CV 1/5; 4/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=175..\n",
      "[CV 1/5; 4/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=175;, score=0.993 total time=  14.7s\n",
      "[CV 2/5; 4/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=175..\n",
      "[CV 2/5; 4/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=175;, score=0.996 total time=  14.9s\n",
      "[CV 3/5; 4/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=175..\n",
      "[CV 3/5; 4/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=175;, score=0.996 total time=  15.3s\n",
      "[CV 4/5; 4/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=175..\n",
      "[CV 4/5; 4/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=175;, score=0.994 total time=  14.7s\n",
      "[CV 5/5; 4/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=175..\n",
      "[CV 5/5; 4/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=175;, score=0.996 total time=  15.6s\n",
      "[CV 1/5; 5/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=125..\n",
      "[CV 1/5; 5/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=0.994 total time=  10.4s\n",
      "[CV 2/5; 5/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=125..\n",
      "[CV 2/5; 5/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=0.996 total time=  10.8s\n",
      "[CV 3/5; 5/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=125..\n",
      "[CV 3/5; 5/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=0.996 total time=  11.1s\n",
      "[CV 4/5; 5/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=125..\n",
      "[CV 4/5; 5/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=0.993 total time=  10.7s\n",
      "[CV 5/5; 5/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=125..\n",
      "[CV 5/5; 5/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=0.996 total time=  10.8s\n",
      "[CV 1/5; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200..\n",
      "[CV 1/5; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.994 total time=  16.7s\n",
      "[CV 2/5; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200..\n",
      "[CV 2/5; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.997 total time=  17.8s\n",
      "[CV 3/5; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200..\n",
      "[CV 3/5; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.996 total time=  17.4s\n",
      "[CV 4/5; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200..\n",
      "[CV 4/5; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.995 total time=  17.6s\n",
      "[CV 5/5; 6/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=200..\n",
      "[CV 5/5; 6/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.995 total time=  18.0s\n",
      "[CV 1/5; 7/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=150.\n",
      "[CV 1/5; 7/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=0.992 total time=  13.3s\n",
      "[CV 2/5; 7/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=150.\n",
      "[CV 2/5; 7/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=0.995 total time=  12.5s\n",
      "[CV 3/5; 7/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=150.\n",
      "[CV 3/5; 7/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=0.995 total time=  13.0s\n",
      "[CV 4/5; 7/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=150.\n",
      "[CV 4/5; 7/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=0.993 total time=  13.2s\n",
      "[CV 5/5; 7/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=150.\n",
      "[CV 5/5; 7/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=150;, score=0.995 total time=  13.4s\n",
      "[CV 1/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=150..\n",
      "[CV 1/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=150;, score=0.992 total time=  12.3s\n",
      "[CV 2/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=150..\n",
      "[CV 2/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=150;, score=0.995 total time=  12.4s\n",
      "[CV 3/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=150..\n",
      "[CV 3/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=150;, score=0.994 total time=  13.2s\n",
      "[CV 4/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=150..\n",
      "[CV 4/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=150;, score=0.993 total time=  13.5s\n",
      "[CV 5/5; 8/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=150..\n",
      "[CV 5/5; 8/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=150;, score=0.995 total time=  13.2s\n",
      "[CV 1/5; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=125..\n",
      "[CV 1/5; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=0.993 total time=  11.3s\n",
      "[CV 2/5; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=125..\n",
      "[CV 2/5; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=0.996 total time=  10.4s\n",
      "[CV 3/5; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=125..\n",
      "[CV 3/5; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=0.996 total time=  11.0s\n",
      "[CV 4/5; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=125..\n",
      "[CV 4/5; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=0.994 total time=  10.9s\n",
      "[CV 5/5; 9/10] START min_samples_leaf=1, min_samples_split=5, n_estimators=125..\n",
      "[CV 5/5; 9/10] END min_samples_leaf=1, min_samples_split=5, n_estimators=125;, score=0.994 total time=  10.8s\n",
      "[CV 1/5; 10/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=100\n",
      "[CV 1/5; 10/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.993 total time=   8.4s\n",
      "[CV 2/5; 10/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=100\n",
      "[CV 2/5; 10/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.996 total time=   8.4s\n",
      "[CV 3/5; 10/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=100\n",
      "[CV 3/5; 10/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.995 total time=   9.2s\n",
      "[CV 4/5; 10/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=100\n",
      "[CV 4/5; 10/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.993 total time=   9.3s\n",
      "[CV 5/5; 10/10] START min_samples_leaf=1, min_samples_split=10, n_estimators=100\n",
      "[CV 5/5; 10/10] END min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.996 total time=   9.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 125, 150, 175,\n",
       "                                                         200]},\n",
       "                   scoring=make_scorer(f1_score, average=micro), verbose=10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=10, scoring=make_scorer(f1_score, average='weighted'))\n",
    "rf_random.fit(undersampled_X_train, undersampled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "NoX5dGpegy4x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NoX5dGpegy4x",
    "outputId": "0780f8b0-1366-4ada-c1a2-8adc32ff310d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true negatives is: 3443\n",
      "The number of false negatives is: 9\n",
      "The number of false positives is: 0\n",
      "The number of true positives is: 91\n",
      "The accuracy is: 0.9974597798475868\n",
      "The accuracy on the 1's is  0.91\n",
      "The accuracy on the 0's is  1.0\n"
     ]
    }
   ],
   "source": [
    "# print(rf_random.best_params_)\n",
    "clf = RandomForestClassifier(n_estimators=200, min_samples_leaf=1, min_samples_split=2, criterion='entropy')\n",
    "clf.fit(undersampled_X_train, undersampled_y_train)\n",
    "undersampled_y_pred = clf.predict(undersampled_X_test)\n",
    "accuracy = return_accuracy(undersampled_y_test, undersampled_y_pred, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MgvvYR3Og4yb",
   "metadata": {
    "id": "MgvvYR3Og4yb"
   },
   "source": [
    "WE TRY TO MAKE THE SUBSAMPLING PROCEDURE MORE ELEGANT AND EFFICIENT BY CONSIDERING K-CLUSTERING, THEN TAKING A SUBSAMPLE FOR EACH CLUSTER (WE PERFORM THE CLUSTERING ONLY ON THE SAMPLES WITH RELKA'S BELOW 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "lFL-jAqBiUg_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFL-jAqBiUg_",
    "outputId": "32e3a048-711d-4ed9-ae12-cb06d47fb2d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration of k-means is: 0,                    the average loss is 6.913651290204287.\n",
      "The current iteration of k-means is: 1,                    the average loss is 5.51839742076969.\n",
      "The current iteration of k-means is: 2,                    the average loss is 5.3974221020446524.\n",
      "The current iteration of k-means is: 3,                    the average loss is 5.350227764835033.\n",
      "The current iteration of k-means is: 4,                    the average loss is 5.3174242010148305.\n",
      "The current iteration of k-means is: 5,                    the average loss is 5.292021291232115.\n",
      "The current iteration of k-means is: 6,                    the average loss is 5.273316762498283.\n",
      "The current iteration of k-means is: 7,                    the average loss is 5.25977890279777.\n",
      "The current iteration of k-means is: 8,                    the average loss is 5.250263920568093.\n",
      "The current iteration of k-means is: 9,                    the average loss is 5.243452766213569.\n"
     ]
    }
   ],
   "source": [
    "max_iters = 5\n",
    "threshold = 1.0e-02\n",
    "k = 5\n",
    "indices = np.where(RelKa <= 0.2)[0]\n",
    "redundant_training_data = training_data[indices, :]\n",
    "redundant_RelKa = RelKa[indices]\n",
    "\n",
    "average_loss, assignments = kmeans(redundant_training_data, k, max_iters, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dLvySA-Al9OV",
   "metadata": {
    "id": "dLvySA-Al9OV"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "clustered_data = np.zeros(training_data.shape[1])\n",
    "clustered_data = clustered_data[..., np.newaxis].T\n",
    "clustered_RelKa = np.array([])\n",
    "for i in range(k):\n",
    "    # collect random_size casual samples from the i-th cluster\n",
    "    assigned_indices = np.where(assignments == i)[0]\n",
    "    # taking the samples and RelKa assigned to the i-th cluster\n",
    "    assigned_data = redundant_training_data[assigned_indices, :]\n",
    "    assigned_RelKa = redundant_RelKa[assigned_indices]\n",
    "    # taking a random subsample\n",
    "    random_picked = random.sample(list(np.arange(0, len(assigned_indices))), np.int(1/10 * len(assigned_indices)))\n",
    "    data_to_add = assigned_data[random_picked, :]\n",
    "    RelKa_to_add = assigned_RelKa[random_picked]\n",
    "    # concatenate the subsample to the old clustered_data and clustered_RelKa\n",
    "    clustered_data = np.concatenate([clustered_data, data_to_add])\n",
    "    clustered_RelKa = np.concatenate([clustered_RelKa, RelKa_to_add])\n",
    "# we delete the first row which was just for initialization\n",
    "clustered_data = np.delete(clustered_data, 0, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "RspXuwKdn9q1",
   "metadata": {
    "id": "RspXuwKdn9q1"
   },
   "outputs": [],
   "source": [
    "# adding all the other samples (which represent less than 20% of the original dataset)\n",
    "indices = np.where(RelKa > 0.2)[0]\n",
    "clustered_data = np.concatenate([clustered_data, training_data[indices, :]])\n",
    "clustered_RelKa = np.concatenate([clustered_RelKa, RelKa[indices]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aPkkpTa5o8UO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPkkpTa5o8UO",
    "outputId": "fad27336-8f3e-4104-8714-21a043b5c3bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75687, 318)\n",
      "(75687,)\n"
     ]
    }
   ],
   "source": [
    "print(clustered_data.shape)\n",
    "print(clustered_RelKa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "xWZqYzmYpBKt",
   "metadata": {
    "id": "xWZqYzmYpBKt"
   },
   "outputs": [],
   "source": [
    "clustered_RelKa = split_RelKa(clustered_RelKa, 0.6)\n",
    "clustered_data = standardize(clustered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "z8dO_jZTpO-1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8dO_jZTpO-1",
    "outputId": "fa5f5668-1897-4af9-92b2-5226cb1a7ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true negatives is: 22416\n",
      "The number of false negatives is: 111\n",
      "The number of false positives is: 24\n",
      "The number of true positives is: 156\n",
      "The accuracy is: 0.9940546967895363\n",
      "The accuracy on the 1's is  0.5842696629213483\n",
      "The accuracy on the 0's is  0.9989304812834224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9940546967895363"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_X_train, clustered_X_test, clustered_y_train, clustered_y_test = train_test_split(clustered_data, clustered_RelKa, train_size=0.7, random_state=42)\n",
    "clustered_y_pred = predict_with_Random_Forests(clustered_X_train, clustered_X_test, clustered_y_train, clustered_y_test)\n",
    "return_accuracy(clustered_y_test, clustered_y_pred, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RPnl8KUNuUm8",
   "metadata": {
    "id": "RPnl8KUNuUm8"
   },
   "source": [
    "Taking 20 clusters the accuracy on the 1's is lower than the accuracy with 10 clusters (61%), so we should decrease such a number for the kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "Ug9wqKwSqoqF",
   "metadata": {
    "id": "Ug9wqKwSqoqF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 5)]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "C2WeI5K4qsA1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2WeI5K4qsA1",
    "outputId": "fb5fbbec-b63b-4586-a255-5119c6952d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=175..\n",
      "[CV 1/5; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=175;, score=0.992 total time=  14.9s\n",
      "[CV 2/5; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=175..\n",
      "[CV 2/5; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=175;, score=0.996 total time=  14.1s\n",
      "[CV 3/5; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=175..\n",
      "[CV 3/5; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=175;, score=0.995 total time=  14.8s\n",
      "[CV 4/5; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=175..\n",
      "[CV 4/5; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=175;, score=0.992 total time=  14.9s\n",
      "[CV 5/5; 1/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=175..\n",
      "[CV 5/5; 1/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=175;, score=0.994 total time=  15.4s\n",
      "[CV 1/5; 2/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=200..\n",
      "[CV 1/5; 2/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.993 total time=  17.2s\n",
      "[CV 2/5; 2/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=200..\n",
      "[CV 2/5; 2/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.995 total time=  17.5s\n",
      "[CV 3/5; 2/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=200..\n",
      "[CV 3/5; 2/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.995 total time=  16.9s\n",
      "[CV 4/5; 2/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=200..\n",
      "[CV 4/5; 2/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.992 total time=  17.3s\n",
      "[CV 5/5; 2/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=200..\n",
      "[CV 5/5; 2/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.995 total time=  16.9s\n",
      "[CV 1/5; 3/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=100..\n",
      "[CV 1/5; 3/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.993 total time=   8.5s\n",
      "[CV 2/5; 3/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=100..\n",
      "[CV 2/5; 3/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.996 total time=   8.5s\n",
      "[CV 3/5; 3/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=100..\n",
      "[CV 3/5; 3/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.995 total time=   8.8s\n",
      "[CV 4/5; 3/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=100..\n",
      "[CV 4/5; 3/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.993 total time=   8.3s\n",
      "[CV 5/5; 3/10] START min_samples_leaf=2, min_samples_split=5, n_estimators=100..\n",
      "[CV 5/5; 3/10] END min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.995 total time=   8.6s\n",
      "[CV 1/5; 4/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 1/5; 4/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.992 total time=  10.4s\n",
      "[CV 2/5; 4/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 2/5; 4/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.995 total time=  10.2s\n",
      "[CV 3/5; 4/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 3/5; 4/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.995 total time=  10.8s\n",
      "[CV 4/5; 4/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 4/5; 4/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.993 total time=   9.9s\n",
      "[CV 5/5; 4/10] START min_samples_leaf=4, min_samples_split=5, n_estimators=125..\n",
      "[CV 5/5; 4/10] END min_samples_leaf=4, min_samples_split=5, n_estimators=125;, score=0.995 total time=  10.4s\n",
      "[CV 1/5; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=125.\n",
      "[CV 1/5; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=125;, score=0.993 total time=  10.1s\n",
      "[CV 2/5; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=125.\n",
      "[CV 2/5; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=125;, score=0.996 total time=  10.4s\n",
      "[CV 3/5; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=125.\n",
      "[CV 3/5; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=125;, score=0.995 total time=  10.5s\n",
      "[CV 4/5; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=125.\n",
      "[CV 4/5; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=125;, score=0.993 total time=  10.3s\n",
      "[CV 5/5; 5/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=125.\n",
      "[CV 5/5; 5/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=125;, score=0.994 total time=  11.1s\n",
      "[CV 1/5; 6/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 1/5; 6/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.992 total time=   8.0s\n",
      "[CV 2/5; 6/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 2/5; 6/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.994 total time=   8.1s\n",
      "[CV 3/5; 6/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 3/5; 6/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.995 total time=   7.8s\n",
      "[CV 4/5; 6/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 4/5; 6/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.992 total time=   8.3s\n",
      "[CV 5/5; 6/10] START min_samples_leaf=4, min_samples_split=10, n_estimators=100.\n",
      "[CV 5/5; 6/10] END min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.995 total time=   8.5s\n",
      "[CV 1/5; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=125..\n",
      "[CV 1/5; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=0.993 total time=  10.4s\n",
      "[CV 2/5; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=125..\n",
      "[CV 2/5; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=0.997 total time=  10.1s\n",
      "[CV 3/5; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=125..\n",
      "[CV 3/5; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=0.996 total time=  11.0s\n",
      "[CV 4/5; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=125..\n",
      "[CV 4/5; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=0.994 total time=  10.6s\n",
      "[CV 5/5; 7/10] START min_samples_leaf=1, min_samples_split=2, n_estimators=125..\n",
      "[CV 5/5; 7/10] END min_samples_leaf=1, min_samples_split=2, n_estimators=125;, score=0.996 total time=  11.2s\n",
      "[CV 1/5; 8/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=175.\n",
      "[CV 1/5; 8/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=175;, score=0.993 total time=  15.0s\n",
      "[CV 2/5; 8/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=175.\n",
      "[CV 2/5; 8/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=175;, score=0.996 total time=  14.5s\n",
      "[CV 3/5; 8/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=175.\n",
      "[CV 3/5; 8/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=175;, score=0.995 total time=  15.8s\n",
      "[CV 4/5; 8/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=175.\n",
      "[CV 4/5; 8/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=175;, score=0.993 total time=  15.3s\n",
      "[CV 5/5; 8/10] START min_samples_leaf=2, min_samples_split=10, n_estimators=175.\n",
      "[CV 5/5; 8/10] END min_samples_leaf=2, min_samples_split=10, n_estimators=175;, score=0.995 total time=  15.6s\n",
      "[CV 1/5; 9/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=100..\n",
      "[CV 1/5; 9/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.992 total time=   8.3s\n",
      "[CV 2/5; 9/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=100..\n",
      "[CV 2/5; 9/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.995 total time=   7.9s\n",
      "[CV 3/5; 9/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=100..\n",
      "[CV 3/5; 9/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.995 total time=   8.5s\n",
      "[CV 4/5; 9/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=100..\n",
      "[CV 4/5; 9/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.992 total time=   8.5s\n",
      "[CV 5/5; 9/10] START min_samples_leaf=4, min_samples_split=2, n_estimators=100..\n",
      "[CV 5/5; 9/10] END min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.995 total time=   8.9s\n",
      "[CV 1/5; 10/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=125.\n",
      "[CV 1/5; 10/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=0.992 total time=  10.8s\n",
      "[CV 2/5; 10/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=125.\n",
      "[CV 2/5; 10/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=0.996 total time=  10.3s\n",
      "[CV 3/5; 10/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=125.\n",
      "[CV 3/5; 10/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=0.995 total time=  10.3s\n",
      "[CV 4/5; 10/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=125.\n",
      "[CV 4/5; 10/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=0.992 total time=  11.2s\n",
      "[CV 5/5; 10/10] START min_samples_leaf=2, min_samples_split=2, n_estimators=125.\n",
      "[CV 5/5; 10/10] END min_samples_leaf=2, min_samples_split=2, n_estimators=125;, score=0.994 total time=  11.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 125, 150, 175,\n",
       "                                                         200]},\n",
       "                   scoring=make_scorer(f1_score, average=micro), verbose=10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=10, scoring=make_scorer(f1_score, average='weighted'))\n",
    "rf_random.fit(clustered_X_train, clustered_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "Xu3JbQ2Gqu18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xu3JbQ2Gqu18",
    "outputId": "0b02c77b-c4f4-499e-d33d-d40d4760d323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true negatives is: 22416\n",
      "The number of false negatives is: 111\n",
      "The number of false positives is: 24\n",
      "The number of true positives is: 156\n",
      "The accuracy is: 0.9940546967895363\n",
      "The accuracy on the 1's is  0.5842696629213483\n",
      "The accuracy on the 0's is  0.9989304812834224\n"
     ]
    }
   ],
   "source": [
    "# print(rf_random.best_params_)\n",
    "clf = RandomForestClassifier(n_estimators=125, min_samples_leaf=1, min_samples_split=2, criterion='entropy')\n",
    "clf.fit(clustered_X_train, clustered_y_train)\n",
    "undersampled_y_pred = clf.predict(clustered_X_test)\n",
    "accuracy = return_accuracy(clustered_y_test, clustered_y_pred, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Outliers_Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
