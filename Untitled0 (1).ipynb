{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "qeM593-TwcoM"
      },
      "outputs": [],
      "source": [
        "# for dealing with data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#for visualization\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as st\n",
        "import random\n",
        "\n",
        "\n",
        "#machine learning libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "#for mathematics and statistics\n",
        "import math\n",
        "from scipy import stats\n",
        "import scipy as sci\n",
        "from scipy.spatial.distance import minkowski\n",
        "from scipy.stats import spearmanr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DD9gASEwigQ",
        "outputId": "24edde97-9783-4bbc-a494-71ec1be0525b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/My Drive'\n",
            "/content/drive/My Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "wcIPdcE4wlb1"
      },
      "outputs": [],
      "source": [
        "# we import the dataset using pandas\n",
        "pddata = pd.read_csv('GSM1586785_ScrH-12A_Exd_14mer_cg.csv.zip', compression='zip', error_bad_lines=False, skiprows=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "FU9GUWIBwnDh"
      },
      "outputs": [],
      "source": [
        "# we visualize the first ten rows of our dataframe\n",
        "pddata = pddata.to_numpy()\n",
        "RelKa = pddata[:, -1]\n",
        "training_data = pddata[:, 2:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "ec7aw0cE6rsV"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def Anomaly_Detection_Isolation_Forests(x, change_split=True):\n",
        "  random_state = np.random.RandomState(42)\n",
        "  contamination = 'auto'\n",
        "  threshold = np.random.uniform(-0.03, -0.02, 1)\n",
        "  model = IsolationForest(n_estimators=120, max_samples='auto', contamination=contamination, random_state=random_state)\n",
        "  model.fit(x)\n",
        "  scores = model.decision_function(x)\n",
        "  if change_split == False:\n",
        "    anomaly_score = model.predict(x)\n",
        "    outliers_indices = np.where(anomaly_score == -1)[0]\n",
        "  if change_split == True:\n",
        "    outliers_indices = split_outliers(threshold, scores)\n",
        "  return contamination, scores, outliers_indices\n",
        "\n",
        "def check_Isolation_Forests(contamination, outliers_indices):\n",
        "  \"\"\"\n",
        "  Simply a check on the proper working of the IF algorithm\n",
        "  \"\"\"\n",
        "  tol = 1.0e-02\n",
        "  if contamination != 'auto':\n",
        "    outliers_percentage = 1 / len(RelKa) * len(outliers_indices)\n",
        "    assert np.abs(contamination-outliers_percentage) < tol\n",
        "\n",
        "def check_boundary_decision(scores, p, verbose=1):\n",
        "  \"\"\"\n",
        "  This function simply controls how many scores returned by the IF algorithm \n",
        "  are likely to be misclassified\n",
        "  \"\"\"\n",
        "  indecision_percentage = 1 / len(RelKa) * np.count_nonzero(np.abs(scores) <= p)\n",
        "  if verbose == 1:\n",
        "    plt.hist(scores)\n",
        "    plt.show()\n",
        "    print(\"The indecision percentage around\", p,  \"is\", indecision_percentage)\n",
        "    print(\"The percentage of outliers detected is\", 1 / len(scores) * len(np.where(scores < 0)[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "d8eYszg3n53z"
      },
      "outputs": [],
      "source": [
        "def split_importance(x, y, importance_class=0.7):\n",
        "  \"\"\"\n",
        "  Split the samples into interesting ones and not interesting ones\n",
        "  :param x: numpy.ndarray:the feature vector of the initial dataset\n",
        "  :param y: numpy.ndarray: the value vector of the initial dataset\n",
        "  :param importance_class: float: the lower bound for the underepresented class\n",
        "  \"\"\"\n",
        "  return x[y >= importance_class], y[y >= importance_class], x[y < importance_class], y[y < importance_class]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "UuXU1lLfoAy1"
      },
      "outputs": [],
      "source": [
        "x_1, y_1, x_0, y_0 = split_importance(training_data, RelKa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "wnZYvVZuoEXN"
      },
      "outputs": [],
      "source": [
        "# split the two classes seperately into train and test set to ensure representation of the minority class\n",
        "# both in the test set and in the train set\n",
        "x_1_train, x_1_test, y_1_train, y_1_test = train_test_split(x_1, y_1, test_size=0.3, random_state=42)\n",
        "x_0_train, x_0_test, y_0_train, y_0_test = train_test_split(x_0, y_0, test_size=0.3, random_state=42)\n",
        "\n",
        "x_train = np.concatenate((x_1_train, x_0_train))\n",
        "y_train = np.concatenate((y_1_train, y_0_train))\n",
        "x_test = np.concatenate((x_1_test, x_0_test))\n",
        "y_test = np.concatenate((y_1_test, y_0_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "vO7-bhBsoMWO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "4fsfcd-qF3YL"
      },
      "outputs": [],
      "source": [
        "def random_undersampling(x, y, alpha, importance_boundary=0.7):\n",
        "  \"\"\"\n",
        "  alpha is a parameter bigger than 1/2\n",
        "  \"\"\"\n",
        "  count = 0\n",
        "  to_drop = []\n",
        "  for i in range(x.shape[0]):\n",
        "    print(\"Checking the \", i, \"sample\")\n",
        "    U = st.uniform.rvs(size=1)\n",
        "    if y[i] <= importance_boundary:\n",
        "      if U <= alpha:\n",
        "        to_drop.append(i)\n",
        "  x = np.delete(x, to_drop, axis=0)\n",
        "  y = np.delete(y, to_drop, axis=0)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "JBdxcA968_G4"
      },
      "outputs": [],
      "source": [
        "def stratified_undersampling(x, y, intervals = 0.05 * np.arange(0, 15)):\n",
        "  \"\"\"\n",
        "  This function performs stratified undersampling on the majority class\n",
        "  by dropping samples in each strata with a probability equal to the frequency\n",
        "  :param x: the datapoints to be undersampled\n",
        "  :param y: the corresponding labels\n",
        "  :param alpha: a hyperparameter to choose the dropping probability \n",
        "  :param intervals: the stratification intervals\n",
        "  :return x and y undersampled  \n",
        "  \"\"\"\n",
        "  # just a check that we drop with high probability in the frequent strata\n",
        "  to_drop = []\n",
        "  # we do a cycle over all intervals\n",
        "  for i in range(len(intervals)-1):\n",
        "    # get the indices for which the label is in the i-th strata\n",
        "    indices = np.where(np.logical_and(intervals[i] < y, y < intervals[i+1]))[0]\n",
        "    # compute the frequency of the i-th strata\n",
        "    frequency = len(indices) / len(y)\n",
        "    # we do a cycle over all elements in such a stratum\n",
        "    for j in range(len(indices)):\n",
        "      # we draw a uniform random variable\n",
        "      U = st.uniform.rvs(size=1)\n",
        "      if U <= frequency:\n",
        "        # we drop every sample in the i-th strata with probability alpha * frequency\n",
        "        to_drop.append(indices[j])\n",
        "  # we drop from x and y the samples and the labels found before\n",
        "  x_new = np.delete(x, to_drop, axis=0)\n",
        "  y_new = np.delete(y, to_drop, axis=0)\n",
        "  return x_new, y_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "4As9ODx8t6_H"
      },
      "outputs": [],
      "source": [
        "#quantization function required for some score functions\n",
        "def quantize(x,cuts=100):\n",
        "  ranges = np.sort(np.unique(pd.cut(x,cuts)))\n",
        "  for i in range(ranges.shape[0]):\n",
        "    ranges_i = ranges[i]\n",
        "    x[(x<=ranges_i.right)&(x>ranges_i.left)] = (ranges_i.left +ranges_i.right)/2\n",
        "  return x\n",
        "\n",
        "def quantize_features(x,cuts=100):\n",
        "  return np.apply_along_axis(quantize,0,x,cuts)\n",
        "\n",
        "#correlation scorers\n",
        "def Spearman(i,j):\n",
        "  ret,_ = spearmanr(i,j)\n",
        "  return ret\n",
        "\n",
        "def Correlation_Score(x,y):\n",
        "  x = x.T\n",
        "  score = [min([abs(Spearman(j,i)) for i in x]) for j in x]\n",
        "  return np.array(score)\n",
        "\n",
        "def Correlation_Score_Max(x,y):\n",
        "  x = x.T\n",
        "  score = [-max([abs(Spearman(j,i)) for i in x]) for j in x]\n",
        "  return np.array(score)\n",
        "\n",
        "def Closest(x, z):\n",
        "    \"\"\"\n",
        "    Returns the index of the sample in x which is the closest one to all the samples in z\n",
        "    :param x: numpy.ndarray: The array of the samples for which we seek to find the furthest\n",
        "    :param z: numpy.ndarray: The array of the samples which we use as a point of reference\n",
        "    :return: int: returns a single index corresponding to the furthest x\n",
        "    \"\"\"\n",
        "    distances = []\n",
        "    # we seek for the closest point to z in x\n",
        "    for i in range(x.shape[0]):\n",
        "        # for each sample in x we calculate the distance from all points in z and we take the minimum\n",
        "        distance = min([np.linalg.norm(j - x[i]) for j in z])\n",
        "        # we add the calculated distance to the list\n",
        "        distances.append(distance)\n",
        "    # we return the closest point by taking the argmin over all calculated distances\n",
        "    return np.argmin(distances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "JtmKdxD5xcMm"
      },
      "outputs": [],
      "source": [
        "def PSU_undersampling_regression(x, y, randomsize, xi, yi):\n",
        "    \"\"\"\n",
        "    This function performs the PSU undersampling of the samples in the x,y arrays\n",
        "    with regards to the set xi,yi. This version is a slight modification of the original proposed algorithm\n",
        "    which helps us improving in the prediction of the RelKa in the central intervals\n",
        "    :param x: numpy.ndarray: The array of samples on which we perform the undersampling\n",
        "    :param y: numpy.ndarray: The labels corresponding to the samples in x\n",
        "    :param randomsize: int: An integer corresponding to the number of samples to be left\n",
        "    :param xi: numpy.ndarray: The array with the samples to be used as a reference for distances\n",
        "    :param yi: numpy.ndarray: The labels of the samples in xi\n",
        "    :return: numpy.ndarray,numpy.ndarray: Returns 2 numpy arrays corresponding to the undersampled data\n",
        "    \"\"\"\n",
        "    # we calculate the centroid of the majority class data\n",
        "    C = np.mean(x, axis=0)\n",
        "    # for each sample in the majority class we calculate the l2 distance from the centroid\n",
        "    dist = np.linalg.norm(x - C, 2, axis=1)\n",
        "    # we sort the distances\n",
        "    indices = dist.argsort()\n",
        "    # we sort the samples and the corresponding labels according to the distances calculated before\n",
        "    x = x[indices]\n",
        "    y = y[indices]\n",
        "    # we split the samples and the corresponding labels in randomsize partitions\n",
        "    split_x = np.array_split(x, randomsize)\n",
        "    split_y = np.array_split(y, randomsize)\n",
        "    # for each partition we calculate the closest point to the minority class xi\n",
        "    indices = [Closest(split_x[i], xi) for i in range(randomsize)]\n",
        "    # the collection of the randomsize closest points calculated above represents the undersampled data\n",
        "    x_resample = np.array([split_x[i][indices[i]] for i in range(randomsize)])\n",
        "    # the corresponding labels of the undersampled data are also returned\n",
        "    y_resample = np.array([split_y[i][indices[i]] for i in range(randomsize)])\n",
        "    return x_resample, y_resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "FcGYPv2Cvwoe"
      },
      "outputs": [],
      "source": [
        "def PSU_stratified_undersampling(x, y, randomsize, intervals, xi, yi):\n",
        "    \"\"\"\n",
        "    This function performs the PSU undersampling of the samples in the x,y arrays\n",
        "    with regards to the set xi,yi. This version is a slight modification of the original proposed algorithm\n",
        "    which helps us improving in the prediction of the RelKa in the central intervals\n",
        "    :param x: numpy.ndarray: The array of samples on which we perform the undersampling\n",
        "    :param y: numpy.ndarray: The labels corresponding to the samples in x\n",
        "    :param randomsize: int: An integer corresponding to the number of samples to be left\n",
        "    :param intervals: the intervals for stratification\n",
        "    :param xi: the reference points\n",
        "    :param yi: the corresponding labels to xi\n",
        "    :return: numpy.ndarray,numpy.ndarray: Returns 2 numpy arrays corresponding to the undersampled data\n",
        "    \"\"\"\n",
        "    # we calculate the number of strata\n",
        "    k = intervals.shape[0]\n",
        "    print(k)\n",
        "    # we initialize the lists for undersampling\n",
        "    x_resample = np.zeros(x.shape[1])\n",
        "    x_resample = x_resample[..., np.newaxis].T\n",
        "    y_resample = []\n",
        "    for i in range(len(intervals)-1):\n",
        "        indices = np.where(np.logical_and(intervals[i] < y, y < intervals[i+1]))[0]\n",
        "        # we get the samples and the labels in the i-th strata\n",
        "        x_ = x[indices]\n",
        "        y_ = y[indices]\n",
        "        frequency = len(indices) / len(y)\n",
        "        # we perform the modified PSU undersampling on the i-th strata\n",
        "        x_, y_ = PSU_undersampling_regression(x_, y_, int(randomsize*frequency), xi, yi)\n",
        "        # we add the samples and the corresponding labels\n",
        "        x_resample = np.concatenate([x_resample, x_], axis=0)\n",
        "        y_resample = np.concatenate([y_resample, y_], axis=0)\n",
        "    # we drop the first row used only for initialization\n",
        "    x_resample = np.delete(x_resample, 0, axis=0)\n",
        "    return x_resample, y_resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "t5MjEsO7t-y-"
      },
      "outputs": [],
      "source": [
        "def Furthest(x, z):\n",
        "    \"\"\"\n",
        "    Returns the index of the sample in x which is furthest from all the samples in z\n",
        "    :param x: numpy.ndarray: The array of the samples for which we seek to find the furthest\n",
        "    :param z: numpy.ndarray: The array of the samples which we use as a point of reference\n",
        "    :return: int: returns a single index corresponding to the furthest x\n",
        "    \"\"\"\n",
        "    # we initialize the maximum distance to be -1 and the furthest sample to have index 0\n",
        "    max_dist_i = 0\n",
        "    max_dist = -1\n",
        "    # we seek for the furthest point from z in x\n",
        "    for i in range(x.shape[0]):\n",
        "        # for each sample in x we calculate the distance from all points in z and we take the minimum\n",
        "        distance = min([np.linalg.norm(j - x[i]) for j in z])\n",
        "        # we update the distance if the current distance is larger than the old one\n",
        "        if max_dist < distance:\n",
        "            max_dist = distance\n",
        "            # we save the current sample i as the candidate furthest point from z\n",
        "            max_dist_i = i\n",
        "    return max_dist_i\n",
        "\n",
        "def PSU_undersampling(x,y,randomsize,xi,yi):\n",
        "  \"\"\"\n",
        "  This function calculates the PSU undersampling of the samples in the x,y arrays\n",
        "  with regards to the set xi,yi\n",
        "  :param x: numpy.ndarray: The array of samples, which we want to undersample\n",
        "  :param y: numpy.ndarray: The array with the labels corresponding to the samples in x\n",
        "  :param randomsize: int: An int corresponding to the number of samples to be left\n",
        "  :param xi: numpy.ndarray: The array with the samples to be used as a reference for distances\n",
        "  :param yi: numpy.ndarray: The labels of these samples\n",
        "  :return: numpy.ndarray,numpy.ndarray: Returns 2 numpy arrays corresponding to the undersampled data\n",
        "  \"\"\"\n",
        "  C = np.mean(x,axis = 0)\n",
        "  dist = np.linalg.norm(x-C,2,axis = 1)\n",
        "  indices = dist.argsort()\n",
        "  x = x[indices]\n",
        "  y = y[indices]\n",
        "  split_x = np.array_split(x,randomsize)\n",
        "  split_y = np.array_split(y,randomsize)\n",
        "  indices = [Furthest(split_x[i],xi) for i in range(randomsize)]\n",
        "  x_resample = np.array([split_x[i][indices[i]] for i in range(randomsize)])\n",
        "  y_resample = np.array([split_y[i][indices[i]] for i in range(randomsize)])\n",
        "  return x_resample, y_resample\n",
        "\n",
        "def PSU_undersampling_reduced_dim(x,y,randomsize,xi,yi):\n",
        "  \"\"\"\n",
        "  This function calculates the PSU undersampling by first doing a dimensionality reduction\n",
        "  of the samples in the x,y arrays with regards to the set xi,yi\n",
        "  :param x: numpy.ndarray: The array of samples, which we want to undersample\n",
        "  :param y: numpy.ndarray: The array with the labels corresponding to the samples in x\n",
        "  :param randomsize: int: An int corresponding to the number of samples to be left\n",
        "  :param xi: numpy.ndarray: The array with the samples to be used as a reference for distances\n",
        "  :param yi: numpy.ndarray: The labels of these samples\n",
        "  :return: numpy.ndarray,numpy.ndarray: Returns 2 numpy arrays corresponding to the undersampled data\n",
        "  \"\"\"\n",
        "  feature_scores =  Fisher_Score(xi,x)\n",
        "  indices = np.sort((-feature_scores).argsort()[:10])\n",
        "  x_filtered = x[:,indices]\n",
        "  x_i = xi[:,indices]\n",
        "  C = np.mean(x_filtered,axis = 0)\n",
        "  dist = np.linalg.norm(x_filtered-C,2,axis = 1)\n",
        "  indices = dist.argsort()\n",
        "  x_filtered = x_filtered[indices]\n",
        "  y = y[indices]\n",
        "  split_x = np.array_split(x_filtered,randomsize)\n",
        "  split_y = np.array_split(y,randomsize)\n",
        "  indices = [Furthest(split_x[i],x_i) for i in range(randomsize)]\n",
        "  split_x = np.array_split(x,randomsize)\n",
        "  x_resample = np.array([split_x[i][indices[i]] for i in range(randomsize)])\n",
        "  y_resample = np.array([split_y[i][indices[i]] for i in range(randomsize)])\n",
        "  return x_resample, y_resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "uJq6YmmPoTM1"
      },
      "outputs": [],
      "source": [
        "def Fisher_Score(x_import, x_nimport):\n",
        "  \"\"\"\n",
        "  Given two arrays of two classes this function calculates the Fischer_scores to \n",
        "  measure the significance for all features\n",
        "  :param x_import: numpy.ndarray: the array containing the samples of one class\n",
        "  :param x_nimport: numpy.ndarray: the array containing the samples of the other class\n",
        "  :return: numpy.ndarray: returns an array containg the Fisher_Score for all features \n",
        "  \"\"\"\n",
        "  mean_import = np.mean(x_import, axis = 0)\n",
        "  mean_nimport = np.mean(x_nimport, axis = 0)\n",
        "  mean_dist = np.absolute(mean_import - mean_nimport)\n",
        "  std_import = np.std(x_import, axis=0)\n",
        "  std_nimport = np.std(x_nimport, axis=0)\n",
        "  std_sum = std_import+std_nimport\n",
        "  #return std_sum\n",
        "  return np.divide(mean_dist,std_sum)\n",
        "\n",
        "def calculate_distances(x, distance):\n",
        "  \"\"\"\n",
        "  Calculates the distance between any two pairs of the set x using \n",
        "  the Minkowski distance of degree distance.\n",
        "  :param x: numpy.ndarray: the vector for which we will calculate the distance \n",
        "                            between all of its elements \n",
        "  :param distance: float: the norm which should be used for the Minkowski distance\n",
        "  :return: numpy.ndarray: returns the Minkowski distance with the specified norm \n",
        "                          between all pairs of elements in x \n",
        "  \"\"\"\n",
        "  dist = np.array([[minkowski(a1,a2,distance) for a2 in x] for a1 in x])\n",
        "  np.fill_diagonal(dist,float('inf'))\n",
        "  return dist\n",
        "\n",
        "def random_sampler(x, y, randomsize):\n",
        "  \"\"\"\n",
        "  This function does random undersampling of vectors x,y and reduces them to \n",
        "  size random size\n",
        "  :param x: numpy.ndarray: the feature vector to be subsampled\n",
        "  :param y: numpy.ndarray: the label vector to be subsampled\n",
        "  :return: <class 'tuple'>: A tuple containing the two undersampled vectors\n",
        "  \"\"\"\n",
        "  p = np.random.permutation(len(y))\n",
        "  new_x = x[p]\n",
        "  new_y = y[p]\n",
        "  return new_x[:randomsize],new_y[:randomsize]\n",
        "\n",
        "def generate_samples(x, y, neighbors, N):\n",
        "  \"\"\"\n",
        "  This function generate N samples which are convex combinations of \n",
        "  the features of x and the labels of y\n",
        "  :param x: numpy.ndarray:\n",
        "  :param y: numpy.ndarray:\n",
        "  :return: <class 'tuple'>:\n",
        "  \"\"\"\n",
        "  new_samples_x = []\n",
        "  new_samples_y = []\n",
        "  for i in range(N):\n",
        "    random_sample_i = random.randint(0,y.shape[0]-1)\n",
        "    x_i = x[random_sample_i]\n",
        "    random_sample_j = random.randint(0,neighbors.shape[1]-1)\n",
        "    neigh_i = neighbors[random_sample_i,random_sample_j]\n",
        "    x_j = x[neigh_i]\n",
        "    lambda_ = random.uniform(0,1)\n",
        "    y_i = y[random_sample_i]\n",
        "    y_j = y[neigh_i]\n",
        "    new_x = x_i + lambda_*(x_j-x_i)\n",
        "    new_y = y_i + lambda_*(y_j-y_i)\n",
        "    new_samples_x.append(new_x)\n",
        "    new_samples_y.append(new_y)\n",
        "  return np.array(new_samples_x),np.array(new_samples_y)\n",
        "\n",
        "def random_sampler(x,y,randomsize):\n",
        "  \"\"\"\n",
        "  This function does random undersampling of vectors x,y and reduces them to \n",
        "  size random size\n",
        "  :param x: numpy.ndarray: the feature vector to be subsampled\n",
        "  :param y: numpy.ndarray: the label vector to be subsampled\n",
        "  :return: <class 'tuple'>: A tuple containing the two undersampled vectors\n",
        "  \"\"\"\n",
        "  p = np.random.permutation(len(y))\n",
        "  new_x = x[p]\n",
        "  new_y = y[p]\n",
        "  return new_x[:randomsize],new_y[:randomsize]\n",
        "\n",
        "def generate_samples(x,y,neighbors,N):\n",
        "  \"\"\"\n",
        "  This function generate N samples which are convex combinations of \n",
        "  the features of x and the labels of y\n",
        "  :param x: numpy.ndarray:\n",
        "  :param y: numpy.ndarray:\n",
        "  :return: <class 'tuple'>:\n",
        "  \"\"\"\n",
        "  new_samples_x = []\n",
        "  new_samples_y = []\n",
        "  for i in range(N):\n",
        "    random_sample_i = random.randint(0,y.shape[0]-1)\n",
        "    x_i = x[random_sample_i]\n",
        "    random_sample_j = random.randint(0,neighbors.shape[1]-1)\n",
        "    neigh_i = neighbors[random_sample_i,random_sample_j]\n",
        "    x_j = x[neigh_i]\n",
        "    lambda_ = random.uniform(0,1)\n",
        "    y_i = y[random_sample_i]\n",
        "    y_j = y[neigh_i]\n",
        "    new_x = x_i + lambda_*(x_j-x_i)\n",
        "    new_y = y_i + lambda_*(y_j-y_i)\n",
        "    new_samples_x.append(new_x)\n",
        "    new_samples_y.append(new_y)\n",
        "  return np.array(new_samples_x),np.array(new_samples_y)\n",
        "\n",
        "def smote_sf_classification(x, y, undersample=0.1, oversample=0.3, attribute_scorer=Fisher_Score,\n",
        "                            attribute_number=10, distance=float('inf'), kneighbors=3, importance_class=0.7):\n",
        "    \"\"\"\n",
        "    This function takes the complete input and produces a more balanced dataset based on the importance class\n",
        "    :param x: numpy.ndarray: the feature vector of the initial dataset\n",
        "    :param y: numpy.ndarray: the value vector of the initial dataset\n",
        "    :param undersample: float: the percentage of the dominant class that we want to keep\n",
        "    :param oversample: float: the percentage of the dataset that the minority class will be at the end\n",
        "    :param attribute_scorer: function: a function which will be used to score the relevance of a feature\n",
        "    :param attribute_number: int: the number of attributes to keep according to their score\n",
        "    :param distance: float: the norm which should be used for the Minkowski distance\n",
        "    :param kneighbors: int: the number of nearest neighbours to be considered for each point\n",
        "    :param importance_class: float: the lower bound for the under-represented class\n",
        "    :return: returns 2 new feature vectors and 2 new label vectors containing\n",
        "            the data for the importance class and the data for the non importance\n",
        "            class and their labels.\n",
        "    \"\"\"\n",
        "    # we split the training set into majority and minority class according to the value of the label\n",
        "    x_import = x[y >= importance_class]\n",
        "    y_import = y[y >= importance_class]\n",
        "    x_nimport = x[y < importance_class]\n",
        "    y_nimport = y[y < importance_class]\n",
        "\n",
        "    # we calculate the Fisher score for all the features\n",
        "    feature_scores = attribute_scorer(x_import, x_nimport)\n",
        "    # we find the attribute_number highest coordinates of the feature_scores vector\n",
        "    indices = np.sort((-feature_scores).argsort()[:attribute_number])\n",
        "    # we filter the samples to be represented only by the attribute number highest scored features\n",
        "    x_import_filtered = x_import[:, indices]\n",
        "    # we calculate the distances between the datapoints considering only the important features as otherwise we\n",
        "    # fall into the curse of dimensionality\n",
        "    distances = calculate_distances(x_import_filtered, distance)\n",
        "    # we find the kneighbors lowest indices of the distances of each sample, the corresponding datapoints are the\n",
        "    # nearest neighbours to be drawn randomly for the oversampling procedure\n",
        "    neighbors = np.array([np.sort(d.argsort()[:kneighbors]) for d in distances])\n",
        "    # we first undersample the the majority class\n",
        "    # we calculate the final size of the undersampled data\n",
        "    nimport_len = int(undersample * y_nimport.shape[0])\n",
        "    # we perform undersampling\n",
        "    x_nimport, y_nimport = PSU_undersampling(x_nimport, y_nimport, nimport_len, x_import, y_import)\n",
        "    # we calculate the number of samples to be generated by the oversampling algorithm\n",
        "    N = int(oversample * (y_nimport.shape[0]) - y_import.shape[0])\n",
        "    # we perform oversampling\n",
        "    new_samples_x, new_samples_y = generate_samples(x_import, y_import, neighbors, N)\n",
        "    # we merge the new samples with the old samples of the minority class and their labels\n",
        "    x_import = np.concatenate((x_import, new_samples_x))\n",
        "    y_import = np.concatenate((y_import, new_samples_y))\n",
        "    # we stack the samples and the labels of the majority and minority class\n",
        "    x_ret = np.concatenate((x_import, x_nimport))\n",
        "    y_ret = np.concatenate((y_import, y_nimport))\n",
        "    # x_ret represents the balanced dataset and y_ret the corresponding labels\n",
        "    return x_ret, y_ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "RzW1M9AHv8Dk"
      },
      "outputs": [],
      "source": [
        "def smote_sf_regression(x, y, undersample=0.1, oversample=0.3, attribute_scorer=Fisher_Score,\n",
        "                        attribute_number=10, distance=float('inf'), kneighbors=3,\n",
        "                        importance_class=0.7, width_strata=0.1):\n",
        "    \"\"\"\n",
        "    This function performs stratified undersampling and SMOTE oversampling for the regression task\n",
        "    @param x: the initial dataset\n",
        "    @param y: the corresponding labels\n",
        "    @param undersample: the undersampling rate\n",
        "    @param oversample: the oversampling rate\n",
        "    @param attribute_scorer: the scorer for the features\n",
        "    @param attribute_number: the number of features to be considered for the distances between samples\n",
        "    @param distance: the degree of the Minkowski distance to be used\n",
        "    @param kneighbors: the number of nearest neighbours for the oversampling algorithm\n",
        "    @param importance_class: the importance boundary between majority and minority class\n",
        "    @param width_strata: the width of the strata for the stratified undersampling\n",
        "    @return: x and y rebalanced\n",
        "    \"\"\"\n",
        "    # we split the training set into majority and minority class according to the value of the label\n",
        "    x_import = x[y >= importance_class]\n",
        "    y_import = y[y >= importance_class]\n",
        "    x_nimport = x[y < importance_class]\n",
        "    y_nimport = y[y < importance_class]\n",
        "\n",
        "    # we calculate the Fisher score for all the features\n",
        "    feature_scores = attribute_scorer(x_import, x_nimport)\n",
        "    # we find the attribute_number highest coordinates of the feature_scores vector\n",
        "    indices = np.sort((-feature_scores).argsort()[:attribute_number])\n",
        "    # we filter the samples to be represented only by the attribute number highest scored features\n",
        "    x_import_filtered = x_import[:, indices]\n",
        "    # we calculate the distances between the datapoints considering only the important features as otherwise we\n",
        "    # fall into the curse of dimensionality\n",
        "    distances = calculate_distances(x_import_filtered, distance)\n",
        "    # we find the kneighbors lowest indices of the distances of each sample, the corresponding datapoints are the\n",
        "    # nearest neighbours to be drawn randomly for the oversampling procedure\n",
        "    neighbors = np.array([np.sort(d.argsort()[:kneighbors]) for d in distances])\n",
        "    # we get the undersampled datasize\n",
        "    nimport_len = int(undersample * y_nimport.shape[0])\n",
        "    print(nimport_len)\n",
        "    # we perform stratified undersampling\n",
        "    intervals = width_strata * np.arange(int(importance_class / width_strata))\n",
        "    print(intervals)\n",
        "    x_nimport, y_nimport = stratified_undersampling(x_nimport, y_nimport, intervals)\n",
        "    # we compute the number of new samples to be generated\n",
        "    N = int(oversample * (y_nimport.shape[0]) - y_import.shape[0])\n",
        "    new_samples_x, new_samples_y = generate_samples(x_import, y_import, neighbors, N)\n",
        "    # we merge the new samples with the old samples of the minority class and their labels\n",
        "    x_import = np.concatenate((x_import, new_samples_x))\n",
        "    y_import = np.concatenate((y_import, new_samples_y))\n",
        "    # we stack the samples and the labels of the majority and minority class\n",
        "    x_ret = np.concatenate((x_import, x_nimport))\n",
        "    y_ret = np.concatenate((y_import, y_nimport))\n",
        "    # x_ret represents the balanced dataset and y_ret the corresponding labels\n",
        "    return x_ret, y_ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c4WT7AvpFRs",
        "outputId": "0bc780cc-69a7-4903-8bb9-d541ff8d10bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11917\n",
            "[0.  0.1 0.2 0.3 0.4 0.5]\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = smote_sf_regression(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "ESd8q6QBxvdu",
        "outputId": "858ad8a2-5d12-44d5-9f18-bebaeb007b85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efd72069ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 228
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 842.4x595.44 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.kdeplot(y_train, fill=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "a63d2612",
        "outputId": "4576c65a-3607-4456-8d92-f432c70da786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17:29:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-229-badf1672b5f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model = XGBRegressor(subsample = 0.8999999999999999, n_estimators= 500,\n\u001b[1;32m      4\u001b[0m                      max_depth = 20, learning_rate = 0.01, colsample_bytree = 0.7999999999999999, colsample_bylevel = 0.6, obj=MSE)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# we use XGB regressor model with the following hyperparameters\n",
        "\n",
        "model = XGBRegressor(subsample = 0.8999999999999999, n_estimators= 500,\n",
        "                     max_depth = 20, learning_rate = 0.01, colsample_bytree = 0.7999999999999999, colsample_bylevel = 0.6, obj=MSE)\n",
        "model.fit(x_train, y_train,eval_metric=MSE)\n",
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6898c6e"
      },
      "outputs": [],
      "source": [
        "range_values = np.arange(0.05,1.05,0.1)\n",
        "mse_ranges = []\n",
        "for val in range_values:\n",
        "    labels_range = y_test[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    correspondent_predictions = predictions[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    mse_ranges.append(MSE(correspondent_predictions, labels_range))\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "intervals = ['0.0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4','0.4-0.5', '0.5-0.6', '0.6-0-7', '0.7-0.8', '0.8-0.9', '0.9-1.0']\n",
        "dict_mse = {'intervals': intervals, 'mse': mse_ranges}\n",
        "df_mse = pd.DataFrame.from_dict(dict_mse)\n",
        "sns.barplot(x = df_mse['intervals'], y = df_mse['mse'], color='blue')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8mUhI5Qp44MW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}