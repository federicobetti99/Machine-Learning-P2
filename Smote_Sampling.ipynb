{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smote_Sampling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kS1CPM9u0lo5"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import minkowski\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Fisher_Score(x_import,x_nimport):\n",
        "  \"\"\"\n",
        "  Given two arrays of two classes this function calculates the Fischer_scores to \n",
        "  measure the significance for all features\n",
        "  :param x_import: numpy.ndarray: the array containing the samples of one class\n",
        "  :param x_nimport: numpy.ndarray: the array containing the samples of the other class\n",
        "  :return: numpy.ndarray: returns an array containg the Fisher_Score for all features \n",
        "  \"\"\"\n",
        "  mean_import = np.mean(x_import,axis = 0)\n",
        "  mean_nimport = np.mean(x_nimport,axis = 0)\n",
        "  mean_dist = np.absolute(mean_import-mean_nimport)\n",
        "  std_import = np.std(x_import,axis=0)\n",
        "  std_nimport = np.std(x_nimport,axis=0)\n",
        "  std_sum = std_import+std_nimport\n",
        "  #return std_sum\n",
        "  return np.divide(mean_dist,std_sum)"
      ],
      "metadata": {
        "id": "c4tlRQ8CDd1V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_distances(x,distance):\n",
        "  \"\"\"\n",
        "  Calculates the distance between any two pairs of the set x using \n",
        "  the Minkowski distance of degree distance.\n",
        "  :param x: numpy.ndarray: the vector for which we will calculate the distance \n",
        "                            between all of its elements \n",
        "  :param distance: float: the norm which should be used for the Minkowski distance\n",
        "  :return: numpy.ndarray: returns the Minkowski distance with the specified norm \n",
        "                          between all pairs of elements in x \n",
        "  \"\"\"\n",
        "  dist = np.array([[minkowski(a1,a2,distance) for a2 in x] for a1 in x])\n",
        "  np.fill_diagonal(dist,float('inf'))\n",
        "  return dist"
      ],
      "metadata": {
        "id": "sILQ-4ABZLk5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_sampler(x,y,randomsize):\n",
        "  \"\"\"\n",
        "  This function does random undersampling of vectors x,y and reduces them to \n",
        "  size random size\n",
        "  :param x: numpy.ndarray: the feature vector to be subsampled\n",
        "  :param y: numpy.ndarray: the label vector to be subsampled\n",
        "  :return: <class 'tuple'>: A tuple containing the two undersampled vectors\n",
        "  \"\"\"\n",
        "  p = np.random.permutation(len(y))\n",
        "  new_x = x[p]\n",
        "  new_y = y[p]\n",
        "  return new_x[:randomsize],new_y[:randomsize]"
      ],
      "metadata": {
        "id": "rlBtdkpn0qOH"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_samples(x,y,neighbors,N):\n",
        "  \"\"\"\n",
        "  This function generate N samples which are convex combinations of \n",
        "  the features of x and the labels of y\n",
        "  :param x: numpy.ndarray:\n",
        "  :param y: numpy.ndarray:\n",
        "  :return: <class 'tuple'>:\n",
        "  \"\"\"\n",
        "  new_samples_x = []\n",
        "  new_samples_y = []\n",
        "  for i in range(N):\n",
        "    random_sample_i = random.randint(0,y.shape[0]-1)\n",
        "    x_i = x[random_sample_i]\n",
        "    random_sample_j = random.randint(0,neighbors.shape[1]-1)\n",
        "    neigh_i = neighbors[random_sample_i,random_sample_j]\n",
        "    x_j = x[neigh_i]\n",
        "    lambda_ = random.uniform(0,1)\n",
        "    y_i = y[random_sample_i]\n",
        "    y_j = y[neigh_i]\n",
        "    new_x = x_i + lambda_*(x_j-x_i)\n",
        "    new_y = y_i + lambda_*(y_j-y_i)\n",
        "    new_samples_x.append(new_x)\n",
        "    new_samples_y.append(new_y)\n",
        "  return np.array(new_samples_x),np.array(new_samples_y)"
      ],
      "metadata": {
        "id": "vYydwJry9YoL"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def smote_sf(x, y, undersample=0.5, oversample = 0.1, attribute_scorer=Fisher_Score, \n",
        "             attribute_number = 10, distance = float('inf'), kneighbors = 3,\n",
        "             undersampling = random_sampler, importance_class = 0.7):\n",
        "  \"\"\"\n",
        "  This function takes the complete input and produces a more balanced dataset based on the importance class\n",
        "  :param x: numpy.ndarray: the feature vector of the initial dataset\n",
        "  :param y: numpy.ndarray: the value vector of the initial dataset\n",
        "  :param undersample: float: the percentage of the dominant class that we want to keep\n",
        "  :param oversample: float: the percentage of the dataset that the small class will be at the end\n",
        "  :param attribute_scorer: function: a function which will be used to score the relevance of a feature\n",
        "  :param attribute_number: int: the number of attributes to keep according to their score\n",
        "  :param distance: float: the norm which should be used for the Minkowski distance\n",
        "  :param kneighbors: int: the number of samples which should be considered for each point \n",
        "  :param undersampling: function: the function to use for the undersampling of the majority class\n",
        "  :param importance_class: float: the lower bound for the underepresented class\n",
        "  :return: returns 2 new feature vectors and 2 new label vectors containing \n",
        "            the data for the importance class and the data for the non importance \n",
        "            class and their labels. \n",
        "  \"\"\"\n",
        "  x_import = x[y>=importance_class]\n",
        "  y_import = y[y>=importance_class]\n",
        "  x_nimport = x[y<importance_class]\n",
        "  y_nimport = y[y<importance_class]\n",
        "\n",
        "  feature_scores =  attribute_scorer(x_import,x_nimport)\n",
        "  #find the attribute_number highest coordinates of the feature_scores vector\n",
        "  indices = np.sort((-feature_scores).argsort()[:attribute_number])\n",
        "  x_import_filtered = x_import[:,indices]\n",
        "  #x_nimport = x_nimport[:,indices]\n",
        "  distances = calculate_distances(x_import_filtered,distance)\n",
        "  #find the k lowest indices\n",
        "  neighbors = np.array([ np.sort(d.argsort()[:(kneighbors)]) for d in distances])\n",
        "  #undersampling for the majority class\n",
        "  nimport_len = int(undersample*y_nimport.shape[0])\n",
        "  x_nimport,y_nimport = undersampling(x_nimport,y_nimport,nimport_len)\n",
        "  #Calculate the number of samples to be generated\n",
        "  N = int(oversample*(y_nimport.shape[0]) - y_import.shape[0])\n",
        "  #Generate N new samples\n",
        "  new_samples_x,new_samples_y = generate_samples(x_import, y_import, neighbors, N)\n",
        "  print(new_samples_x,new_samples_y)\n",
        "  #merge the new samples of the minority class with its old samples\n",
        "  x_import = np.concatenate((x_import,new_samples_x))\n",
        "  y_import = np.concatenate((y_import,new_samples_y))\n",
        "\n",
        "  return x_import,y_import,x_nimport,y_nimport"
      ],
      "metadata": {
        "id": "19580vOc1PXD"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array([[1,2,1],[5,4,11],[3,-3,2],[15,1,4],[3,3,3],[3,-3,2],[15,1,4],[3,3,3],[3,4,3]])\n",
        "y=np.array([0.3,0.4,0.1,1.,0.11,0.1,0.1,0.8,0.3])\n",
        "\n",
        "smote_sf(X,y,undersample = 0.8,oversample= 1.,attribute_number=2,kneighbors=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDKCQviy6I9C",
        "outputId": "5cfa9bc3-cf57-41d5-e675-88dc234ec7e8"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.87149771  2.85475038  3.07262481]\n",
            " [12.15351783  1.47441369  3.76279315]\n",
            " [11.01100726  1.66483212  3.66758394]] [0.81452496 0.95255863 0.93351679]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[15.        ,  1.        ,  4.        ],\n",
              "        [ 3.        ,  3.        ,  3.        ],\n",
              "        [ 3.87149771,  2.85475038,  3.07262481],\n",
              "        [12.15351783,  1.47441369,  3.76279315],\n",
              "        [11.01100726,  1.66483212,  3.66758394]]),\n",
              " array([1.        , 0.8       , 0.81452496, 0.95255863, 0.93351679]),\n",
              " array([[ 3,  3,  3],\n",
              "        [ 1,  2,  1],\n",
              "        [ 3,  4,  3],\n",
              "        [ 5,  4, 11],\n",
              "        [15,  1,  4]]),\n",
              " array([0.11, 0.3 , 0.3 , 0.4 , 0.1 ]))"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    }
  ]
}