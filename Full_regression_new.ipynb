{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Full_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EFJD9FLSoy16"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "import math\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from scipy import stats\n",
        "import scipy as sci\n",
        "\n",
        "import random\n",
        "\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from scipy.spatial.distance import minkowski\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "from imblearn.under_sampling import *\n",
        "\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount  Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive/Colab\\ Notebooks/ML\\ Project2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dKpmmGRrbFV",
        "outputId": "a8e40af5-f83e-4a6d-ac27-5fdde2674052"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/ML Project2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset"
      ],
      "metadata": {
        "id": "lQeZc60OuW1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('GSM1586785_ScrH-12A_Exd_14mer_cg.csv.zip', compression='zip')"
      ],
      "metadata": {
        "id": "f1fAXgGIrqyH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns = 'Unnamed: 0', inplace = True)\n",
        "df.drop(columns = 'Kmer', inplace = True)"
      ],
      "metadata": {
        "id": "ATPYYK6HruO7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['relKa'].to_numpy()\n",
        "x = df.loc[:, df.columns != 'relKa'].to_numpy()"
      ],
      "metadata": {
        "id": "2hLrB8vquQHJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split to 0 & 1"
      ],
      "metadata": {
        "id": "nj8JK_I4y2BB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_importance(x,y,importance_class=0.7):\n",
        "  \"\"\"\n",
        "  Split the samples into interesting ones and not interesting ones\n",
        "  :param x: numpy.ndarray:the feature vector of the initial dataset\n",
        "  :param y: numpy.ndarray: the value vector of the initial dataset\n",
        "  :param importance_class: float: the lower bound for the underepresented class\n",
        "  \"\"\"\n",
        "  return x[y>=importance_class], y[y>=importance_class], x[y<importance_class], y[y<importance_class]"
      ],
      "metadata": {
        "id": "wK2ng3NRy47T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_1,y_1,x_0,y_0 = split_importance(x,y)"
      ],
      "metadata": {
        "id": "EgJ9bfph0d3d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train - Test Split"
      ],
      "metadata": {
        "id": "WzFdM7KK1fPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the two classes seperately into train and test set to ensure representation of the minority class\n",
        "# both in the test set and in the train set\n",
        "x_1_train,x_1_test,y_1_train,y_1_test = train_test_split(x_1, y_1, test_size=0.30, random_state=42)\n",
        "x_0_train,x_0_test,y_0_train,y_0_test = train_test_split(x_0, y_0, test_size=0.30, random_state=42)\n",
        "\n",
        "x_train = np.concatenate((x_1_train,x_0_train))\n",
        "y_train = np.concatenate((y_1_train,y_0_train))\n",
        "x_test = np.concatenate((x_1_test,x_0_test))\n",
        "y_test = np.concatenate((y_1_test,y_0_test))"
      ],
      "metadata": {
        "id": "0xgHKQkg1dPA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove Outliers"
      ],
      "metadata": {
        "id": "6zM9TrUluZKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Worse performances\n",
        "def Anomaly_Detection_Isolation_Forests(x, change_split=True):\n",
        "  random_state = np.random.RandomState(42)\n",
        "  contamination = 'auto'\n",
        "  threshold = np.random.uniform(-0.03, -0.02, 1)\n",
        "  model = IsolationForest(n_estimators=120, max_samples='auto', contamination=contamination, random_state=random_state)\n",
        "  model.fit(x)\n",
        "  scores = model.decision_function(x)\n",
        "  if change_split == False:\n",
        "    anomaly_score = model.predict(x)\n",
        "    outliers_indices = np.where(anomaly_score == -1)[0]\n",
        "  if change_split == True:\n",
        "    outliers_indices = split_outliers(threshold, scores)\n",
        "  return contamination, scores, outliers_indices\n",
        "\n",
        "def check_Isolation_Forests(contamination, outliers_indices):\n",
        "  \"\"\"\n",
        "  Simply a check on the proper working of the IF algorithm\n",
        "  \"\"\"\n",
        "  tol = 1.0e-02\n",
        "  if contamination != 'auto':\n",
        "    outliers_percentage = 1 / len(RelKa) * len(outliers_indices)\n",
        "    assert np.abs(contamination-outliers_percentage) < tol\n",
        "\n",
        "def check_boundary_decision(scores, p, verbose=1):\n",
        "  \"\"\"\n",
        "  This function simply controls how many scores returned by the IF algorithm \n",
        "  are likely to be misclassified\n",
        "  \"\"\"\n",
        "  indecision_percentage = 1 / len(y) * np.count_nonzero(np.abs(scores) <= p)\n",
        "  if verbose == 1:\n",
        "    plt.hist(scores)\n",
        "    plt.show()\n",
        "    print(\"The indecision percentage around\", p,  \"is\", indecision_percentage)\n",
        "    print(\"The percentage of outliers detected is\", 1 / len(scores) * len(np.where(scores < 0)[0]))\n",
        "\n",
        "def drop_outliers(x, y, outliers):\n",
        "  x = np.delete(x, outliers, axis=0)\n",
        "  y = np.delete(y, outliers, axis=0)\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "tBDiGVbquTSa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contamination, scores, outliers_indices = Anomaly_Detection_Isolation_Forests(x_train, change_split=False)\n",
        "check_Isolation_Forests(contamination, outliers_indices)\n",
        "check_boundary_decision(scores, 0.02, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "wU_e-0CRukGZ",
        "outputId": "6befb35a-a1f9-4300-aa5f-2e977bd4870b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The indecision percentage around 0.02 is 0.3352659440383161\n",
            "The percentage of outliers detected is 0.06591796057149557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = drop_outliers(x_train, y_train, outliers_indices)"
      ],
      "metadata": {
        "id": "nY4GquNvuoIZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Manipulation"
      ],
      "metadata": {
        "id": "M30LuGhM8_AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "3uRlU-2s9Bkj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boxcox Transformation"
      ],
      "metadata": {
        "id": "c0jXjMimOOGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, fitted_lambda= stats.boxcox(list(y_train),lmbda=None)\n",
        "#print(fitted_lambda)\n",
        "#print(stats.boxcox([0.7,1], fitted_lambda))\n",
        "y_train = np.array(y_train)\n",
        "print(fitted_lambda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lib9c4qEOQU5",
        "outputId": "98bfed55-b451-4b88-cb4f-f0b85539394d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.0008549422054305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Smote Sampling "
      ],
      "metadata": {
        "id": "YIluw6pa-OIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#quantization function required for some score functions\n",
        "def quantize(x,cuts=100):\n",
        "  ranges = np.sort(np.unique(pd.cut(x,cuts)))\n",
        "  for i in range(ranges.shape[0]):\n",
        "    ranges_i = ranges[i]\n",
        "    x[(x<=ranges_i.right)&(x>ranges_i.left)] = (ranges_i.left +ranges_i.right)/2\n",
        "  return x\n",
        "\n",
        "def quantize_features(x,cuts=100):\n",
        "  return np.apply_along_axis(quantize,0,x,cuts)\n",
        "\n",
        "#correlation scorers\n",
        "def Spearman(i,j):\n",
        "  ret,_ = spearmanr(i,j)\n",
        "  return ret\n",
        "\n",
        "def Correlation_Score(x,y):\n",
        "  x = x.T\n",
        "  score = [min([abs(Spearman(j,i)) for i in x]) for j in x]\n",
        "  return np.array(score)\n",
        "\n",
        "def Correlation_Score_Max(x,y):\n",
        "  x = x.T\n",
        "  score = [-max([abs(Spearman(j,i)) for i in x]) for j in x]\n",
        "  return np.array(score)\n"
      ],
      "metadata": {
        "id": "tsW_zpazlj_A"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Furthest(x,z):\n",
        "  \"\"\"\n",
        "  Returns the index of the sample in x which is furthest from all the samples in z\n",
        "  :param x: numpy.ndarray: The array of the samples for which we seek to find the furthest\n",
        "  :param z: numpy.ndarray: The array of the samples which we use as a point of reference\n",
        "  :return: int: returns a single index corresponding to the furthest x\n",
        "  \"\"\"\n",
        "  distances = []\n",
        "  for i in range(x.shape[0]):\n",
        "    distance = min([np.linalg.norm(j-x[i]) for j in z])\n",
        "    distances.append(distance)\n",
        "  return np.argmin(distances)\n",
        "\n",
        "def PSU_undersampling(x,y,randomsize,xi,yi):\n",
        "  \"\"\"\n",
        "  This function calculates the PSU undersampling of the samples in the x,y arrays\n",
        "  with regards to the set xi,yi\n",
        "  :param x: numpy.ndarray: The array of samples, which we want to undersample\n",
        "  :param y: numpy.ndarray: The array with the labels corresponding to the samples in x\n",
        "  :param randomsize: int: An int corresponding to the number of samples to be left\n",
        "  :param xi: numpy.ndarray: The array with the samples to be used as a reference for distances\n",
        "  :param yi: numpy.ndarray: The labels of these samples\n",
        "  :return: numpy.ndarray,numpy.ndarray: Returns 2 numpy arrays corresponding to the undersampled data\n",
        "  \"\"\"\n",
        "  C = np.mean(x,axis = 0)\n",
        "  dist = np.linalg.norm(x-C,2,axis = 1)\n",
        "  indices = dist.argsort()\n",
        "  x = x[indices]\n",
        "  y = y[indices]\n",
        "  split_x = np.array_split(x,randomsize)\n",
        "  split_y = np.array_split(y,randomsize)\n",
        "  indices = [Furthest(split_x[i],xi) for i in range(randomsize)]\n",
        "  x_resample = np.array([split_x[i][indices[i]] for i in range(randomsize)])\n",
        "  y_resample = np.array([split_y[i][indices[i]] for i in range(randomsize)])\n",
        "  return x_resample,y_resample\n",
        "\n",
        "def PSU_undersampling_reduced_dim(x,y,randomsize,xi,yi):\n",
        "  \"\"\"\n",
        "  This function calculates the PSU undersampling by first doing a dimensionality reduction\n",
        "  of the samples in the x,y arrays with regards to the set xi,yi\n",
        "  :param x: numpy.ndarray: The array of samples, which we want to undersample\n",
        "  :param y: numpy.ndarray: The array with the labels corresponding to the samples in x\n",
        "  :param randomsize: int: An int corresponding to the number of samples to be left\n",
        "  :param xi: numpy.ndarray: The array with the samples to be used as a reference for distances\n",
        "  :param yi: numpy.ndarray: The labels of these samples\n",
        "  :return: numpy.ndarray,numpy.ndarray: Returns 2 numpy arrays corresponding to the undersampled data\n",
        "  \"\"\"\n",
        "  feature_scores =  Fisher_Score(xi,x)\n",
        "  indices = np.sort((-feature_scores).argsort()[:10])\n",
        "  x_filtered = x[:,indices]\n",
        "  x_i = xi[:,indices]\n",
        "  C = np.mean(x_filtered,axis = 0)\n",
        "  dist = np.linalg.norm(x_filtered-C,2,axis = 1)\n",
        "  indices = dist.argsort()\n",
        "  x_filtered = x_filtered[indices]\n",
        "  y = y[indices]\n",
        "  split_x = np.array_split(x_filtered,randomsize)\n",
        "  split_y = np.array_split(y,randomsize)\n",
        "  indices = [Furthest(split_x[i],x_i) for i in range(randomsize)]\n",
        "  split_x = np.array_split(x,randomsize)\n",
        "  x_resample = np.array([split_x[i][indices[i]] for i in range(randomsize)])\n",
        "  y_resample = np.array([split_y[i][indices[i]] for i in range(randomsize)])\n",
        "  return x_resample,y_resample\n",
        "\n",
        "def Fisher_Score(x_import,x_nimport):\n",
        "  \"\"\"\n",
        "  Given two arrays of two classes this function calculates the Fischer_scores to \n",
        "  measure the significance for all features\n",
        "  :param x_import: numpy.ndarray: the array containing the samples of one class\n",
        "  :param x_nimport: numpy.ndarray: the array containing the samples of the other class\n",
        "  :return: numpy.ndarray: returns an array containg the Fisher_Score for all features \n",
        "  \"\"\"\n",
        "  mean_import = np.mean(x_import,axis = 0)\n",
        "  mean_nimport = np.mean(x_nimport,axis = 0)\n",
        "  mean_dist = np.absolute(mean_import-mean_nimport)\n",
        "  std_import = np.std(x_import,axis=0)\n",
        "  std_nimport = np.std(x_nimport,axis=0)\n",
        "  std_sum = std_import+std_nimport\n",
        "  #return std_sum\n",
        "  return np.divide(mean_dist,std_sum)\n",
        "\n",
        "def calculate_distances(x,distance):\n",
        "  \"\"\"\n",
        "  Calculates the distance between any two pairs of the set x using \n",
        "  the Minkowski distance of degree distance.\n",
        "  :param x: numpy.ndarray: the vector for which we will calculate the distance \n",
        "                            between all of its elements \n",
        "  :param distance: float: the norm which should be used for the Minkowski distance\n",
        "  :return: numpy.ndarray: returns the Minkowski distance with the specified norm \n",
        "                          between all pairs of elements in x \n",
        "  \"\"\"\n",
        "  dist = np.array([[minkowski(a1,a2,distance) for a2 in x] for a1 in x])\n",
        "  np.fill_diagonal(dist,float('inf'))\n",
        "  return dist\n",
        "\n",
        "def random_sampler(x,y,randomsize,x1,x2):\n",
        "  \"\"\"\n",
        "  This function does random undersampling of vectors x,y and reduces them to \n",
        "  size random size\n",
        "  :param x: numpy.ndarray: the feature vector to be subsampled\n",
        "  :param y: numpy.ndarray: the label vector to be subsampled\n",
        "  :return: <class 'tuple'>: A tuple containing the two undersampled vectors\n",
        "  \"\"\"\n",
        "  p = np.random.permutation(len(y))\n",
        "  new_x = x[p]\n",
        "  new_y = y[p]\n",
        "  return new_x[:randomsize],new_y[:randomsize]\n",
        "\n",
        "def generate_samples(x,y,neighbors,N):\n",
        "  \"\"\"\n",
        "  This function generate N samples which are convex combinations of \n",
        "  the features of x and the labels of y\n",
        "  :param x: numpy.ndarray:\n",
        "  :param y: numpy.ndarray:\n",
        "  :return: <class 'tuple'>:\n",
        "  \"\"\"\n",
        "  new_samples_x = []\n",
        "  new_samples_y = []\n",
        "  for i in range(N):\n",
        "    random_sample_i = random.randint(0,y.shape[0]-1)\n",
        "    x_i = x[random_sample_i]\n",
        "    random_sample_j = random.randint(0,neighbors.shape[1]-1)\n",
        "    neigh_i = neighbors[random_sample_i,random_sample_j]\n",
        "    x_j = x[neigh_i]\n",
        "    lambda_ = random.uniform(0,1)\n",
        "    y_i = y[random_sample_i]\n",
        "    y_j = y[neigh_i]\n",
        "    new_x = x_i + lambda_*(x_j-x_i)\n",
        "    new_y = y_i + lambda_*(y_j-y_i)\n",
        "    new_samples_x.append(new_x)\n",
        "    new_samples_y.append(new_y)\n",
        "  return np.array(new_samples_x),np.array(new_samples_y)\n",
        "\n",
        "def smote_sf(x, y, undersample=0.5, oversample = 0.1, attribute_scorer=Fisher_Score, \n",
        "             attribute_number = 10, distance = float('inf'), kneighbors = 3,\n",
        "             undersampling = random_sampler, importance_class = 0.7):\n",
        "  \"\"\"\n",
        "  This function takes the complete input and produces a more balanced dataset based on the importance class\n",
        "  :param x: numpy.ndarray: the feature vector of the initial dataset\n",
        "  :param y: numpy.ndarray: the value vector of the initial dataset\n",
        "  :param undersample: float: the percentage of the dominant class that we want to keep\n",
        "  :param oversample: float: the percentage of the dataset that the small class will be at the end\n",
        "  :param attribute_scorer: function: a function which will be used to score the relevance of a feature\n",
        "  :param attribute_number: int: the number of attributes to keep according to their score\n",
        "  :param distance: float: the norm which should be used for the Minkowski distance\n",
        "  :param kneighbors: int: the number of samples which should be considered for each point \n",
        "  :param undersampling: function: the function to use for the undersampling of the majority class\n",
        "  :param importance_class: float: the lower bound for the underepresented class\n",
        "  :return: returns 2 new feature vectors and 2 new label vectors containing \n",
        "            the data for the importance class and the data for the non importance \n",
        "            class and their labels. \n",
        "  \"\"\"\n",
        "  x_import = x[y>=importance_class]\n",
        "  y_import = y[y>=importance_class]\n",
        "  x_nimport = x[y<importance_class]\n",
        "  y_nimport = y[y<importance_class]\n",
        "\n",
        "  feature_scores =  attribute_scorer(x_import,x_nimport)\n",
        "  #find the attribute_number highest coordinates of the feature_scores vector\n",
        "  indices = np.sort((-feature_scores).argsort()[:attribute_number])\n",
        "  x_import_filtered = x_import[:,indices]\n",
        "  #x_nimport = x_nimport[:,indices]\n",
        "  distances = calculate_distances(x_import_filtered,distance)\n",
        "  #find the k lowest indices\n",
        "  neighbors = np.array([ np.sort(d.argsort()[:(kneighbors)]) for d in distances])\n",
        "  #undersampling for the majority class\n",
        "  nimport_len = int(undersample*y_nimport.shape[0])\n",
        "  x_nimport,y_nimport = undersampling(x_nimport,y_nimport,nimport_len,x_import,y_import)\n",
        "  #Calculate the number of samples to be generated\n",
        "  N = int(oversample*(y_nimport.shape[0]) - y_import.shape[0])\n",
        "  #Generate N new samples\n",
        "  new_samples_x,new_samples_y = generate_samples(x_import, y_import, neighbors, N)\n",
        "  #merge the new samples of the minority class with its old samples\n",
        "  x_import = np.concatenate((x_import,new_samples_x))\n",
        "  y_import = np.concatenate((y_import,new_samples_y))\n",
        "\n",
        "  x_ret = np.concatenate((x_import, x_nimport))\n",
        "  y_ret = np.concatenate((y_import,y_nimport))\n",
        "  return x_ret, y_ret"
      ],
      "metadata": {
        "id": "KY_m2BEF-dsn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_boundary = stats.boxcox([0.7,1.],fitted_lambda)[0]\n",
        "print(importance_boundary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIt02CxxTf4T",
        "outputId": "d1933c4b-ed26-4309-8392-b0f8fa258f33"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.4286406555284001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try with the L1 norm\n",
        "x_train1,y_train1 = smote_sf(x_train,y_train,undersample=0.1,oversample=0.3, kneighbors=5, distance = 1.,undersampling = PSU_undersampling, importance_class = importance_boundary)\n",
        "p = np.random.permutation(len(y_train1))\n",
        "x_train1 = x_train1[p]\n",
        "y_train1 = y_train1[p]"
      ],
      "metadata": {
        "id": "2L_KQg4rjNA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try with the L2 norm\n",
        "x_train2,y_train2 = smote_sf(x_train,y_train,undersample=0.1,oversample=0.3, kneighbors=5, distance = 2.,undersampling = PSU_undersampling,attribute_scorer= Correlation_Score_Max,importance_class = importance_boundary)\n",
        "p = np.random.permutation(len(y_train2))\n",
        "x_train2 = x_train2[p]\n",
        "y_train2 = y_train2[p]"
      ],
      "metadata": {
        "id": "loFpTLWkobzv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train = smote_sf(x_train,y_train,undersample=0.1,oversample=0.3, kneighbors=5,undersampling = PSU_undersampling, importance_class = importance_boundary)"
      ],
      "metadata": {
        "id": "6066fXiS-4iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = np.random.permutation(len(y_train))\n",
        "x_train = x_train[p]\n",
        "y_train = y_train[p]"
      ],
      "metadata": {
        "id": "Doh_hZCM-EYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train2.shape,y_train2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgAhJisfW1o6",
        "outputId": "47a1c952-d182-48b1-ee5b-9d92f5bab94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14469, 318) (14469,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric"
      ],
      "metadata": {
        "id": "ZvEXLgieP1xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def penalized_MSE_helper(y_true, y_pred):\n",
        "    critical_indices = np.where(y_true >= 0.7)[0]\n",
        "    print(critical_indices)\n",
        "    print(y_true,y_pred)\n",
        "    if(critical_indices.shape[0]==0 | critical_indices.shape[0]==y_true.shape[0]):\n",
        "        return (1/2)*MSE(y_true, y_pred)\n",
        "    else:\n",
        "      critical_y = y_true[critical_indices]\n",
        "      common_y = np.delete(y_true, critical_indices)\n",
        "      critical_predictions = y_pred[critical_indices]\n",
        "      common_predictions = np.delete(y_pred, critical_indices)\n",
        "      return (1/2)*MSE(critical_y, critical_predictions)+ (1/2)*MSE(common_y, common_predictions)"
      ],
      "metadata": {
        "id": "7sv8B7apP44H"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def penalized_MSE(y_true, y_pred,fitted_lambda=-1.0008549422054305):\n",
        "  return penalized_MSE_helper(y_true,sci.special.inv_boxcox(y_pred, fitted_lambda))\n",
        "\n",
        "def penalized_MSE_train(y_true, y_pred,fitted_lambda=-1.0008549422054305):\n",
        "  return penalized_MSE_helper(sci.special.inv_boxcox(y_true, fitted_lambda),sci.special.inv_boxcox(y_pred, fitted_lambda))"
      ],
      "metadata": {
        "id": "2cUHHVH9QUrV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Qpc5tgP0WX2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBRegressor(subsample = 0.8999999999999999, n_estimators= 500,\n",
        "                     max_depth = 20, learning_rate = 0.01, colsample_bytree = 0.7999999999999999, colsample_bylevel = 0.6, obj=penalized_MSE )\n",
        "model.fit(x_train, y_train,eval_metric=penalized_MSE_train)\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJWM9WCZBJyi",
        "outputId": "4053e29e-51eb-49c0-d13e-401a637068ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:06:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = sci.special.inv_boxcox(predictions, fitted_lambda)"
      ],
      "metadata": {
        "id": "HDEbj2_dNrhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('the MSE for tuned model XGB Regressor is',MSE(y_test, predictions))\n",
        "print('the weighted-MSE for tuned model XGB Regressor is',penalized_MSE(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCtO6NkiB3Xt",
        "outputId": "ac7421b5-e14e-4bc1-9266-8ac8b2f1d9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the MSE for tuned model XGB Regressor is 0.0031429880988767694\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97]\n",
            "[0.72502145 0.79381635 0.72175077 ... 0.1444491  0.23114848 0.15589872] [3.1627264 3.2895598 3.4726837 ... 1.1765703 1.1863221 1.1790321]\n",
            "the weighted-MSE for tuned model XGB Regressor is 7.455629293165921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range_values = np.arange(0.05,1.05,0.1)\n",
        "mse_ranges = []\n",
        "print(range_values)\n",
        "for val in range_values:\n",
        "    labels_range = y_test[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    correspondent_predictions = predictions[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    mse_ranges.append(MSE(correspondent_predictions, labels_range))\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "intervals = ['0.0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4','0.4-0.5', '0.5-0.6', '0.6-0-7', '0.7-0.8', '0.8-0.9', '0.9-1.0']\n",
        "dict_mse = {'intervals': intervals, 'mse': mse_ranges}\n",
        "df_mse = pd.DataFrame.from_dict(dict_mse)\n",
        "sns.barplot(x = df_mse['intervals'], y = df_mse['mse'], color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "t2CZ38fgOmyj",
        "outputId": "08861529-0327-4c1b-934f-f86af266554d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 842.4x595.44 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = XGBRegressor(subsample = 0.8999999999999999, n_estimators= 500,\n",
        "                     max_depth = 20, learning_rate = 0.01, colsample_bytree = 0.7999999999999999, colsample_bylevel = 0.6, obj=penalized_MSE )\n",
        "model1.fit(x_train1, y_train1,eval_metric=penalized_MSE_train)\n",
        "predictions1 = model1.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uAp29oxlqD-",
        "outputId": "f1d51d59-b435-4e76-f1ec-d6941cfe7607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:14:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions1 = sci.special.inv_boxcox(predictions1, fitted_lambda)"
      ],
      "metadata": {
        "id": "TFunhx50luuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('the MSE for tuned model XGB Regressor is',MSE(y_test, predictions1))\n",
        "print('the weighted-MSE for tuned model XGB Regressor is',penalized_MSE(y_test, predictions1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sgmYgL5mCXL",
        "outputId": "c5a2b635-3b92-4c14-def6-6c65d928edb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the MSE for tuned model XGB Regressor is 0.0031564488783591724\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97]\n",
            "[0.72502145 0.79381635 0.72175077 ... 0.1444491  0.23114848 0.15589872] [3.4377396 3.44978   3.156199  ... 1.1782721 1.1941216 1.1713947]\n",
            "the weighted-MSE for tuned model XGB Regressor is 7.56034445913278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range_values = np.arange(0.05,1.05,0.1)\n",
        "mse_ranges = []\n",
        "print(range_values)\n",
        "for val in range_values:\n",
        "    labels_range = y_test[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    correspondent_predictions = predictions1[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    mse_ranges.append(MSE(correspondent_predictions, labels_range))\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "intervals = ['0.0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4','0.4-0.5', '0.5-0.6', '0.6-0-7', '0.7-0.8', '0.8-0.9', '0.9-1.0']\n",
        "dict_mse = {'intervals': intervals, 'mse': mse_ranges}\n",
        "df_mse = pd.DataFrame.from_dict(dict_mse)\n",
        "sns.barplot(x = df_mse['intervals'], y = df_mse['mse'], color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "lnI4B_JVmFLO",
        "outputId": "2ab5a11a-2418-44dd-f90d-ebeb15d5628c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 842.4x595.44 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = XGBRegressor(subsample = 0.8999999999999999, n_estimators= 500,\n",
        "                     max_depth = 20, learning_rate = 0.01, colsample_bytree = 0.7999999999999999, colsample_bylevel = 0.6, obj=penalized_MSE )\n",
        "model2.fit(x_train2, y_train2,eval_metric=penalized_MSE_train)\n",
        "predictions2 = model2.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASzh5aQNo61E",
        "outputId": "8a1872b0-1b7d-43ba-c590-491cee8c8ca3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11:53:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2 = sci.special.inv_boxcox(predictions2, fitted_lambda)"
      ],
      "metadata": {
        "id": "SW5Vi4fLpBYC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('the MSE for tuned model XGB Regressor is',MSE(y_test, predictions2))\n",
        "print('the weighted-MSE for tuned model XGB Regressor is',penalized_MSE(y_test, predictions2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LloUpS-SpFYF",
        "outputId": "39daa833-c443-4b7f-ff91-2ecca4ee0ccf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the MSE for tuned model XGB Regressor is 0.003138740537915041\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97]\n",
            "[0.72502145 0.79381635 0.72175077 ... 0.1444491  0.23114848 0.15589872] [3.013186  3.5712512 3.385554  ... 1.1804537 1.1922094 1.1745116]\n",
            "the weighted-MSE for tuned model XGB Regressor is 7.529257885524304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range_values = np.arange(0.05,1.05,0.1)\n",
        "mse_ranges = []\n",
        "print(range_values)\n",
        "for val in range_values:\n",
        "    labels_range = y_test[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    correspondent_predictions = predictions2[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    mse_ranges.append(MSE(correspondent_predictions, labels_range))\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "intervals = ['0.0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4','0.4-0.5', '0.5-0.6', '0.6-0-7', '0.7-0.8', '0.8-0.9', '0.9-1.0']\n",
        "dict_mse = {'intervals': intervals, 'mse': mse_ranges}\n",
        "df_mse = pd.DataFrame.from_dict(dict_mse)\n",
        "sns.barplot(x = df_mse['intervals'], y = df_mse['mse'], color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "iKN79b5dpLUY",
        "outputId": "4ee0c8ee-e2e4-492e-d4f7-227d7d32da21"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 842.4x595.44 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = { 'max_depth': [5, 10, 15, 20],\n",
        "           'learning_rate': [0.01, 0.1, 0.5],\n",
        "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
        "           'colsample_bytree': np.arange(0.5, 1.0, 0.1),\n",
        "           'colsample_bylevel': np.arange(0.5, 1.0, 0.1),\n",
        "           'n_estimators': [100,500,1000]\n",
        "            }\n",
        "\n",
        "score = make_scorer(penalized_MSE_train, greater_is_better=False)\n",
        "model = XGBRegressor(tree_method='gpu_hist',seed = 20)\n",
        "clf = RandomizedSearchCV(estimator = model,\n",
        "                         param_distributions = params,\n",
        "                         scoring = score,\n",
        "                         n_iter=10,\n",
        "                         verbose=10)\n",
        "clf.fit(x_train, y_train,eval_metric = penalized_MSE_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLKJunbtYxkS",
        "outputId": "9d11db40-233f-4abd-9ffd-a26b9c09171a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV 1/5; 1/10] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.7\n",
            "[23:03:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    8   11   17   19   20   23   33   34   36   39   43   47   52\n",
            "   55   65   67   70   74   76   78   80   85   87   89   97   98  102\n",
            "  108  109  111  114  117  119  121  123  124  128  130  135  138  140\n",
            "  149  162  169  171  174  175  177  180  188  189  190  192  195  202\n",
            "  212  224  227  234  235  237  238  242  243  245  247  248  251  252\n",
            "  257  262  264  267  271  274  275  277  279  280  287  292  297  304\n",
            "  306  307  314  319  327  332  334  336  340  345  346  347  350  352\n",
            "  354  358  368  375  379  381  385  388  390  391  394  395  402  404\n",
            "  412  418  422  423  424  428  430  438  443  447  450  459  468  477\n",
            "  479  484  485  486  488  495  499  511  522  529  532  534  536  541\n",
            "  543  560  562  563  568  570  577  586  589  590  594  599  603  613\n",
            "  615  617  624  625  627  634  635  639  645  650  667  676  679  689\n",
            "  690  691  695  696  700  703  707  715  718  720  726  728  730  733\n",
            "  737  749  755  759  763  764  765  773  774  779  786  798  802  808\n",
            "  822  824  829  832  836  852  856  862  865  867  870  872  873  874\n",
            "  884  888  893  894  899  900  917  920  922  923  926  940  941  944\n",
            "  959  965  968  974  976  978  979  981  983  989  990  991  995  996\n",
            " 1001 1009 1012 1015 1025 1028 1038 1044 1049 1070 1071 1079 1080 1081\n",
            " 1083 1089 1090 1096 1098 1104 1105 1111 1113 1120 1121 1123 1125 1127\n",
            " 1131 1135 1141 1145 1151 1154 1156 1157 1158 1163 1164 1166 1179 1183\n",
            " 1192 1195 1202 1205 1206 1209 1210 1224 1226 1239 1240 1245 1256 1259\n",
            " 1260 1262 1263 1270 1273 1280 1288 1289 1292 1295 1296 1300 1304 1309\n",
            " 1322 1330 1332 1338 1340 1343 1346 1358 1363 1377 1378 1380 1383 1384\n",
            " 1391 1393 1401 1402 1403 1410 1417 1418 1422 1438 1444 1445 1450 1453\n",
            " 1455 1456 1464 1466 1468 1469 1475 1482 1489 1491 1494 1499 1505 1513\n",
            " 1528 1532 1535 1536 1537 1538 1539 1545 1551 1554 1555 1557 1559 1561\n",
            " 1562 1565 1566 1573 1579 1588 1597 1599 1602 1607 1609 1612 1614 1615\n",
            " 1618 1622 1625 1630 1631 1643 1645 1649 1650 1656 1675 1676 1679 1684\n",
            " 1685 1691 1697 1701 1705 1706 1707 1709 1716 1726 1727 1728 1740 1742\n",
            " 1748 1751 1753 1763 1768 1769 1770 1786 1794 1798 1799 1801 1804 1812\n",
            " 1814 1821 1822 1825 1835 1841 1842 1846 1848 1856 1857 1874 1875 1879\n",
            " 1880 1892 1907 1917 1927 1930 1940 1942 1949 1952 1957 1966 1971 1974\n",
            " 1975 1976 1979 1981 1984 1987 1989 1992 1993 1995 2002 2003 2007 2010\n",
            " 2015 2027 2028 2029 2031 2035 2037 2049 2054 2056 2060 2061 2066 2070\n",
            " 2071 2075 2076 2082 2085 2087 2094 2098 2110 2111 2112 2113 2122 2123\n",
            " 2141 2142 2145 2157 2162 2166 2167 2172 2177 2180 2181 2183 2186 2195\n",
            " 2202 2209 2213 2215 2219 2220 2222 2224 2232 2233 2240 2244 2246 2248\n",
            " 2253 2259 2266 2276 2277 2280 2282 2284 2291 2298 2309 2311 2313 2322\n",
            " 2338 2339 2340 2341 2346 2347 2348 2350 2361 2363 2364 2365 2366 2369\n",
            " 2374 2375 2380 2382 2385 2386 2396 2406 2410 2413 2416 2420 2422 2427\n",
            " 2436 2438 2439 2440 2441 2444 2445 2448 2449 2453 2456 2459 2461 2463\n",
            " 2464 2469 2472 2474 2483 2494 2498 2505 2507 2509 2514 2517 2522 2524\n",
            " 2526 2531 2538 2547 2550 2554 2557 2561 2566 2571 2574 2577 2581 2585\n",
            " 2590 2594 2600 2603 2606 2612 2618 2620 2622 2625 2633 2642 2647 2654\n",
            " 2655 2656 2661 2665 2669 2671 2672 2677 2684 2694 2700 2701 2704 2706\n",
            " 2709 2712 2713 2714 2715 2725 2727 2730 2735 2738 2742 2743 2748 2756\n",
            " 2760 2763 2767 2772 2774 2776 2779 2781 2785 2786 2790 2792 2805 2806\n",
            " 2807 2810 2820 2827 2832 2841 2847 2852 2857 2862 2865 2867 2871 2873\n",
            " 2878 2881 2884 2887 2889]\n",
            "[CV 1/5; 1/10] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.7;, score=-0.002 total time= 2.6min\n",
            "[CV 2/5; 1/10] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.7\n",
            "[23:06:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   3    5    7   12   14   20   22   25   27   31   32   33   43   47\n",
            "   51   62   64   69   70   71   74   76   88   89  109  111  113  115\n",
            "  125  133  137  141  143  145  148  156  159  174  175  176  180  190\n",
            "  191  195  199  200  203  205  207  209  210  212  213  215  220  227\n",
            "  231  238  252  258  262  268  269  272  310  311  314  315  332  334\n",
            "  356  361  362  363  364  367  368  369  371  373  377  380  384  385\n",
            "  390  399  403  407  409  410  417  429  431  435  444  449  464  465\n",
            "  466  467  470  474  475  480  489  490  492  493  498  499  501  505\n",
            "  509  512  513  517  518  521  524  529  533  534  537  539  541  545\n",
            "  549  550  558  560  564  573  574  577  580  584  585  586  587  594\n",
            "  598  605  606  612  624  627  628  630  642  647  649  651  663  665\n",
            "  679  680  691  696  701  710  711  716  727  731  733  736  744  750\n",
            "  751  759  760  763  765  771  773  776  780  789  794  806  809  812\n",
            "  814  820  821  833  838  844  855  859  866  868  884  890  894  902\n",
            "  905  907  909  916  917  921  922  931  934  937  958  968  969  973\n",
            "  979  981  990 1004 1010 1014 1015 1018 1033 1036 1037 1038 1040 1042\n",
            " 1043 1049 1068 1069 1076 1081 1084 1088 1090 1092 1094 1097 1100 1101\n",
            " 1105 1107 1116 1118 1123 1124 1128 1133 1141 1151 1152 1153 1161 1162\n",
            " 1164 1178 1179 1181 1189 1193 1197 1202 1209 1214 1221 1237 1241 1244\n",
            " 1245 1250 1253 1254 1258 1261 1262 1264 1266 1267 1268 1269 1270 1272\n",
            " 1276 1283 1287 1292 1293 1295 1303 1304 1310 1312 1316 1319 1328 1336\n",
            " 1341 1343 1344 1346 1351 1356 1374 1375 1378 1379 1383 1389 1397 1398\n",
            " 1399 1401 1404 1408 1413 1420 1437 1439 1440 1441 1446 1447 1450 1451\n",
            " 1458 1461 1475 1479 1481 1487 1488 1493 1504 1505 1506 1511 1512 1529\n",
            " 1532 1533 1537 1538 1541 1549 1550 1553 1559 1560 1565 1570 1571 1572\n",
            " 1573 1586 1588 1601 1607 1610 1611 1613 1614 1620 1626 1627 1634 1641\n",
            " 1647 1653 1658 1665 1672 1681 1684 1686 1696 1697 1705 1708 1720 1721\n",
            " 1725 1727 1738 1739 1742 1743 1751 1757 1762 1764 1769 1770 1773 1775\n",
            " 1779 1783 1786 1787 1789 1800 1803 1807 1809 1812 1821 1829 1836 1837\n",
            " 1839 1844 1855 1857 1875 1877 1879 1887 1889 1894 1897 1900 1902 1903\n",
            " 1907 1908 1917 1921 1923 1937 1947 1948 1951 1953 1956 1957 1959 1961\n",
            " 1964 1967 1968 1970 1974 1975 1981 1983 1986 1987 1994 1998 2003 2007\n",
            " 2009 2011 2013 2015 2020 2029 2036 2037 2041 2043 2045 2046 2047 2057\n",
            " 2058 2064 2070 2082 2086 2088 2089 2090 2093 2095 2101 2104 2110 2111\n",
            " 2113 2114 2115 2118 2119 2127 2134 2139 2141 2146 2147 2149 2150 2157\n",
            " 2159 2161 2166 2167 2169 2178 2182 2188 2197 2201 2207 2215 2217 2219\n",
            " 2222 2223 2224 2225 2231 2232 2233 2241 2245 2257 2262 2272 2291 2292\n",
            " 2293 2294 2296 2306 2307 2308 2309 2314 2340 2346 2347 2348 2353 2359\n",
            " 2369 2373 2380 2381 2382 2386 2393 2396 2401 2402 2403 2409 2411 2414\n",
            " 2419 2424 2431 2432 2433 2436 2437 2445 2450 2451 2452 2458 2460 2462\n",
            " 2463 2466 2471 2476 2494 2496 2503 2507 2510 2528 2530 2534 2535 2536\n",
            " 2538 2540 2542 2553 2554 2558 2559 2564 2571 2572 2574 2575 2582 2592\n",
            " 2594 2605 2612 2620 2623 2637 2643 2654 2657 2668 2677 2678 2680 2683\n",
            " 2690 2691 2693 2696 2700 2702 2705 2707 2708 2713 2717 2724 2727 2733\n",
            " 2735 2737 2748 2752 2753 2755 2765 2772 2775 2776 2781 2797 2800 2805\n",
            " 2806 2812 2813 2814 2815 2822 2831 2832 2835 2839 2843 2851 2855 2856\n",
            " 2859 2871 2872 2873 2884 2885 2886 2890 2892]\n",
            "[CV 2/5; 1/10] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.7;, score=-0.002 total time= 2.6min\n",
            "[CV 3/5; 1/10] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.7\n",
            "[23:09:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   4   11   30   35   36   37   41   54   63   66   69   76   87   97\n",
            "   98  102  106  130  131  133  134  142  148  149  159  161  165  176\n",
            "  178  187  190  191  194  201  202  206  224  226  227  232  238  246\n",
            "  248  250  256  259  261  264  270  271  274  278  279  287  288  290\n",
            "  303  304  307  313  314  316  318  322  324  327  334  335  339  346\n",
            "  347  349  358  367  369  373  374  375  376  377  378  390  391  393\n",
            "  394  397  398  411  420  421  423  428  429  435  442  443  448  450\n",
            "  457  461  464  465  467  469  474  493  497  499  500  501  503  520\n",
            "  529  530  545  547  553  561  562  567  569  570  573  586  592  597\n",
            "  598  599  603  604  605  611  625  629  630  633  636  640  645  654\n",
            "  658  662  670  675  678  686  690  692  697  699  702  707  710  718\n",
            "  719  725  731  732  733  738  745  746  752  777  782  784  788  790\n",
            "  793  794  797  798  800  802  804  813  824  825  826  832  836  852\n",
            "  856  859  861  864  868  871  878  885  889  891  896  904  911  913\n",
            "  917  923  927  952  958  962  969  974  976  979  986  988  989  990\n",
            "  997  998  999 1001 1008 1009 1029 1034 1041 1048 1052 1056 1061 1069\n",
            " 1072 1073 1080 1082 1091 1092 1099 1101 1111 1115 1120 1123 1124 1130\n",
            " 1134 1137 1144 1150 1152 1156 1168 1171 1173 1179 1183 1188 1196 1200\n",
            " 1202 1203 1205 1212 1214 1215 1222 1255 1256 1257 1262 1273 1279 1281\n",
            " 1287 1291 1306 1307 1310 1314 1315 1320 1324 1326 1329 1330 1332 1336\n",
            " 1346 1349 1351 1352 1353 1354 1365 1394 1397 1398 1400 1405 1407 1411\n",
            " 1423 1432 1434 1442 1445 1448 1449 1467 1469 1472 1490 1494 1495 1510\n",
            " 1516 1519 1521 1522 1526 1533 1547 1548 1551 1553 1574 1581 1583 1585\n",
            " 1589 1590 1598 1601 1611 1613 1614 1619 1622 1623 1637 1642 1647 1649\n",
            " 1650 1660 1667 1671 1673 1677 1682 1684 1695 1696 1697 1705 1723 1725\n",
            " 1727 1730 1732 1734 1742 1749 1772 1781 1782 1786 1795 1798 1802 1804\n",
            " 1805 1806 1812 1813 1814 1819 1820 1821 1831 1842 1844 1847 1849 1859\n",
            " 1860 1866 1869 1873 1878 1880 1886 1892 1896 1898 1900 1910 1911 1912\n",
            " 1919 1920 1922 1926 1931 1934 1941 1943 1946 1947 1951 1952 1957 1971\n",
            " 1972 1974 1979 1982 1983 1986 1989 1995 2000 2004 2010 2013 2014 2015\n",
            " 2016 2020 2021 2022 2038 2041 2042 2044 2045 2047 2056 2057 2059 2071\n",
            " 2074 2088 2091 2096 2107 2108 2110 2111 2113 2114 2120 2121 2134 2136\n",
            " 2140 2141 2147 2148 2151 2158 2163 2165 2166 2169 2172 2173 2178 2185\n",
            " 2188 2189 2203 2208 2209 2213 2218 2226 2234 2235 2251 2254 2263 2264\n",
            " 2266 2269 2271 2277 2278 2280 2281 2287 2288 2293 2294 2296 2302 2305\n",
            " 2306 2308 2310 2312 2315 2316 2318 2319 2335 2353 2357 2363 2368 2369\n",
            " 2370 2372 2375 2378 2379 2380 2382 2384 2405 2407 2414 2417 2429 2434\n",
            " 2435 2445 2451 2452 2454 2455 2459 2460 2467 2468 2473 2475 2479 2485\n",
            " 2487 2488 2490 2501 2509 2524 2530 2533 2535 2537 2538 2540 2541 2542\n",
            " 2552 2556 2557 2562 2564 2565 2566 2578 2581 2582 2587 2588 2589 2595\n",
            " 2599 2604 2607 2610 2612 2614 2616 2621 2626 2627 2630 2631 2632 2633\n",
            " 2644 2646 2648 2651 2652 2653 2654 2657 2660 2664 2671 2678 2686 2692\n",
            " 2696 2697 2698 2703 2704 2706 2707 2709 2710 2711 2716 2725 2729 2731\n",
            " 2734 2735 2739 2747 2755 2757 2758 2767 2771 2775 2777 2781 2791 2796\n",
            " 2802 2805 2806 2808 2809 2811 2814 2816 2818 2824 2827 2829 2833 2835\n",
            " 2837 2846 2850 2855 2858 2861 2865 2871 2874 2875 2877 2878 2879 2883\n",
            " 2886 2890 2891]\n",
            "[CV 3/5; 1/10] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.7;, score=-0.002 total time= 2.7min\n",
            "[CV 4/5; 1/10] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.7\n",
            "[23:11:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    4   14   16   23   25   26   29   30   39   40   43   47   62\n",
            "   64   67   70   75   76   78   83   84   90   97   98  102  107  108\n",
            "  113  121  123  126  127  128  132  137  138  142  146  154  158  159\n",
            "  168  188  191  192  198  201  204  209  211  215  219  229  234  238\n",
            "  239  240  242  243  245  246  254  255  257  258  259  264  272  286\n",
            "  287  296  297  302  303  315  316  328  329  334  338  345  347  349\n",
            "  354  359  365  367  373  379  385  386  397  399  411  415  421  423\n",
            "  428  431  439  440  458  460  463  464  469  474  475  479  485  487\n",
            "  515  527  533  535  550  553  554  555  556  557  560  561  568  569\n",
            "  571  573  575  582  586  595  597  601  603  608  618  624  628  629\n",
            "  630  631  640  643  649  652  653  662  668  671  678  679  686  688\n",
            "  690  691  695  698  699  702  704  706  709  710  720  736  739  747\n",
            "  753  762  766  778  789  790  792  799  802  804  805  813  829  830\n",
            "  835  850  856  864  866  872  876  902  906  910  914  920  923  929\n",
            "  934  938  943  944  945  946  950  957  959  960  961  965  971  978\n",
            "  984  985  995  996  998  999 1000 1002 1005 1008 1012 1013 1014 1020\n",
            " 1036 1037 1049 1050 1059 1061 1062 1065 1066 1067 1070 1072 1074 1076\n",
            " 1082 1087 1090 1091 1093 1096 1101 1102 1104 1105 1112 1115 1118 1128\n",
            " 1134 1136 1141 1142 1143 1145 1150 1155 1163 1166 1181 1188 1189 1192\n",
            " 1193 1194 1198 1199 1200 1201 1202 1208 1209 1217 1222 1223 1225 1226\n",
            " 1229 1231 1232 1234 1238 1245 1247 1248 1249 1260 1261 1265 1266 1267\n",
            " 1269 1275 1276 1277 1289 1292 1302 1305 1310 1313 1314 1315 1317 1319\n",
            " 1321 1323 1324 1325 1328 1335 1344 1347 1349 1357 1361 1365 1369 1373\n",
            " 1379 1388 1391 1395 1397 1401 1407 1419 1421 1424 1426 1433 1438 1439\n",
            " 1441 1445 1461 1463 1464 1478 1482 1492 1493 1498 1499 1501 1503 1505\n",
            " 1511 1514 1516 1517 1519 1521 1524 1528 1529 1533 1534 1538 1539 1557\n",
            " 1558 1559 1579 1583 1587 1590 1602 1603 1613 1617 1619 1622 1626 1631\n",
            " 1641 1651 1654 1655 1657 1663 1668 1670 1688 1695 1706 1711 1712 1714\n",
            " 1719 1727 1728 1732 1734 1735 1736 1740 1746 1748 1761 1762 1767 1768\n",
            " 1778 1781 1783 1785 1788 1791 1795 1796 1802 1805 1810 1811 1813 1817\n",
            " 1818 1819 1822 1823 1839 1843 1862 1865 1873 1874 1875 1876 1877 1882\n",
            " 1887 1894 1896 1902 1905 1914 1915 1917 1925 1929 1931 1938 1939 1944\n",
            " 1952 1953 1954 1960 1965 1979 1980 1984 1986 1991 1993 1996 2001 2010\n",
            " 2011 2019 2024 2025 2032 2033 2036 2038 2040 2041 2042 2044 2047 2048\n",
            " 2051 2054 2056 2059 2069 2071 2078 2079 2080 2085 2087 2094 2097 2099\n",
            " 2104 2110 2115 2120 2121 2122 2129 2130 2135 2141 2143 2145 2148 2150\n",
            " 2157 2158 2160 2162 2166 2169 2175 2184 2195 2199 2202 2205 2213 2215\n",
            " 2217 2219 2220 2223 2224 2225 2228 2230 2231 2234 2235 2237 2248 2249\n",
            " 2253 2255 2257 2258 2259 2262 2277 2278 2282 2283 2291 2292 2297 2310\n",
            " 2314 2317 2320 2325 2326 2332 2337 2338 2340 2341 2343 2345 2349 2353\n",
            " 2354 2358 2360 2362 2376 2383 2384 2387 2390 2391 2396 2399 2400 2404\n",
            " 2408 2413 2415 2416 2417 2418 2421 2422 2427 2429 2432 2433 2450 2451\n",
            " 2454 2457 2458 2460 2461 2465 2467 2470 2471 2475 2480 2487 2494 2498\n",
            " 2502 2507 2523 2524 2531 2533 2536 2538 2543 2545 2547 2549 2551 2553\n",
            " 2554 2557 2561 2563 2567 2570 2571 2572 2579 2582 2583 2585 2586 2588\n",
            " 2594 2595 2609 2613 2615 2617 2620 2623 2624 2625 2632 2633 2640 2647\n",
            " 2649 2650 2655 2657 2662 2664 2668 2669 2671 2689 2699 2701 2704 2706\n",
            " 2707 2710 2717 2720 2723 2726 2733 2735 2736 2747 2754 2755 2757 2763\n",
            " 2771 2779 2786 2790 2791 2792 2796 2800 2802 2805 2809 2832 2840 2845\n",
            " 2846 2850 2855 2860 2861 2863 2869 2870 2876 2877 2879 2883 2887 2889]\n",
            "[CV 4/5; 1/10] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.7;, score=-0.002 total time= 2.6min\n",
            "[CV 5/5; 1/10] START colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.7\n",
            "[23:14:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   5   11   14   25   27   37   41   42   51   52   55   56   59   60\n",
            "   76   81   83   90   96  100  108  109  114  116  119  124  128  135\n",
            "  137  142  145  147  150  157  164  167  170  178  185  190  192  194\n",
            "  198  202  211  214  222  223  237  238  243  246  252  255  258  260\n",
            "  261  268  270  271  276  283  286  288  294  302  318  322  326  331\n",
            "  335  336  348  350  351  353  354  370  375  380  382  383  390  393\n",
            "  403  404  406  407  409  421  424  433  438  440  442  455  463  473\n",
            "  476  478  479  481  482  487  489  497  499  502  504  509  510  516\n",
            "  517  521  529  533  536  540  541  546  552  556  557  560  566  572\n",
            "  575  578  579  581  595  602  603  612  614  617  618  622  626  629\n",
            "  639  642  644  657  660  666  668  673  675  676  688  689  690  692\n",
            "  695  696  697  703  705  715  717  718  719  728  730  733  740  747\n",
            "  755  759  761  764  765  773  776  779  782  784  786  794  797  799\n",
            "  800  810  811  816  822  830  831  833  836  855  858  864  868  879\n",
            "  880  896  898  904  910  917  925  928  930  932  940  942  948  950\n",
            "  963  966  968  970  971  972  974  984  987  989  992  993  997 1002\n",
            " 1006 1010 1014 1023 1029 1032 1035 1041 1046 1050 1051 1057 1062 1063\n",
            " 1065 1067 1068 1069 1072 1076 1077 1088 1089 1093 1101 1107 1114 1118\n",
            " 1121 1128 1130 1131 1138 1139 1142 1144 1150 1151 1155 1161 1167 1175\n",
            " 1177 1181 1187 1194 1196 1199 1201 1202 1205 1222 1223 1225 1230 1231\n",
            " 1234 1246 1250 1252 1253 1255 1263 1270 1272 1273 1277 1279 1285 1289\n",
            " 1291 1297 1298 1303 1304 1306 1307 1311 1321 1328 1331 1336 1337 1341\n",
            " 1347 1355 1358 1364 1370 1372 1374 1376 1379 1380 1381 1383 1392 1394\n",
            " 1399 1404 1409 1412 1419 1420 1422 1431 1433 1437 1438 1441 1447 1448\n",
            " 1449 1454 1458 1459 1463 1465 1467 1468 1471 1486 1491 1497 1499 1501\n",
            " 1508 1509 1510 1514 1522 1524 1527 1533 1537 1542 1551 1554 1561 1563\n",
            " 1565 1567 1569 1571 1572 1574 1577 1581 1583 1584 1588 1595 1596 1598\n",
            " 1600 1608 1612 1617 1621 1624 1630 1635 1636 1637 1640 1643 1653 1656\n",
            " 1657 1661 1668 1672 1673 1676 1679 1681 1686 1687 1688 1696 1699 1701\n",
            " 1709 1710 1720 1722 1725 1726 1731 1733 1737 1738 1741 1746 1747 1749\n",
            " 1751 1754 1756 1763 1765 1772 1782 1783 1787 1788 1792 1796 1802 1809\n",
            " 1817 1819 1822 1834 1835 1848 1851 1860 1868 1876 1880 1893 1894 1900\n",
            " 1905 1929 1934 1938 1947 1948 1953 1956 1967 1969 1976 1978 1988 1989\n",
            " 1994 1995 1996 1999 2000 2005 2009 2011 2013 2020 2026 2027 2032 2045\n",
            " 2062 2063 2072 2074 2075 2081 2088 2089 2090 2099 2101 2110 2111 2117\n",
            " 2120 2129 2131 2132 2133 2138 2142 2143 2144 2147 2151 2153 2154 2166\n",
            " 2175 2178 2185 2188 2198 2202 2204 2206 2207 2209 2224 2230 2231 2237\n",
            " 2248 2249 2251 2258 2261 2262 2264 2272 2276 2280 2281 2282 2283 2285\n",
            " 2288 2295 2297 2300 2308 2314 2315 2316 2317 2320 2321 2327 2328 2332\n",
            " 2336 2337 2351 2359 2368 2370 2373 2383 2392 2394 2404 2405 2408 2410\n",
            " 2425 2435 2439 2440 2453 2458 2467 2470 2473 2478 2481 2483 2487 2489\n",
            " 2490 2499 2500 2505 2512 2513 2517 2522 2523 2524 2527 2528 2529 2533\n",
            " 2538 2541 2549 2551 2578 2589 2596 2601 2610 2627 2630 2633 2643 2645\n",
            " 2649 2653 2655 2672 2673 2679 2690 2692 2697 2698 2699 2705 2714 2718\n",
            " 2727 2732 2744 2745 2746 2747 2751 2757 2758 2761 2763 2767 2781 2782\n",
            " 2786 2789 2795 2801 2806 2810 2812 2814 2816 2818 2824 2826 2832 2833\n",
            " 2838 2841 2843 2844 2847 2850 2851 2853 2868 2871 2876 2878 2880 2881\n",
            " 2887 2888 2889 2892]\n",
            "[CV 5/5; 1/10] END colsample_bylevel=0.7, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.7;, score=-0.002 total time= 2.7min\n",
            "[CV 1/5; 2/10] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.5\n",
            "[23:17:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    8   11   17   19   20   23   33   34   36   39   43   47   52\n",
            "   55   65   67   70   74   76   78   80   85   87   89   97   98  102\n",
            "  108  109  111  114  117  119  121  123  124  128  130  135  138  140\n",
            "  149  162  169  171  174  175  177  180  188  189  190  192  195  202\n",
            "  212  224  227  234  235  237  238  242  243  245  247  248  251  252\n",
            "  257  262  264  267  271  274  275  277  279  280  287  292  297  304\n",
            "  306  307  314  319  327  332  334  336  340  345  346  347  350  352\n",
            "  354  358  368  375  379  381  385  388  390  391  394  395  402  404\n",
            "  412  418  422  423  424  428  430  438  443  447  450  459  468  477\n",
            "  479  484  485  486  488  495  499  511  522  529  532  534  536  541\n",
            "  543  560  562  563  568  570  577  586  589  590  594  599  603  613\n",
            "  615  617  624  625  627  634  635  639  645  650  667  676  679  689\n",
            "  690  691  695  696  700  703  707  715  718  720  726  728  730  733\n",
            "  737  749  755  759  763  764  765  773  774  779  786  798  802  808\n",
            "  822  824  829  832  836  852  856  862  865  867  870  872  873  874\n",
            "  884  888  893  894  899  900  917  920  922  923  926  940  941  944\n",
            "  959  965  968  974  976  978  979  981  983  989  990  991  995  996\n",
            " 1001 1009 1012 1015 1025 1028 1038 1044 1049 1070 1071 1079 1080 1081\n",
            " 1083 1089 1090 1096 1098 1104 1105 1111 1113 1120 1121 1123 1125 1127\n",
            " 1131 1135 1141 1145 1151 1154 1156 1157 1158 1163 1164 1166 1179 1183\n",
            " 1192 1195 1202 1205 1206 1209 1210 1224 1226 1239 1240 1245 1256 1259\n",
            " 1260 1262 1263 1270 1273 1280 1288 1289 1292 1295 1296 1300 1304 1309\n",
            " 1322 1330 1332 1338 1340 1343 1346 1358 1363 1377 1378 1380 1383 1384\n",
            " 1391 1393 1401 1402 1403 1410 1417 1418 1422 1438 1444 1445 1450 1453\n",
            " 1455 1456 1464 1466 1468 1469 1475 1482 1489 1491 1494 1499 1505 1513\n",
            " 1528 1532 1535 1536 1537 1538 1539 1545 1551 1554 1555 1557 1559 1561\n",
            " 1562 1565 1566 1573 1579 1588 1597 1599 1602 1607 1609 1612 1614 1615\n",
            " 1618 1622 1625 1630 1631 1643 1645 1649 1650 1656 1675 1676 1679 1684\n",
            " 1685 1691 1697 1701 1705 1706 1707 1709 1716 1726 1727 1728 1740 1742\n",
            " 1748 1751 1753 1763 1768 1769 1770 1786 1794 1798 1799 1801 1804 1812\n",
            " 1814 1821 1822 1825 1835 1841 1842 1846 1848 1856 1857 1874 1875 1879\n",
            " 1880 1892 1907 1917 1927 1930 1940 1942 1949 1952 1957 1966 1971 1974\n",
            " 1975 1976 1979 1981 1984 1987 1989 1992 1993 1995 2002 2003 2007 2010\n",
            " 2015 2027 2028 2029 2031 2035 2037 2049 2054 2056 2060 2061 2066 2070\n",
            " 2071 2075 2076 2082 2085 2087 2094 2098 2110 2111 2112 2113 2122 2123\n",
            " 2141 2142 2145 2157 2162 2166 2167 2172 2177 2180 2181 2183 2186 2195\n",
            " 2202 2209 2213 2215 2219 2220 2222 2224 2232 2233 2240 2244 2246 2248\n",
            " 2253 2259 2266 2276 2277 2280 2282 2284 2291 2298 2309 2311 2313 2322\n",
            " 2338 2339 2340 2341 2346 2347 2348 2350 2361 2363 2364 2365 2366 2369\n",
            " 2374 2375 2380 2382 2385 2386 2396 2406 2410 2413 2416 2420 2422 2427\n",
            " 2436 2438 2439 2440 2441 2444 2445 2448 2449 2453 2456 2459 2461 2463\n",
            " 2464 2469 2472 2474 2483 2494 2498 2505 2507 2509 2514 2517 2522 2524\n",
            " 2526 2531 2538 2547 2550 2554 2557 2561 2566 2571 2574 2577 2581 2585\n",
            " 2590 2594 2600 2603 2606 2612 2618 2620 2622 2625 2633 2642 2647 2654\n",
            " 2655 2656 2661 2665 2669 2671 2672 2677 2684 2694 2700 2701 2704 2706\n",
            " 2709 2712 2713 2714 2715 2725 2727 2730 2735 2738 2742 2743 2748 2756\n",
            " 2760 2763 2767 2772 2774 2776 2779 2781 2785 2786 2790 2792 2805 2806\n",
            " 2807 2810 2820 2827 2832 2841 2847 2852 2857 2862 2865 2867 2871 2873\n",
            " 2878 2881 2884 2887 2889]\n",
            "[CV 1/5; 2/10] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.5;, score=-0.003 total time= 2.4min\n",
            "[CV 2/5; 2/10] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.5\n",
            "[23:19:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   3    5    7   12   14   20   22   25   27   31   32   33   43   47\n",
            "   51   62   64   69   70   71   74   76   88   89  109  111  113  115\n",
            "  125  133  137  141  143  145  148  156  159  174  175  176  180  190\n",
            "  191  195  199  200  203  205  207  209  210  212  213  215  220  227\n",
            "  231  238  252  258  262  268  269  272  310  311  314  315  332  334\n",
            "  356  361  362  363  364  367  368  369  371  373  377  380  384  385\n",
            "  390  399  403  407  409  410  417  429  431  435  444  449  464  465\n",
            "  466  467  470  474  475  480  489  490  492  493  498  499  501  505\n",
            "  509  512  513  517  518  521  524  529  533  534  537  539  541  545\n",
            "  549  550  558  560  564  573  574  577  580  584  585  586  587  594\n",
            "  598  605  606  612  624  627  628  630  642  647  649  651  663  665\n",
            "  679  680  691  696  701  710  711  716  727  731  733  736  744  750\n",
            "  751  759  760  763  765  771  773  776  780  789  794  806  809  812\n",
            "  814  820  821  833  838  844  855  859  866  868  884  890  894  902\n",
            "  905  907  909  916  917  921  922  931  934  937  958  968  969  973\n",
            "  979  981  990 1004 1010 1014 1015 1018 1033 1036 1037 1038 1040 1042\n",
            " 1043 1049 1068 1069 1076 1081 1084 1088 1090 1092 1094 1097 1100 1101\n",
            " 1105 1107 1116 1118 1123 1124 1128 1133 1141 1151 1152 1153 1161 1162\n",
            " 1164 1178 1179 1181 1189 1193 1197 1202 1209 1214 1221 1237 1241 1244\n",
            " 1245 1250 1253 1254 1258 1261 1262 1264 1266 1267 1268 1269 1270 1272\n",
            " 1276 1283 1287 1292 1293 1295 1303 1304 1310 1312 1316 1319 1328 1336\n",
            " 1341 1343 1344 1346 1351 1356 1374 1375 1378 1379 1383 1389 1397 1398\n",
            " 1399 1401 1404 1408 1413 1420 1437 1439 1440 1441 1446 1447 1450 1451\n",
            " 1458 1461 1475 1479 1481 1487 1488 1493 1504 1505 1506 1511 1512 1529\n",
            " 1532 1533 1537 1538 1541 1549 1550 1553 1559 1560 1565 1570 1571 1572\n",
            " 1573 1586 1588 1601 1607 1610 1611 1613 1614 1620 1626 1627 1634 1641\n",
            " 1647 1653 1658 1665 1672 1681 1684 1686 1696 1697 1705 1708 1720 1721\n",
            " 1725 1727 1738 1739 1742 1743 1751 1757 1762 1764 1769 1770 1773 1775\n",
            " 1779 1783 1786 1787 1789 1800 1803 1807 1809 1812 1821 1829 1836 1837\n",
            " 1839 1844 1855 1857 1875 1877 1879 1887 1889 1894 1897 1900 1902 1903\n",
            " 1907 1908 1917 1921 1923 1937 1947 1948 1951 1953 1956 1957 1959 1961\n",
            " 1964 1967 1968 1970 1974 1975 1981 1983 1986 1987 1994 1998 2003 2007\n",
            " 2009 2011 2013 2015 2020 2029 2036 2037 2041 2043 2045 2046 2047 2057\n",
            " 2058 2064 2070 2082 2086 2088 2089 2090 2093 2095 2101 2104 2110 2111\n",
            " 2113 2114 2115 2118 2119 2127 2134 2139 2141 2146 2147 2149 2150 2157\n",
            " 2159 2161 2166 2167 2169 2178 2182 2188 2197 2201 2207 2215 2217 2219\n",
            " 2222 2223 2224 2225 2231 2232 2233 2241 2245 2257 2262 2272 2291 2292\n",
            " 2293 2294 2296 2306 2307 2308 2309 2314 2340 2346 2347 2348 2353 2359\n",
            " 2369 2373 2380 2381 2382 2386 2393 2396 2401 2402 2403 2409 2411 2414\n",
            " 2419 2424 2431 2432 2433 2436 2437 2445 2450 2451 2452 2458 2460 2462\n",
            " 2463 2466 2471 2476 2494 2496 2503 2507 2510 2528 2530 2534 2535 2536\n",
            " 2538 2540 2542 2553 2554 2558 2559 2564 2571 2572 2574 2575 2582 2592\n",
            " 2594 2605 2612 2620 2623 2637 2643 2654 2657 2668 2677 2678 2680 2683\n",
            " 2690 2691 2693 2696 2700 2702 2705 2707 2708 2713 2717 2724 2727 2733\n",
            " 2735 2737 2748 2752 2753 2755 2765 2772 2775 2776 2781 2797 2800 2805\n",
            " 2806 2812 2813 2814 2815 2822 2831 2832 2835 2839 2843 2851 2855 2856\n",
            " 2859 2871 2872 2873 2884 2885 2886 2890 2892]\n",
            "[CV 2/5; 2/10] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.5;, score=-0.002 total time= 2.4min\n",
            "[CV 3/5; 2/10] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.5\n",
            "[23:21:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   4   11   30   35   36   37   41   54   63   66   69   76   87   97\n",
            "   98  102  106  130  131  133  134  142  148  149  159  161  165  176\n",
            "  178  187  190  191  194  201  202  206  224  226  227  232  238  246\n",
            "  248  250  256  259  261  264  270  271  274  278  279  287  288  290\n",
            "  303  304  307  313  314  316  318  322  324  327  334  335  339  346\n",
            "  347  349  358  367  369  373  374  375  376  377  378  390  391  393\n",
            "  394  397  398  411  420  421  423  428  429  435  442  443  448  450\n",
            "  457  461  464  465  467  469  474  493  497  499  500  501  503  520\n",
            "  529  530  545  547  553  561  562  567  569  570  573  586  592  597\n",
            "  598  599  603  604  605  611  625  629  630  633  636  640  645  654\n",
            "  658  662  670  675  678  686  690  692  697  699  702  707  710  718\n",
            "  719  725  731  732  733  738  745  746  752  777  782  784  788  790\n",
            "  793  794  797  798  800  802  804  813  824  825  826  832  836  852\n",
            "  856  859  861  864  868  871  878  885  889  891  896  904  911  913\n",
            "  917  923  927  952  958  962  969  974  976  979  986  988  989  990\n",
            "  997  998  999 1001 1008 1009 1029 1034 1041 1048 1052 1056 1061 1069\n",
            " 1072 1073 1080 1082 1091 1092 1099 1101 1111 1115 1120 1123 1124 1130\n",
            " 1134 1137 1144 1150 1152 1156 1168 1171 1173 1179 1183 1188 1196 1200\n",
            " 1202 1203 1205 1212 1214 1215 1222 1255 1256 1257 1262 1273 1279 1281\n",
            " 1287 1291 1306 1307 1310 1314 1315 1320 1324 1326 1329 1330 1332 1336\n",
            " 1346 1349 1351 1352 1353 1354 1365 1394 1397 1398 1400 1405 1407 1411\n",
            " 1423 1432 1434 1442 1445 1448 1449 1467 1469 1472 1490 1494 1495 1510\n",
            " 1516 1519 1521 1522 1526 1533 1547 1548 1551 1553 1574 1581 1583 1585\n",
            " 1589 1590 1598 1601 1611 1613 1614 1619 1622 1623 1637 1642 1647 1649\n",
            " 1650 1660 1667 1671 1673 1677 1682 1684 1695 1696 1697 1705 1723 1725\n",
            " 1727 1730 1732 1734 1742 1749 1772 1781 1782 1786 1795 1798 1802 1804\n",
            " 1805 1806 1812 1813 1814 1819 1820 1821 1831 1842 1844 1847 1849 1859\n",
            " 1860 1866 1869 1873 1878 1880 1886 1892 1896 1898 1900 1910 1911 1912\n",
            " 1919 1920 1922 1926 1931 1934 1941 1943 1946 1947 1951 1952 1957 1971\n",
            " 1972 1974 1979 1982 1983 1986 1989 1995 2000 2004 2010 2013 2014 2015\n",
            " 2016 2020 2021 2022 2038 2041 2042 2044 2045 2047 2056 2057 2059 2071\n",
            " 2074 2088 2091 2096 2107 2108 2110 2111 2113 2114 2120 2121 2134 2136\n",
            " 2140 2141 2147 2148 2151 2158 2163 2165 2166 2169 2172 2173 2178 2185\n",
            " 2188 2189 2203 2208 2209 2213 2218 2226 2234 2235 2251 2254 2263 2264\n",
            " 2266 2269 2271 2277 2278 2280 2281 2287 2288 2293 2294 2296 2302 2305\n",
            " 2306 2308 2310 2312 2315 2316 2318 2319 2335 2353 2357 2363 2368 2369\n",
            " 2370 2372 2375 2378 2379 2380 2382 2384 2405 2407 2414 2417 2429 2434\n",
            " 2435 2445 2451 2452 2454 2455 2459 2460 2467 2468 2473 2475 2479 2485\n",
            " 2487 2488 2490 2501 2509 2524 2530 2533 2535 2537 2538 2540 2541 2542\n",
            " 2552 2556 2557 2562 2564 2565 2566 2578 2581 2582 2587 2588 2589 2595\n",
            " 2599 2604 2607 2610 2612 2614 2616 2621 2626 2627 2630 2631 2632 2633\n",
            " 2644 2646 2648 2651 2652 2653 2654 2657 2660 2664 2671 2678 2686 2692\n",
            " 2696 2697 2698 2703 2704 2706 2707 2709 2710 2711 2716 2725 2729 2731\n",
            " 2734 2735 2739 2747 2755 2757 2758 2767 2771 2775 2777 2781 2791 2796\n",
            " 2802 2805 2806 2808 2809 2811 2814 2816 2818 2824 2827 2829 2833 2835\n",
            " 2837 2846 2850 2855 2858 2861 2865 2871 2874 2875 2877 2878 2879 2883\n",
            " 2886 2890 2891]\n",
            "[CV 3/5; 2/10] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.5;, score=-0.002 total time= 2.4min\n",
            "[CV 4/5; 2/10] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.5\n",
            "[23:24:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    4   14   16   23   25   26   29   30   39   40   43   47   62\n",
            "   64   67   70   75   76   78   83   84   90   97   98  102  107  108\n",
            "  113  121  123  126  127  128  132  137  138  142  146  154  158  159\n",
            "  168  188  191  192  198  201  204  209  211  215  219  229  234  238\n",
            "  239  240  242  243  245  246  254  255  257  258  259  264  272  286\n",
            "  287  296  297  302  303  315  316  328  329  334  338  345  347  349\n",
            "  354  359  365  367  373  379  385  386  397  399  411  415  421  423\n",
            "  428  431  439  440  458  460  463  464  469  474  475  479  485  487\n",
            "  515  527  533  535  550  553  554  555  556  557  560  561  568  569\n",
            "  571  573  575  582  586  595  597  601  603  608  618  624  628  629\n",
            "  630  631  640  643  649  652  653  662  668  671  678  679  686  688\n",
            "  690  691  695  698  699  702  704  706  709  710  720  736  739  747\n",
            "  753  762  766  778  789  790  792  799  802  804  805  813  829  830\n",
            "  835  850  856  864  866  872  876  902  906  910  914  920  923  929\n",
            "  934  938  943  944  945  946  950  957  959  960  961  965  971  978\n",
            "  984  985  995  996  998  999 1000 1002 1005 1008 1012 1013 1014 1020\n",
            " 1036 1037 1049 1050 1059 1061 1062 1065 1066 1067 1070 1072 1074 1076\n",
            " 1082 1087 1090 1091 1093 1096 1101 1102 1104 1105 1112 1115 1118 1128\n",
            " 1134 1136 1141 1142 1143 1145 1150 1155 1163 1166 1181 1188 1189 1192\n",
            " 1193 1194 1198 1199 1200 1201 1202 1208 1209 1217 1222 1223 1225 1226\n",
            " 1229 1231 1232 1234 1238 1245 1247 1248 1249 1260 1261 1265 1266 1267\n",
            " 1269 1275 1276 1277 1289 1292 1302 1305 1310 1313 1314 1315 1317 1319\n",
            " 1321 1323 1324 1325 1328 1335 1344 1347 1349 1357 1361 1365 1369 1373\n",
            " 1379 1388 1391 1395 1397 1401 1407 1419 1421 1424 1426 1433 1438 1439\n",
            " 1441 1445 1461 1463 1464 1478 1482 1492 1493 1498 1499 1501 1503 1505\n",
            " 1511 1514 1516 1517 1519 1521 1524 1528 1529 1533 1534 1538 1539 1557\n",
            " 1558 1559 1579 1583 1587 1590 1602 1603 1613 1617 1619 1622 1626 1631\n",
            " 1641 1651 1654 1655 1657 1663 1668 1670 1688 1695 1706 1711 1712 1714\n",
            " 1719 1727 1728 1732 1734 1735 1736 1740 1746 1748 1761 1762 1767 1768\n",
            " 1778 1781 1783 1785 1788 1791 1795 1796 1802 1805 1810 1811 1813 1817\n",
            " 1818 1819 1822 1823 1839 1843 1862 1865 1873 1874 1875 1876 1877 1882\n",
            " 1887 1894 1896 1902 1905 1914 1915 1917 1925 1929 1931 1938 1939 1944\n",
            " 1952 1953 1954 1960 1965 1979 1980 1984 1986 1991 1993 1996 2001 2010\n",
            " 2011 2019 2024 2025 2032 2033 2036 2038 2040 2041 2042 2044 2047 2048\n",
            " 2051 2054 2056 2059 2069 2071 2078 2079 2080 2085 2087 2094 2097 2099\n",
            " 2104 2110 2115 2120 2121 2122 2129 2130 2135 2141 2143 2145 2148 2150\n",
            " 2157 2158 2160 2162 2166 2169 2175 2184 2195 2199 2202 2205 2213 2215\n",
            " 2217 2219 2220 2223 2224 2225 2228 2230 2231 2234 2235 2237 2248 2249\n",
            " 2253 2255 2257 2258 2259 2262 2277 2278 2282 2283 2291 2292 2297 2310\n",
            " 2314 2317 2320 2325 2326 2332 2337 2338 2340 2341 2343 2345 2349 2353\n",
            " 2354 2358 2360 2362 2376 2383 2384 2387 2390 2391 2396 2399 2400 2404\n",
            " 2408 2413 2415 2416 2417 2418 2421 2422 2427 2429 2432 2433 2450 2451\n",
            " 2454 2457 2458 2460 2461 2465 2467 2470 2471 2475 2480 2487 2494 2498\n",
            " 2502 2507 2523 2524 2531 2533 2536 2538 2543 2545 2547 2549 2551 2553\n",
            " 2554 2557 2561 2563 2567 2570 2571 2572 2579 2582 2583 2585 2586 2588\n",
            " 2594 2595 2609 2613 2615 2617 2620 2623 2624 2625 2632 2633 2640 2647\n",
            " 2649 2650 2655 2657 2662 2664 2668 2669 2671 2689 2699 2701 2704 2706\n",
            " 2707 2710 2717 2720 2723 2726 2733 2735 2736 2747 2754 2755 2757 2763\n",
            " 2771 2779 2786 2790 2791 2792 2796 2800 2802 2805 2809 2832 2840 2845\n",
            " 2846 2850 2855 2860 2861 2863 2869 2870 2876 2877 2879 2883 2887 2889]\n",
            "[CV 4/5; 2/10] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.5;, score=-0.002 total time= 2.4min\n",
            "[CV 5/5; 2/10] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.5\n",
            "[23:26:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   5   11   14   25   27   37   41   42   51   52   55   56   59   60\n",
            "   76   81   83   90   96  100  108  109  114  116  119  124  128  135\n",
            "  137  142  145  147  150  157  164  167  170  178  185  190  192  194\n",
            "  198  202  211  214  222  223  237  238  243  246  252  255  258  260\n",
            "  261  268  270  271  276  283  286  288  294  302  318  322  326  331\n",
            "  335  336  348  350  351  353  354  370  375  380  382  383  390  393\n",
            "  403  404  406  407  409  421  424  433  438  440  442  455  463  473\n",
            "  476  478  479  481  482  487  489  497  499  502  504  509  510  516\n",
            "  517  521  529  533  536  540  541  546  552  556  557  560  566  572\n",
            "  575  578  579  581  595  602  603  612  614  617  618  622  626  629\n",
            "  639  642  644  657  660  666  668  673  675  676  688  689  690  692\n",
            "  695  696  697  703  705  715  717  718  719  728  730  733  740  747\n",
            "  755  759  761  764  765  773  776  779  782  784  786  794  797  799\n",
            "  800  810  811  816  822  830  831  833  836  855  858  864  868  879\n",
            "  880  896  898  904  910  917  925  928  930  932  940  942  948  950\n",
            "  963  966  968  970  971  972  974  984  987  989  992  993  997 1002\n",
            " 1006 1010 1014 1023 1029 1032 1035 1041 1046 1050 1051 1057 1062 1063\n",
            " 1065 1067 1068 1069 1072 1076 1077 1088 1089 1093 1101 1107 1114 1118\n",
            " 1121 1128 1130 1131 1138 1139 1142 1144 1150 1151 1155 1161 1167 1175\n",
            " 1177 1181 1187 1194 1196 1199 1201 1202 1205 1222 1223 1225 1230 1231\n",
            " 1234 1246 1250 1252 1253 1255 1263 1270 1272 1273 1277 1279 1285 1289\n",
            " 1291 1297 1298 1303 1304 1306 1307 1311 1321 1328 1331 1336 1337 1341\n",
            " 1347 1355 1358 1364 1370 1372 1374 1376 1379 1380 1381 1383 1392 1394\n",
            " 1399 1404 1409 1412 1419 1420 1422 1431 1433 1437 1438 1441 1447 1448\n",
            " 1449 1454 1458 1459 1463 1465 1467 1468 1471 1486 1491 1497 1499 1501\n",
            " 1508 1509 1510 1514 1522 1524 1527 1533 1537 1542 1551 1554 1561 1563\n",
            " 1565 1567 1569 1571 1572 1574 1577 1581 1583 1584 1588 1595 1596 1598\n",
            " 1600 1608 1612 1617 1621 1624 1630 1635 1636 1637 1640 1643 1653 1656\n",
            " 1657 1661 1668 1672 1673 1676 1679 1681 1686 1687 1688 1696 1699 1701\n",
            " 1709 1710 1720 1722 1725 1726 1731 1733 1737 1738 1741 1746 1747 1749\n",
            " 1751 1754 1756 1763 1765 1772 1782 1783 1787 1788 1792 1796 1802 1809\n",
            " 1817 1819 1822 1834 1835 1848 1851 1860 1868 1876 1880 1893 1894 1900\n",
            " 1905 1929 1934 1938 1947 1948 1953 1956 1967 1969 1976 1978 1988 1989\n",
            " 1994 1995 1996 1999 2000 2005 2009 2011 2013 2020 2026 2027 2032 2045\n",
            " 2062 2063 2072 2074 2075 2081 2088 2089 2090 2099 2101 2110 2111 2117\n",
            " 2120 2129 2131 2132 2133 2138 2142 2143 2144 2147 2151 2153 2154 2166\n",
            " 2175 2178 2185 2188 2198 2202 2204 2206 2207 2209 2224 2230 2231 2237\n",
            " 2248 2249 2251 2258 2261 2262 2264 2272 2276 2280 2281 2282 2283 2285\n",
            " 2288 2295 2297 2300 2308 2314 2315 2316 2317 2320 2321 2327 2328 2332\n",
            " 2336 2337 2351 2359 2368 2370 2373 2383 2392 2394 2404 2405 2408 2410\n",
            " 2425 2435 2439 2440 2453 2458 2467 2470 2473 2478 2481 2483 2487 2489\n",
            " 2490 2499 2500 2505 2512 2513 2517 2522 2523 2524 2527 2528 2529 2533\n",
            " 2538 2541 2549 2551 2578 2589 2596 2601 2610 2627 2630 2633 2643 2645\n",
            " 2649 2653 2655 2672 2673 2679 2690 2692 2697 2698 2699 2705 2714 2718\n",
            " 2727 2732 2744 2745 2746 2747 2751 2757 2758 2761 2763 2767 2781 2782\n",
            " 2786 2789 2795 2801 2806 2810 2812 2814 2816 2818 2824 2826 2832 2833\n",
            " 2838 2841 2843 2844 2847 2850 2851 2853 2868 2871 2876 2878 2880 2881\n",
            " 2887 2888 2889 2892]\n",
            "[CV 5/5; 2/10] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.8999999999999999, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.5;, score=-0.002 total time= 2.4min\n",
            "[CV 1/5; 3/10] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7\n",
            "[23:29:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    8   11   17   19   20   23   33   34   36   39   43   47   52\n",
            "   55   65   67   70   74   76   78   80   85   87   89   97   98  102\n",
            "  108  109  111  114  117  119  121  123  124  128  130  135  138  140\n",
            "  149  162  169  171  174  175  177  180  188  189  190  192  195  202\n",
            "  212  224  227  234  235  237  238  242  243  245  247  248  251  252\n",
            "  257  262  264  267  271  274  275  277  279  280  287  292  297  304\n",
            "  306  307  314  319  327  332  334  336  340  345  346  347  350  352\n",
            "  354  358  368  375  379  381  385  388  390  391  394  395  402  404\n",
            "  412  418  422  423  424  428  430  438  443  447  450  459  468  477\n",
            "  479  484  485  486  488  495  499  511  522  529  532  534  536  541\n",
            "  543  560  562  563  568  570  577  586  589  590  594  599  603  613\n",
            "  615  617  624  625  627  634  635  639  645  650  667  676  679  689\n",
            "  690  691  695  696  700  703  707  715  718  720  726  728  730  733\n",
            "  737  749  755  759  763  764  765  773  774  779  786  798  802  808\n",
            "  822  824  829  832  836  852  856  862  865  867  870  872  873  874\n",
            "  884  888  893  894  899  900  917  920  922  923  926  940  941  944\n",
            "  959  965  968  974  976  978  979  981  983  989  990  991  995  996\n",
            " 1001 1009 1012 1015 1025 1028 1038 1044 1049 1070 1071 1079 1080 1081\n",
            " 1083 1089 1090 1096 1098 1104 1105 1111 1113 1120 1121 1123 1125 1127\n",
            " 1131 1135 1141 1145 1151 1154 1156 1157 1158 1163 1164 1166 1179 1183\n",
            " 1192 1195 1202 1205 1206 1209 1210 1224 1226 1239 1240 1245 1256 1259\n",
            " 1260 1262 1263 1270 1273 1280 1288 1289 1292 1295 1296 1300 1304 1309\n",
            " 1322 1330 1332 1338 1340 1343 1346 1358 1363 1377 1378 1380 1383 1384\n",
            " 1391 1393 1401 1402 1403 1410 1417 1418 1422 1438 1444 1445 1450 1453\n",
            " 1455 1456 1464 1466 1468 1469 1475 1482 1489 1491 1494 1499 1505 1513\n",
            " 1528 1532 1535 1536 1537 1538 1539 1545 1551 1554 1555 1557 1559 1561\n",
            " 1562 1565 1566 1573 1579 1588 1597 1599 1602 1607 1609 1612 1614 1615\n",
            " 1618 1622 1625 1630 1631 1643 1645 1649 1650 1656 1675 1676 1679 1684\n",
            " 1685 1691 1697 1701 1705 1706 1707 1709 1716 1726 1727 1728 1740 1742\n",
            " 1748 1751 1753 1763 1768 1769 1770 1786 1794 1798 1799 1801 1804 1812\n",
            " 1814 1821 1822 1825 1835 1841 1842 1846 1848 1856 1857 1874 1875 1879\n",
            " 1880 1892 1907 1917 1927 1930 1940 1942 1949 1952 1957 1966 1971 1974\n",
            " 1975 1976 1979 1981 1984 1987 1989 1992 1993 1995 2002 2003 2007 2010\n",
            " 2015 2027 2028 2029 2031 2035 2037 2049 2054 2056 2060 2061 2066 2070\n",
            " 2071 2075 2076 2082 2085 2087 2094 2098 2110 2111 2112 2113 2122 2123\n",
            " 2141 2142 2145 2157 2162 2166 2167 2172 2177 2180 2181 2183 2186 2195\n",
            " 2202 2209 2213 2215 2219 2220 2222 2224 2232 2233 2240 2244 2246 2248\n",
            " 2253 2259 2266 2276 2277 2280 2282 2284 2291 2298 2309 2311 2313 2322\n",
            " 2338 2339 2340 2341 2346 2347 2348 2350 2361 2363 2364 2365 2366 2369\n",
            " 2374 2375 2380 2382 2385 2386 2396 2406 2410 2413 2416 2420 2422 2427\n",
            " 2436 2438 2439 2440 2441 2444 2445 2448 2449 2453 2456 2459 2461 2463\n",
            " 2464 2469 2472 2474 2483 2494 2498 2505 2507 2509 2514 2517 2522 2524\n",
            " 2526 2531 2538 2547 2550 2554 2557 2561 2566 2571 2574 2577 2581 2585\n",
            " 2590 2594 2600 2603 2606 2612 2618 2620 2622 2625 2633 2642 2647 2654\n",
            " 2655 2656 2661 2665 2669 2671 2672 2677 2684 2694 2700 2701 2704 2706\n",
            " 2709 2712 2713 2714 2715 2725 2727 2730 2735 2738 2742 2743 2748 2756\n",
            " 2760 2763 2767 2772 2774 2776 2779 2781 2785 2786 2790 2792 2805 2806\n",
            " 2807 2810 2820 2827 2832 2841 2847 2852 2857 2862 2865 2867 2871 2873\n",
            " 2878 2881 2884 2887 2889]\n",
            "[CV 1/5; 3/10] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7;, score=nan total time=  50.1s\n",
            "[CV 2/5; 3/10] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7\n",
            "[23:29:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"<ipython-input-32-fc5a6eefbb96>\", line 5, in penalized_MSE_train\n",
            "    return penalized_MSE_helper(sci.special.inv_boxcox(y_true, fitted_lambda),sci.special.inv_boxcox(y_pred, fitted_lambda))\n",
            "  File \"<ipython-input-31-ae3c46e3511d>\", line 11, in penalized_MSE_helper\n",
            "    return (1/2)*MSE(critical_y, critical_predictions)+ (1/2)*MSE(common_y, common_predictions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 424, in mean_squared_error\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 91, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 792, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   3    5    7   12   14   20   22   25   27   31   32   33   43   47\n",
            "   51   62   64   69   70   71   74   76   88   89  109  111  113  115\n",
            "  125  133  137  141  143  145  148  156  159  174  175  176  180  190\n",
            "  191  195  199  200  203  205  207  209  210  212  213  215  220  227\n",
            "  231  238  252  258  262  268  269  272  310  311  314  315  332  334\n",
            "  356  361  362  363  364  367  368  369  371  373  377  380  384  385\n",
            "  390  399  403  407  409  410  417  429  431  435  444  449  464  465\n",
            "  466  467  470  474  475  480  489  490  492  493  498  499  501  505\n",
            "  509  512  513  517  518  521  524  529  533  534  537  539  541  545\n",
            "  549  550  558  560  564  573  574  577  580  584  585  586  587  594\n",
            "  598  605  606  612  624  627  628  630  642  647  649  651  663  665\n",
            "  679  680  691  696  701  710  711  716  727  731  733  736  744  750\n",
            "  751  759  760  763  765  771  773  776  780  789  794  806  809  812\n",
            "  814  820  821  833  838  844  855  859  866  868  884  890  894  902\n",
            "  905  907  909  916  917  921  922  931  934  937  958  968  969  973\n",
            "  979  981  990 1004 1010 1014 1015 1018 1033 1036 1037 1038 1040 1042\n",
            " 1043 1049 1068 1069 1076 1081 1084 1088 1090 1092 1094 1097 1100 1101\n",
            " 1105 1107 1116 1118 1123 1124 1128 1133 1141 1151 1152 1153 1161 1162\n",
            " 1164 1178 1179 1181 1189 1193 1197 1202 1209 1214 1221 1237 1241 1244\n",
            " 1245 1250 1253 1254 1258 1261 1262 1264 1266 1267 1268 1269 1270 1272\n",
            " 1276 1283 1287 1292 1293 1295 1303 1304 1310 1312 1316 1319 1328 1336\n",
            " 1341 1343 1344 1346 1351 1356 1374 1375 1378 1379 1383 1389 1397 1398\n",
            " 1399 1401 1404 1408 1413 1420 1437 1439 1440 1441 1446 1447 1450 1451\n",
            " 1458 1461 1475 1479 1481 1487 1488 1493 1504 1505 1506 1511 1512 1529\n",
            " 1532 1533 1537 1538 1541 1549 1550 1553 1559 1560 1565 1570 1571 1572\n",
            " 1573 1586 1588 1601 1607 1610 1611 1613 1614 1620 1626 1627 1634 1641\n",
            " 1647 1653 1658 1665 1672 1681 1684 1686 1696 1697 1705 1708 1720 1721\n",
            " 1725 1727 1738 1739 1742 1743 1751 1757 1762 1764 1769 1770 1773 1775\n",
            " 1779 1783 1786 1787 1789 1800 1803 1807 1809 1812 1821 1829 1836 1837\n",
            " 1839 1844 1855 1857 1875 1877 1879 1887 1889 1894 1897 1900 1902 1903\n",
            " 1907 1908 1917 1921 1923 1937 1947 1948 1951 1953 1956 1957 1959 1961\n",
            " 1964 1967 1968 1970 1974 1975 1981 1983 1986 1987 1994 1998 2003 2007\n",
            " 2009 2011 2013 2015 2020 2029 2036 2037 2041 2043 2045 2046 2047 2057\n",
            " 2058 2064 2070 2082 2086 2088 2089 2090 2093 2095 2101 2104 2110 2111\n",
            " 2113 2114 2115 2118 2119 2127 2134 2139 2141 2146 2147 2149 2150 2157\n",
            " 2159 2161 2166 2167 2169 2178 2182 2188 2197 2201 2207 2215 2217 2219\n",
            " 2222 2223 2224 2225 2231 2232 2233 2241 2245 2257 2262 2272 2291 2292\n",
            " 2293 2294 2296 2306 2307 2308 2309 2314 2340 2346 2347 2348 2353 2359\n",
            " 2369 2373 2380 2381 2382 2386 2393 2396 2401 2402 2403 2409 2411 2414\n",
            " 2419 2424 2431 2432 2433 2436 2437 2445 2450 2451 2452 2458 2460 2462\n",
            " 2463 2466 2471 2476 2494 2496 2503 2507 2510 2528 2530 2534 2535 2536\n",
            " 2538 2540 2542 2553 2554 2558 2559 2564 2571 2572 2574 2575 2582 2592\n",
            " 2594 2605 2612 2620 2623 2637 2643 2654 2657 2668 2677 2678 2680 2683\n",
            " 2690 2691 2693 2696 2700 2702 2705 2707 2708 2713 2717 2724 2727 2733\n",
            " 2735 2737 2748 2752 2753 2755 2765 2772 2775 2776 2781 2797 2800 2805\n",
            " 2806 2812 2813 2814 2815 2822 2831 2832 2835 2839 2843 2851 2855 2856\n",
            " 2859 2871 2872 2873 2884 2885 2886 2890 2892]\n",
            "[CV 2/5; 3/10] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7;, score=-0.005 total time=  49.8s\n",
            "[CV 3/5; 3/10] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7\n",
            "[23:30:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   4   11   30   35   36   37   41   54   63   66   69   76   87   97\n",
            "   98  102  106  130  131  133  134  142  148  149  159  161  165  176\n",
            "  178  187  190  191  194  201  202  206  224  226  227  232  238  246\n",
            "  248  250  256  259  261  264  270  271  274  278  279  287  288  290\n",
            "  303  304  307  313  314  316  318  322  324  327  334  335  339  346\n",
            "  347  349  358  367  369  373  374  375  376  377  378  390  391  393\n",
            "  394  397  398  411  420  421  423  428  429  435  442  443  448  450\n",
            "  457  461  464  465  467  469  474  493  497  499  500  501  503  520\n",
            "  529  530  545  547  553  561  562  567  569  570  573  586  592  597\n",
            "  598  599  603  604  605  611  625  629  630  633  636  640  645  654\n",
            "  658  662  670  675  678  686  690  692  697  699  702  707  710  718\n",
            "  719  725  731  732  733  738  745  746  752  777  782  784  788  790\n",
            "  793  794  797  798  800  802  804  813  824  825  826  832  836  852\n",
            "  856  859  861  864  868  871  878  885  889  891  896  904  911  913\n",
            "  917  923  927  952  958  962  969  974  976  979  986  988  989  990\n",
            "  997  998  999 1001 1008 1009 1029 1034 1041 1048 1052 1056 1061 1069\n",
            " 1072 1073 1080 1082 1091 1092 1099 1101 1111 1115 1120 1123 1124 1130\n",
            " 1134 1137 1144 1150 1152 1156 1168 1171 1173 1179 1183 1188 1196 1200\n",
            " 1202 1203 1205 1212 1214 1215 1222 1255 1256 1257 1262 1273 1279 1281\n",
            " 1287 1291 1306 1307 1310 1314 1315 1320 1324 1326 1329 1330 1332 1336\n",
            " 1346 1349 1351 1352 1353 1354 1365 1394 1397 1398 1400 1405 1407 1411\n",
            " 1423 1432 1434 1442 1445 1448 1449 1467 1469 1472 1490 1494 1495 1510\n",
            " 1516 1519 1521 1522 1526 1533 1547 1548 1551 1553 1574 1581 1583 1585\n",
            " 1589 1590 1598 1601 1611 1613 1614 1619 1622 1623 1637 1642 1647 1649\n",
            " 1650 1660 1667 1671 1673 1677 1682 1684 1695 1696 1697 1705 1723 1725\n",
            " 1727 1730 1732 1734 1742 1749 1772 1781 1782 1786 1795 1798 1802 1804\n",
            " 1805 1806 1812 1813 1814 1819 1820 1821 1831 1842 1844 1847 1849 1859\n",
            " 1860 1866 1869 1873 1878 1880 1886 1892 1896 1898 1900 1910 1911 1912\n",
            " 1919 1920 1922 1926 1931 1934 1941 1943 1946 1947 1951 1952 1957 1971\n",
            " 1972 1974 1979 1982 1983 1986 1989 1995 2000 2004 2010 2013 2014 2015\n",
            " 2016 2020 2021 2022 2038 2041 2042 2044 2045 2047 2056 2057 2059 2071\n",
            " 2074 2088 2091 2096 2107 2108 2110 2111 2113 2114 2120 2121 2134 2136\n",
            " 2140 2141 2147 2148 2151 2158 2163 2165 2166 2169 2172 2173 2178 2185\n",
            " 2188 2189 2203 2208 2209 2213 2218 2226 2234 2235 2251 2254 2263 2264\n",
            " 2266 2269 2271 2277 2278 2280 2281 2287 2288 2293 2294 2296 2302 2305\n",
            " 2306 2308 2310 2312 2315 2316 2318 2319 2335 2353 2357 2363 2368 2369\n",
            " 2370 2372 2375 2378 2379 2380 2382 2384 2405 2407 2414 2417 2429 2434\n",
            " 2435 2445 2451 2452 2454 2455 2459 2460 2467 2468 2473 2475 2479 2485\n",
            " 2487 2488 2490 2501 2509 2524 2530 2533 2535 2537 2538 2540 2541 2542\n",
            " 2552 2556 2557 2562 2564 2565 2566 2578 2581 2582 2587 2588 2589 2595\n",
            " 2599 2604 2607 2610 2612 2614 2616 2621 2626 2627 2630 2631 2632 2633\n",
            " 2644 2646 2648 2651 2652 2653 2654 2657 2660 2664 2671 2678 2686 2692\n",
            " 2696 2697 2698 2703 2704 2706 2707 2709 2710 2711 2716 2725 2729 2731\n",
            " 2734 2735 2739 2747 2755 2757 2758 2767 2771 2775 2777 2781 2791 2796\n",
            " 2802 2805 2806 2808 2809 2811 2814 2816 2818 2824 2827 2829 2833 2835\n",
            " 2837 2846 2850 2855 2858 2861 2865 2871 2874 2875 2877 2878 2879 2883\n",
            " 2886 2890 2891]\n",
            "[CV 3/5; 3/10] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7;, score=-0.006 total time=  50.7s\n",
            "[CV 4/5; 3/10] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7\n",
            "[23:31:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    4   14   16   23   25   26   29   30   39   40   43   47   62\n",
            "   64   67   70   75   76   78   83   84   90   97   98  102  107  108\n",
            "  113  121  123  126  127  128  132  137  138  142  146  154  158  159\n",
            "  168  188  191  192  198  201  204  209  211  215  219  229  234  238\n",
            "  239  240  242  243  245  246  254  255  257  258  259  264  272  286\n",
            "  287  296  297  302  303  315  316  328  329  334  338  345  347  349\n",
            "  354  359  365  367  373  379  385  386  397  399  411  415  421  423\n",
            "  428  431  439  440  458  460  463  464  469  474  475  479  485  487\n",
            "  515  527  533  535  550  553  554  555  556  557  560  561  568  569\n",
            "  571  573  575  582  586  595  597  601  603  608  618  624  628  629\n",
            "  630  631  640  643  649  652  653  662  668  671  678  679  686  688\n",
            "  690  691  695  698  699  702  704  706  709  710  720  736  739  747\n",
            "  753  762  766  778  789  790  792  799  802  804  805  813  829  830\n",
            "  835  850  856  864  866  872  876  902  906  910  914  920  923  929\n",
            "  934  938  943  944  945  946  950  957  959  960  961  965  971  978\n",
            "  984  985  995  996  998  999 1000 1002 1005 1008 1012 1013 1014 1020\n",
            " 1036 1037 1049 1050 1059 1061 1062 1065 1066 1067 1070 1072 1074 1076\n",
            " 1082 1087 1090 1091 1093 1096 1101 1102 1104 1105 1112 1115 1118 1128\n",
            " 1134 1136 1141 1142 1143 1145 1150 1155 1163 1166 1181 1188 1189 1192\n",
            " 1193 1194 1198 1199 1200 1201 1202 1208 1209 1217 1222 1223 1225 1226\n",
            " 1229 1231 1232 1234 1238 1245 1247 1248 1249 1260 1261 1265 1266 1267\n",
            " 1269 1275 1276 1277 1289 1292 1302 1305 1310 1313 1314 1315 1317 1319\n",
            " 1321 1323 1324 1325 1328 1335 1344 1347 1349 1357 1361 1365 1369 1373\n",
            " 1379 1388 1391 1395 1397 1401 1407 1419 1421 1424 1426 1433 1438 1439\n",
            " 1441 1445 1461 1463 1464 1478 1482 1492 1493 1498 1499 1501 1503 1505\n",
            " 1511 1514 1516 1517 1519 1521 1524 1528 1529 1533 1534 1538 1539 1557\n",
            " 1558 1559 1579 1583 1587 1590 1602 1603 1613 1617 1619 1622 1626 1631\n",
            " 1641 1651 1654 1655 1657 1663 1668 1670 1688 1695 1706 1711 1712 1714\n",
            " 1719 1727 1728 1732 1734 1735 1736 1740 1746 1748 1761 1762 1767 1768\n",
            " 1778 1781 1783 1785 1788 1791 1795 1796 1802 1805 1810 1811 1813 1817\n",
            " 1818 1819 1822 1823 1839 1843 1862 1865 1873 1874 1875 1876 1877 1882\n",
            " 1887 1894 1896 1902 1905 1914 1915 1917 1925 1929 1931 1938 1939 1944\n",
            " 1952 1953 1954 1960 1965 1979 1980 1984 1986 1991 1993 1996 2001 2010\n",
            " 2011 2019 2024 2025 2032 2033 2036 2038 2040 2041 2042 2044 2047 2048\n",
            " 2051 2054 2056 2059 2069 2071 2078 2079 2080 2085 2087 2094 2097 2099\n",
            " 2104 2110 2115 2120 2121 2122 2129 2130 2135 2141 2143 2145 2148 2150\n",
            " 2157 2158 2160 2162 2166 2169 2175 2184 2195 2199 2202 2205 2213 2215\n",
            " 2217 2219 2220 2223 2224 2225 2228 2230 2231 2234 2235 2237 2248 2249\n",
            " 2253 2255 2257 2258 2259 2262 2277 2278 2282 2283 2291 2292 2297 2310\n",
            " 2314 2317 2320 2325 2326 2332 2337 2338 2340 2341 2343 2345 2349 2353\n",
            " 2354 2358 2360 2362 2376 2383 2384 2387 2390 2391 2396 2399 2400 2404\n",
            " 2408 2413 2415 2416 2417 2418 2421 2422 2427 2429 2432 2433 2450 2451\n",
            " 2454 2457 2458 2460 2461 2465 2467 2470 2471 2475 2480 2487 2494 2498\n",
            " 2502 2507 2523 2524 2531 2533 2536 2538 2543 2545 2547 2549 2551 2553\n",
            " 2554 2557 2561 2563 2567 2570 2571 2572 2579 2582 2583 2585 2586 2588\n",
            " 2594 2595 2609 2613 2615 2617 2620 2623 2624 2625 2632 2633 2640 2647\n",
            " 2649 2650 2655 2657 2662 2664 2668 2669 2671 2689 2699 2701 2704 2706\n",
            " 2707 2710 2717 2720 2723 2726 2733 2735 2736 2747 2754 2755 2757 2763\n",
            " 2771 2779 2786 2790 2791 2792 2796 2800 2802 2805 2809 2832 2840 2845\n",
            " 2846 2850 2855 2860 2861 2863 2869 2870 2876 2877 2879 2883 2887 2889]\n",
            "[CV 4/5; 3/10] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7;, score=-0.006 total time=  50.5s\n",
            "[CV 5/5; 3/10] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7\n",
            "[23:32:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   5   11   14   25   27   37   41   42   51   52   55   56   59   60\n",
            "   76   81   83   90   96  100  108  109  114  116  119  124  128  135\n",
            "  137  142  145  147  150  157  164  167  170  178  185  190  192  194\n",
            "  198  202  211  214  222  223  237  238  243  246  252  255  258  260\n",
            "  261  268  270  271  276  283  286  288  294  302  318  322  326  331\n",
            "  335  336  348  350  351  353  354  370  375  380  382  383  390  393\n",
            "  403  404  406  407  409  421  424  433  438  440  442  455  463  473\n",
            "  476  478  479  481  482  487  489  497  499  502  504  509  510  516\n",
            "  517  521  529  533  536  540  541  546  552  556  557  560  566  572\n",
            "  575  578  579  581  595  602  603  612  614  617  618  622  626  629\n",
            "  639  642  644  657  660  666  668  673  675  676  688  689  690  692\n",
            "  695  696  697  703  705  715  717  718  719  728  730  733  740  747\n",
            "  755  759  761  764  765  773  776  779  782  784  786  794  797  799\n",
            "  800  810  811  816  822  830  831  833  836  855  858  864  868  879\n",
            "  880  896  898  904  910  917  925  928  930  932  940  942  948  950\n",
            "  963  966  968  970  971  972  974  984  987  989  992  993  997 1002\n",
            " 1006 1010 1014 1023 1029 1032 1035 1041 1046 1050 1051 1057 1062 1063\n",
            " 1065 1067 1068 1069 1072 1076 1077 1088 1089 1093 1101 1107 1114 1118\n",
            " 1121 1128 1130 1131 1138 1139 1142 1144 1150 1151 1155 1161 1167 1175\n",
            " 1177 1181 1187 1194 1196 1199 1201 1202 1205 1222 1223 1225 1230 1231\n",
            " 1234 1246 1250 1252 1253 1255 1263 1270 1272 1273 1277 1279 1285 1289\n",
            " 1291 1297 1298 1303 1304 1306 1307 1311 1321 1328 1331 1336 1337 1341\n",
            " 1347 1355 1358 1364 1370 1372 1374 1376 1379 1380 1381 1383 1392 1394\n",
            " 1399 1404 1409 1412 1419 1420 1422 1431 1433 1437 1438 1441 1447 1448\n",
            " 1449 1454 1458 1459 1463 1465 1467 1468 1471 1486 1491 1497 1499 1501\n",
            " 1508 1509 1510 1514 1522 1524 1527 1533 1537 1542 1551 1554 1561 1563\n",
            " 1565 1567 1569 1571 1572 1574 1577 1581 1583 1584 1588 1595 1596 1598\n",
            " 1600 1608 1612 1617 1621 1624 1630 1635 1636 1637 1640 1643 1653 1656\n",
            " 1657 1661 1668 1672 1673 1676 1679 1681 1686 1687 1688 1696 1699 1701\n",
            " 1709 1710 1720 1722 1725 1726 1731 1733 1737 1738 1741 1746 1747 1749\n",
            " 1751 1754 1756 1763 1765 1772 1782 1783 1787 1788 1792 1796 1802 1809\n",
            " 1817 1819 1822 1834 1835 1848 1851 1860 1868 1876 1880 1893 1894 1900\n",
            " 1905 1929 1934 1938 1947 1948 1953 1956 1967 1969 1976 1978 1988 1989\n",
            " 1994 1995 1996 1999 2000 2005 2009 2011 2013 2020 2026 2027 2032 2045\n",
            " 2062 2063 2072 2074 2075 2081 2088 2089 2090 2099 2101 2110 2111 2117\n",
            " 2120 2129 2131 2132 2133 2138 2142 2143 2144 2147 2151 2153 2154 2166\n",
            " 2175 2178 2185 2188 2198 2202 2204 2206 2207 2209 2224 2230 2231 2237\n",
            " 2248 2249 2251 2258 2261 2262 2264 2272 2276 2280 2281 2282 2283 2285\n",
            " 2288 2295 2297 2300 2308 2314 2315 2316 2317 2320 2321 2327 2328 2332\n",
            " 2336 2337 2351 2359 2368 2370 2373 2383 2392 2394 2404 2405 2408 2410\n",
            " 2425 2435 2439 2440 2453 2458 2467 2470 2473 2478 2481 2483 2487 2489\n",
            " 2490 2499 2500 2505 2512 2513 2517 2522 2523 2524 2527 2528 2529 2533\n",
            " 2538 2541 2549 2551 2578 2589 2596 2601 2610 2627 2630 2633 2643 2645\n",
            " 2649 2653 2655 2672 2673 2679 2690 2692 2697 2698 2699 2705 2714 2718\n",
            " 2727 2732 2744 2745 2746 2747 2751 2757 2758 2761 2763 2767 2781 2782\n",
            " 2786 2789 2795 2801 2806 2810 2812 2814 2816 2818 2824 2826 2832 2833\n",
            " 2838 2841 2843 2844 2847 2850 2851 2853 2868 2871 2876 2878 2880 2881\n",
            " 2887 2888 2889 2892]\n",
            "[CV 5/5; 3/10] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7;, score=-0.011 total time=  50.2s\n",
            "[CV 1/5; 4/10] START colsample_bylevel=0.5, colsample_bytree=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5\n",
            "[23:33:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    8   11   17   19   20   23   33   34   36   39   43   47   52\n",
            "   55   65   67   70   74   76   78   80   85   87   89   97   98  102\n",
            "  108  109  111  114  117  119  121  123  124  128  130  135  138  140\n",
            "  149  162  169  171  174  175  177  180  188  189  190  192  195  202\n",
            "  212  224  227  234  235  237  238  242  243  245  247  248  251  252\n",
            "  257  262  264  267  271  274  275  277  279  280  287  292  297  304\n",
            "  306  307  314  319  327  332  334  336  340  345  346  347  350  352\n",
            "  354  358  368  375  379  381  385  388  390  391  394  395  402  404\n",
            "  412  418  422  423  424  428  430  438  443  447  450  459  468  477\n",
            "  479  484  485  486  488  495  499  511  522  529  532  534  536  541\n",
            "  543  560  562  563  568  570  577  586  589  590  594  599  603  613\n",
            "  615  617  624  625  627  634  635  639  645  650  667  676  679  689\n",
            "  690  691  695  696  700  703  707  715  718  720  726  728  730  733\n",
            "  737  749  755  759  763  764  765  773  774  779  786  798  802  808\n",
            "  822  824  829  832  836  852  856  862  865  867  870  872  873  874\n",
            "  884  888  893  894  899  900  917  920  922  923  926  940  941  944\n",
            "  959  965  968  974  976  978  979  981  983  989  990  991  995  996\n",
            " 1001 1009 1012 1015 1025 1028 1038 1044 1049 1070 1071 1079 1080 1081\n",
            " 1083 1089 1090 1096 1098 1104 1105 1111 1113 1120 1121 1123 1125 1127\n",
            " 1131 1135 1141 1145 1151 1154 1156 1157 1158 1163 1164 1166 1179 1183\n",
            " 1192 1195 1202 1205 1206 1209 1210 1224 1226 1239 1240 1245 1256 1259\n",
            " 1260 1262 1263 1270 1273 1280 1288 1289 1292 1295 1296 1300 1304 1309\n",
            " 1322 1330 1332 1338 1340 1343 1346 1358 1363 1377 1378 1380 1383 1384\n",
            " 1391 1393 1401 1402 1403 1410 1417 1418 1422 1438 1444 1445 1450 1453\n",
            " 1455 1456 1464 1466 1468 1469 1475 1482 1489 1491 1494 1499 1505 1513\n",
            " 1528 1532 1535 1536 1537 1538 1539 1545 1551 1554 1555 1557 1559 1561\n",
            " 1562 1565 1566 1573 1579 1588 1597 1599 1602 1607 1609 1612 1614 1615\n",
            " 1618 1622 1625 1630 1631 1643 1645 1649 1650 1656 1675 1676 1679 1684\n",
            " 1685 1691 1697 1701 1705 1706 1707 1709 1716 1726 1727 1728 1740 1742\n",
            " 1748 1751 1753 1763 1768 1769 1770 1786 1794 1798 1799 1801 1804 1812\n",
            " 1814 1821 1822 1825 1835 1841 1842 1846 1848 1856 1857 1874 1875 1879\n",
            " 1880 1892 1907 1917 1927 1930 1940 1942 1949 1952 1957 1966 1971 1974\n",
            " 1975 1976 1979 1981 1984 1987 1989 1992 1993 1995 2002 2003 2007 2010\n",
            " 2015 2027 2028 2029 2031 2035 2037 2049 2054 2056 2060 2061 2066 2070\n",
            " 2071 2075 2076 2082 2085 2087 2094 2098 2110 2111 2112 2113 2122 2123\n",
            " 2141 2142 2145 2157 2162 2166 2167 2172 2177 2180 2181 2183 2186 2195\n",
            " 2202 2209 2213 2215 2219 2220 2222 2224 2232 2233 2240 2244 2246 2248\n",
            " 2253 2259 2266 2276 2277 2280 2282 2284 2291 2298 2309 2311 2313 2322\n",
            " 2338 2339 2340 2341 2346 2347 2348 2350 2361 2363 2364 2365 2366 2369\n",
            " 2374 2375 2380 2382 2385 2386 2396 2406 2410 2413 2416 2420 2422 2427\n",
            " 2436 2438 2439 2440 2441 2444 2445 2448 2449 2453 2456 2459 2461 2463\n",
            " 2464 2469 2472 2474 2483 2494 2498 2505 2507 2509 2514 2517 2522 2524\n",
            " 2526 2531 2538 2547 2550 2554 2557 2561 2566 2571 2574 2577 2581 2585\n",
            " 2590 2594 2600 2603 2606 2612 2618 2620 2622 2625 2633 2642 2647 2654\n",
            " 2655 2656 2661 2665 2669 2671 2672 2677 2684 2694 2700 2701 2704 2706\n",
            " 2709 2712 2713 2714 2715 2725 2727 2730 2735 2738 2742 2743 2748 2756\n",
            " 2760 2763 2767 2772 2774 2776 2779 2781 2785 2786 2790 2792 2805 2806\n",
            " 2807 2810 2820 2827 2832 2841 2847 2852 2857 2862 2865 2867 2871 2873\n",
            " 2878 2881 2884 2887 2889]\n",
            "[CV 1/5; 4/10] END colsample_bylevel=0.5, colsample_bytree=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=-0.005 total time=   8.9s\n",
            "[CV 2/5; 4/10] START colsample_bylevel=0.5, colsample_bytree=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5\n",
            "[23:33:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   3    5    7   12   14   20   22   25   27   31   32   33   43   47\n",
            "   51   62   64   69   70   71   74   76   88   89  109  111  113  115\n",
            "  125  133  137  141  143  145  148  156  159  174  175  176  180  190\n",
            "  191  195  199  200  203  205  207  209  210  212  213  215  220  227\n",
            "  231  238  252  258  262  268  269  272  310  311  314  315  332  334\n",
            "  356  361  362  363  364  367  368  369  371  373  377  380  384  385\n",
            "  390  399  403  407  409  410  417  429  431  435  444  449  464  465\n",
            "  466  467  470  474  475  480  489  490  492  493  498  499  501  505\n",
            "  509  512  513  517  518  521  524  529  533  534  537  539  541  545\n",
            "  549  550  558  560  564  573  574  577  580  584  585  586  587  594\n",
            "  598  605  606  612  624  627  628  630  642  647  649  651  663  665\n",
            "  679  680  691  696  701  710  711  716  727  731  733  736  744  750\n",
            "  751  759  760  763  765  771  773  776  780  789  794  806  809  812\n",
            "  814  820  821  833  838  844  855  859  866  868  884  890  894  902\n",
            "  905  907  909  916  917  921  922  931  934  937  958  968  969  973\n",
            "  979  981  990 1004 1010 1014 1015 1018 1033 1036 1037 1038 1040 1042\n",
            " 1043 1049 1068 1069 1076 1081 1084 1088 1090 1092 1094 1097 1100 1101\n",
            " 1105 1107 1116 1118 1123 1124 1128 1133 1141 1151 1152 1153 1161 1162\n",
            " 1164 1178 1179 1181 1189 1193 1197 1202 1209 1214 1221 1237 1241 1244\n",
            " 1245 1250 1253 1254 1258 1261 1262 1264 1266 1267 1268 1269 1270 1272\n",
            " 1276 1283 1287 1292 1293 1295 1303 1304 1310 1312 1316 1319 1328 1336\n",
            " 1341 1343 1344 1346 1351 1356 1374 1375 1378 1379 1383 1389 1397 1398\n",
            " 1399 1401 1404 1408 1413 1420 1437 1439 1440 1441 1446 1447 1450 1451\n",
            " 1458 1461 1475 1479 1481 1487 1488 1493 1504 1505 1506 1511 1512 1529\n",
            " 1532 1533 1537 1538 1541 1549 1550 1553 1559 1560 1565 1570 1571 1572\n",
            " 1573 1586 1588 1601 1607 1610 1611 1613 1614 1620 1626 1627 1634 1641\n",
            " 1647 1653 1658 1665 1672 1681 1684 1686 1696 1697 1705 1708 1720 1721\n",
            " 1725 1727 1738 1739 1742 1743 1751 1757 1762 1764 1769 1770 1773 1775\n",
            " 1779 1783 1786 1787 1789 1800 1803 1807 1809 1812 1821 1829 1836 1837\n",
            " 1839 1844 1855 1857 1875 1877 1879 1887 1889 1894 1897 1900 1902 1903\n",
            " 1907 1908 1917 1921 1923 1937 1947 1948 1951 1953 1956 1957 1959 1961\n",
            " 1964 1967 1968 1970 1974 1975 1981 1983 1986 1987 1994 1998 2003 2007\n",
            " 2009 2011 2013 2015 2020 2029 2036 2037 2041 2043 2045 2046 2047 2057\n",
            " 2058 2064 2070 2082 2086 2088 2089 2090 2093 2095 2101 2104 2110 2111\n",
            " 2113 2114 2115 2118 2119 2127 2134 2139 2141 2146 2147 2149 2150 2157\n",
            " 2159 2161 2166 2167 2169 2178 2182 2188 2197 2201 2207 2215 2217 2219\n",
            " 2222 2223 2224 2225 2231 2232 2233 2241 2245 2257 2262 2272 2291 2292\n",
            " 2293 2294 2296 2306 2307 2308 2309 2314 2340 2346 2347 2348 2353 2359\n",
            " 2369 2373 2380 2381 2382 2386 2393 2396 2401 2402 2403 2409 2411 2414\n",
            " 2419 2424 2431 2432 2433 2436 2437 2445 2450 2451 2452 2458 2460 2462\n",
            " 2463 2466 2471 2476 2494 2496 2503 2507 2510 2528 2530 2534 2535 2536\n",
            " 2538 2540 2542 2553 2554 2558 2559 2564 2571 2572 2574 2575 2582 2592\n",
            " 2594 2605 2612 2620 2623 2637 2643 2654 2657 2668 2677 2678 2680 2683\n",
            " 2690 2691 2693 2696 2700 2702 2705 2707 2708 2713 2717 2724 2727 2733\n",
            " 2735 2737 2748 2752 2753 2755 2765 2772 2775 2776 2781 2797 2800 2805\n",
            " 2806 2812 2813 2814 2815 2822 2831 2832 2835 2839 2843 2851 2855 2856\n",
            " 2859 2871 2872 2873 2884 2885 2886 2890 2892]\n",
            "[CV 2/5; 4/10] END colsample_bylevel=0.5, colsample_bytree=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=-0.004 total time=   9.3s\n",
            "[CV 3/5; 4/10] START colsample_bylevel=0.5, colsample_bytree=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5\n",
            "[23:33:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   4   11   30   35   36   37   41   54   63   66   69   76   87   97\n",
            "   98  102  106  130  131  133  134  142  148  149  159  161  165  176\n",
            "  178  187  190  191  194  201  202  206  224  226  227  232  238  246\n",
            "  248  250  256  259  261  264  270  271  274  278  279  287  288  290\n",
            "  303  304  307  313  314  316  318  322  324  327  334  335  339  346\n",
            "  347  349  358  367  369  373  374  375  376  377  378  390  391  393\n",
            "  394  397  398  411  420  421  423  428  429  435  442  443  448  450\n",
            "  457  461  464  465  467  469  474  493  497  499  500  501  503  520\n",
            "  529  530  545  547  553  561  562  567  569  570  573  586  592  597\n",
            "  598  599  603  604  605  611  625  629  630  633  636  640  645  654\n",
            "  658  662  670  675  678  686  690  692  697  699  702  707  710  718\n",
            "  719  725  731  732  733  738  745  746  752  777  782  784  788  790\n",
            "  793  794  797  798  800  802  804  813  824  825  826  832  836  852\n",
            "  856  859  861  864  868  871  878  885  889  891  896  904  911  913\n",
            "  917  923  927  952  958  962  969  974  976  979  986  988  989  990\n",
            "  997  998  999 1001 1008 1009 1029 1034 1041 1048 1052 1056 1061 1069\n",
            " 1072 1073 1080 1082 1091 1092 1099 1101 1111 1115 1120 1123 1124 1130\n",
            " 1134 1137 1144 1150 1152 1156 1168 1171 1173 1179 1183 1188 1196 1200\n",
            " 1202 1203 1205 1212 1214 1215 1222 1255 1256 1257 1262 1273 1279 1281\n",
            " 1287 1291 1306 1307 1310 1314 1315 1320 1324 1326 1329 1330 1332 1336\n",
            " 1346 1349 1351 1352 1353 1354 1365 1394 1397 1398 1400 1405 1407 1411\n",
            " 1423 1432 1434 1442 1445 1448 1449 1467 1469 1472 1490 1494 1495 1510\n",
            " 1516 1519 1521 1522 1526 1533 1547 1548 1551 1553 1574 1581 1583 1585\n",
            " 1589 1590 1598 1601 1611 1613 1614 1619 1622 1623 1637 1642 1647 1649\n",
            " 1650 1660 1667 1671 1673 1677 1682 1684 1695 1696 1697 1705 1723 1725\n",
            " 1727 1730 1732 1734 1742 1749 1772 1781 1782 1786 1795 1798 1802 1804\n",
            " 1805 1806 1812 1813 1814 1819 1820 1821 1831 1842 1844 1847 1849 1859\n",
            " 1860 1866 1869 1873 1878 1880 1886 1892 1896 1898 1900 1910 1911 1912\n",
            " 1919 1920 1922 1926 1931 1934 1941 1943 1946 1947 1951 1952 1957 1971\n",
            " 1972 1974 1979 1982 1983 1986 1989 1995 2000 2004 2010 2013 2014 2015\n",
            " 2016 2020 2021 2022 2038 2041 2042 2044 2045 2047 2056 2057 2059 2071\n",
            " 2074 2088 2091 2096 2107 2108 2110 2111 2113 2114 2120 2121 2134 2136\n",
            " 2140 2141 2147 2148 2151 2158 2163 2165 2166 2169 2172 2173 2178 2185\n",
            " 2188 2189 2203 2208 2209 2213 2218 2226 2234 2235 2251 2254 2263 2264\n",
            " 2266 2269 2271 2277 2278 2280 2281 2287 2288 2293 2294 2296 2302 2305\n",
            " 2306 2308 2310 2312 2315 2316 2318 2319 2335 2353 2357 2363 2368 2369\n",
            " 2370 2372 2375 2378 2379 2380 2382 2384 2405 2407 2414 2417 2429 2434\n",
            " 2435 2445 2451 2452 2454 2455 2459 2460 2467 2468 2473 2475 2479 2485\n",
            " 2487 2488 2490 2501 2509 2524 2530 2533 2535 2537 2538 2540 2541 2542\n",
            " 2552 2556 2557 2562 2564 2565 2566 2578 2581 2582 2587 2588 2589 2595\n",
            " 2599 2604 2607 2610 2612 2614 2616 2621 2626 2627 2630 2631 2632 2633\n",
            " 2644 2646 2648 2651 2652 2653 2654 2657 2660 2664 2671 2678 2686 2692\n",
            " 2696 2697 2698 2703 2704 2706 2707 2709 2710 2711 2716 2725 2729 2731\n",
            " 2734 2735 2739 2747 2755 2757 2758 2767 2771 2775 2777 2781 2791 2796\n",
            " 2802 2805 2806 2808 2809 2811 2814 2816 2818 2824 2827 2829 2833 2835\n",
            " 2837 2846 2850 2855 2858 2861 2865 2871 2874 2875 2877 2878 2879 2883\n",
            " 2886 2890 2891]\n",
            "[CV 3/5; 4/10] END colsample_bylevel=0.5, colsample_bytree=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=-0.004 total time=   9.0s\n",
            "[CV 4/5; 4/10] START colsample_bylevel=0.5, colsample_bytree=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5\n",
            "[23:33:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    4   14   16   23   25   26   29   30   39   40   43   47   62\n",
            "   64   67   70   75   76   78   83   84   90   97   98  102  107  108\n",
            "  113  121  123  126  127  128  132  137  138  142  146  154  158  159\n",
            "  168  188  191  192  198  201  204  209  211  215  219  229  234  238\n",
            "  239  240  242  243  245  246  254  255  257  258  259  264  272  286\n",
            "  287  296  297  302  303  315  316  328  329  334  338  345  347  349\n",
            "  354  359  365  367  373  379  385  386  397  399  411  415  421  423\n",
            "  428  431  439  440  458  460  463  464  469  474  475  479  485  487\n",
            "  515  527  533  535  550  553  554  555  556  557  560  561  568  569\n",
            "  571  573  575  582  586  595  597  601  603  608  618  624  628  629\n",
            "  630  631  640  643  649  652  653  662  668  671  678  679  686  688\n",
            "  690  691  695  698  699  702  704  706  709  710  720  736  739  747\n",
            "  753  762  766  778  789  790  792  799  802  804  805  813  829  830\n",
            "  835  850  856  864  866  872  876  902  906  910  914  920  923  929\n",
            "  934  938  943  944  945  946  950  957  959  960  961  965  971  978\n",
            "  984  985  995  996  998  999 1000 1002 1005 1008 1012 1013 1014 1020\n",
            " 1036 1037 1049 1050 1059 1061 1062 1065 1066 1067 1070 1072 1074 1076\n",
            " 1082 1087 1090 1091 1093 1096 1101 1102 1104 1105 1112 1115 1118 1128\n",
            " 1134 1136 1141 1142 1143 1145 1150 1155 1163 1166 1181 1188 1189 1192\n",
            " 1193 1194 1198 1199 1200 1201 1202 1208 1209 1217 1222 1223 1225 1226\n",
            " 1229 1231 1232 1234 1238 1245 1247 1248 1249 1260 1261 1265 1266 1267\n",
            " 1269 1275 1276 1277 1289 1292 1302 1305 1310 1313 1314 1315 1317 1319\n",
            " 1321 1323 1324 1325 1328 1335 1344 1347 1349 1357 1361 1365 1369 1373\n",
            " 1379 1388 1391 1395 1397 1401 1407 1419 1421 1424 1426 1433 1438 1439\n",
            " 1441 1445 1461 1463 1464 1478 1482 1492 1493 1498 1499 1501 1503 1505\n",
            " 1511 1514 1516 1517 1519 1521 1524 1528 1529 1533 1534 1538 1539 1557\n",
            " 1558 1559 1579 1583 1587 1590 1602 1603 1613 1617 1619 1622 1626 1631\n",
            " 1641 1651 1654 1655 1657 1663 1668 1670 1688 1695 1706 1711 1712 1714\n",
            " 1719 1727 1728 1732 1734 1735 1736 1740 1746 1748 1761 1762 1767 1768\n",
            " 1778 1781 1783 1785 1788 1791 1795 1796 1802 1805 1810 1811 1813 1817\n",
            " 1818 1819 1822 1823 1839 1843 1862 1865 1873 1874 1875 1876 1877 1882\n",
            " 1887 1894 1896 1902 1905 1914 1915 1917 1925 1929 1931 1938 1939 1944\n",
            " 1952 1953 1954 1960 1965 1979 1980 1984 1986 1991 1993 1996 2001 2010\n",
            " 2011 2019 2024 2025 2032 2033 2036 2038 2040 2041 2042 2044 2047 2048\n",
            " 2051 2054 2056 2059 2069 2071 2078 2079 2080 2085 2087 2094 2097 2099\n",
            " 2104 2110 2115 2120 2121 2122 2129 2130 2135 2141 2143 2145 2148 2150\n",
            " 2157 2158 2160 2162 2166 2169 2175 2184 2195 2199 2202 2205 2213 2215\n",
            " 2217 2219 2220 2223 2224 2225 2228 2230 2231 2234 2235 2237 2248 2249\n",
            " 2253 2255 2257 2258 2259 2262 2277 2278 2282 2283 2291 2292 2297 2310\n",
            " 2314 2317 2320 2325 2326 2332 2337 2338 2340 2341 2343 2345 2349 2353\n",
            " 2354 2358 2360 2362 2376 2383 2384 2387 2390 2391 2396 2399 2400 2404\n",
            " 2408 2413 2415 2416 2417 2418 2421 2422 2427 2429 2432 2433 2450 2451\n",
            " 2454 2457 2458 2460 2461 2465 2467 2470 2471 2475 2480 2487 2494 2498\n",
            " 2502 2507 2523 2524 2531 2533 2536 2538 2543 2545 2547 2549 2551 2553\n",
            " 2554 2557 2561 2563 2567 2570 2571 2572 2579 2582 2583 2585 2586 2588\n",
            " 2594 2595 2609 2613 2615 2617 2620 2623 2624 2625 2632 2633 2640 2647\n",
            " 2649 2650 2655 2657 2662 2664 2668 2669 2671 2689 2699 2701 2704 2706\n",
            " 2707 2710 2717 2720 2723 2726 2733 2735 2736 2747 2754 2755 2757 2763\n",
            " 2771 2779 2786 2790 2791 2792 2796 2800 2802 2805 2809 2832 2840 2845\n",
            " 2846 2850 2855 2860 2861 2863 2869 2870 2876 2877 2879 2883 2887 2889]\n",
            "[CV 4/5; 4/10] END colsample_bylevel=0.5, colsample_bytree=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=-0.004 total time=   8.7s\n",
            "[CV 5/5; 4/10] START colsample_bylevel=0.5, colsample_bytree=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5\n",
            "[23:33:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   5   11   14   25   27   37   41   42   51   52   55   56   59   60\n",
            "   76   81   83   90   96  100  108  109  114  116  119  124  128  135\n",
            "  137  142  145  147  150  157  164  167  170  178  185  190  192  194\n",
            "  198  202  211  214  222  223  237  238  243  246  252  255  258  260\n",
            "  261  268  270  271  276  283  286  288  294  302  318  322  326  331\n",
            "  335  336  348  350  351  353  354  370  375  380  382  383  390  393\n",
            "  403  404  406  407  409  421  424  433  438  440  442  455  463  473\n",
            "  476  478  479  481  482  487  489  497  499  502  504  509  510  516\n",
            "  517  521  529  533  536  540  541  546  552  556  557  560  566  572\n",
            "  575  578  579  581  595  602  603  612  614  617  618  622  626  629\n",
            "  639  642  644  657  660  666  668  673  675  676  688  689  690  692\n",
            "  695  696  697  703  705  715  717  718  719  728  730  733  740  747\n",
            "  755  759  761  764  765  773  776  779  782  784  786  794  797  799\n",
            "  800  810  811  816  822  830  831  833  836  855  858  864  868  879\n",
            "  880  896  898  904  910  917  925  928  930  932  940  942  948  950\n",
            "  963  966  968  970  971  972  974  984  987  989  992  993  997 1002\n",
            " 1006 1010 1014 1023 1029 1032 1035 1041 1046 1050 1051 1057 1062 1063\n",
            " 1065 1067 1068 1069 1072 1076 1077 1088 1089 1093 1101 1107 1114 1118\n",
            " 1121 1128 1130 1131 1138 1139 1142 1144 1150 1151 1155 1161 1167 1175\n",
            " 1177 1181 1187 1194 1196 1199 1201 1202 1205 1222 1223 1225 1230 1231\n",
            " 1234 1246 1250 1252 1253 1255 1263 1270 1272 1273 1277 1279 1285 1289\n",
            " 1291 1297 1298 1303 1304 1306 1307 1311 1321 1328 1331 1336 1337 1341\n",
            " 1347 1355 1358 1364 1370 1372 1374 1376 1379 1380 1381 1383 1392 1394\n",
            " 1399 1404 1409 1412 1419 1420 1422 1431 1433 1437 1438 1441 1447 1448\n",
            " 1449 1454 1458 1459 1463 1465 1467 1468 1471 1486 1491 1497 1499 1501\n",
            " 1508 1509 1510 1514 1522 1524 1527 1533 1537 1542 1551 1554 1561 1563\n",
            " 1565 1567 1569 1571 1572 1574 1577 1581 1583 1584 1588 1595 1596 1598\n",
            " 1600 1608 1612 1617 1621 1624 1630 1635 1636 1637 1640 1643 1653 1656\n",
            " 1657 1661 1668 1672 1673 1676 1679 1681 1686 1687 1688 1696 1699 1701\n",
            " 1709 1710 1720 1722 1725 1726 1731 1733 1737 1738 1741 1746 1747 1749\n",
            " 1751 1754 1756 1763 1765 1772 1782 1783 1787 1788 1792 1796 1802 1809\n",
            " 1817 1819 1822 1834 1835 1848 1851 1860 1868 1876 1880 1893 1894 1900\n",
            " 1905 1929 1934 1938 1947 1948 1953 1956 1967 1969 1976 1978 1988 1989\n",
            " 1994 1995 1996 1999 2000 2005 2009 2011 2013 2020 2026 2027 2032 2045\n",
            " 2062 2063 2072 2074 2075 2081 2088 2089 2090 2099 2101 2110 2111 2117\n",
            " 2120 2129 2131 2132 2133 2138 2142 2143 2144 2147 2151 2153 2154 2166\n",
            " 2175 2178 2185 2188 2198 2202 2204 2206 2207 2209 2224 2230 2231 2237\n",
            " 2248 2249 2251 2258 2261 2262 2264 2272 2276 2280 2281 2282 2283 2285\n",
            " 2288 2295 2297 2300 2308 2314 2315 2316 2317 2320 2321 2327 2328 2332\n",
            " 2336 2337 2351 2359 2368 2370 2373 2383 2392 2394 2404 2405 2408 2410\n",
            " 2425 2435 2439 2440 2453 2458 2467 2470 2473 2478 2481 2483 2487 2489\n",
            " 2490 2499 2500 2505 2512 2513 2517 2522 2523 2524 2527 2528 2529 2533\n",
            " 2538 2541 2549 2551 2578 2589 2596 2601 2610 2627 2630 2633 2643 2645\n",
            " 2649 2653 2655 2672 2673 2679 2690 2692 2697 2698 2699 2705 2714 2718\n",
            " 2727 2732 2744 2745 2746 2747 2751 2757 2758 2761 2763 2767 2781 2782\n",
            " 2786 2789 2795 2801 2806 2810 2812 2814 2816 2818 2824 2826 2832 2833\n",
            " 2838 2841 2843 2844 2847 2850 2851 2853 2868 2871 2876 2878 2880 2881\n",
            " 2887 2888 2889 2892]\n",
            "[CV 5/5; 4/10] END colsample_bylevel=0.5, colsample_bytree=0.8999999999999999, learning_rate=0.1, max_depth=10, n_estimators=100, subsample=0.5;, score=-0.004 total time=   9.1s\n",
            "[CV 1/5; 5/10] START colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=20, n_estimators=100, subsample=0.5\n",
            "[23:34:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    8   11   17   19   20   23   33   34   36   39   43   47   52\n",
            "   55   65   67   70   74   76   78   80   85   87   89   97   98  102\n",
            "  108  109  111  114  117  119  121  123  124  128  130  135  138  140\n",
            "  149  162  169  171  174  175  177  180  188  189  190  192  195  202\n",
            "  212  224  227  234  235  237  238  242  243  245  247  248  251  252\n",
            "  257  262  264  267  271  274  275  277  279  280  287  292  297  304\n",
            "  306  307  314  319  327  332  334  336  340  345  346  347  350  352\n",
            "  354  358  368  375  379  381  385  388  390  391  394  395  402  404\n",
            "  412  418  422  423  424  428  430  438  443  447  450  459  468  477\n",
            "  479  484  485  486  488  495  499  511  522  529  532  534  536  541\n",
            "  543  560  562  563  568  570  577  586  589  590  594  599  603  613\n",
            "  615  617  624  625  627  634  635  639  645  650  667  676  679  689\n",
            "  690  691  695  696  700  703  707  715  718  720  726  728  730  733\n",
            "  737  749  755  759  763  764  765  773  774  779  786  798  802  808\n",
            "  822  824  829  832  836  852  856  862  865  867  870  872  873  874\n",
            "  884  888  893  894  899  900  917  920  922  923  926  940  941  944\n",
            "  959  965  968  974  976  978  979  981  983  989  990  991  995  996\n",
            " 1001 1009 1012 1015 1025 1028 1038 1044 1049 1070 1071 1079 1080 1081\n",
            " 1083 1089 1090 1096 1098 1104 1105 1111 1113 1120 1121 1123 1125 1127\n",
            " 1131 1135 1141 1145 1151 1154 1156 1157 1158 1163 1164 1166 1179 1183\n",
            " 1192 1195 1202 1205 1206 1209 1210 1224 1226 1239 1240 1245 1256 1259\n",
            " 1260 1262 1263 1270 1273 1280 1288 1289 1292 1295 1296 1300 1304 1309\n",
            " 1322 1330 1332 1338 1340 1343 1346 1358 1363 1377 1378 1380 1383 1384\n",
            " 1391 1393 1401 1402 1403 1410 1417 1418 1422 1438 1444 1445 1450 1453\n",
            " 1455 1456 1464 1466 1468 1469 1475 1482 1489 1491 1494 1499 1505 1513\n",
            " 1528 1532 1535 1536 1537 1538 1539 1545 1551 1554 1555 1557 1559 1561\n",
            " 1562 1565 1566 1573 1579 1588 1597 1599 1602 1607 1609 1612 1614 1615\n",
            " 1618 1622 1625 1630 1631 1643 1645 1649 1650 1656 1675 1676 1679 1684\n",
            " 1685 1691 1697 1701 1705 1706 1707 1709 1716 1726 1727 1728 1740 1742\n",
            " 1748 1751 1753 1763 1768 1769 1770 1786 1794 1798 1799 1801 1804 1812\n",
            " 1814 1821 1822 1825 1835 1841 1842 1846 1848 1856 1857 1874 1875 1879\n",
            " 1880 1892 1907 1917 1927 1930 1940 1942 1949 1952 1957 1966 1971 1974\n",
            " 1975 1976 1979 1981 1984 1987 1989 1992 1993 1995 2002 2003 2007 2010\n",
            " 2015 2027 2028 2029 2031 2035 2037 2049 2054 2056 2060 2061 2066 2070\n",
            " 2071 2075 2076 2082 2085 2087 2094 2098 2110 2111 2112 2113 2122 2123\n",
            " 2141 2142 2145 2157 2162 2166 2167 2172 2177 2180 2181 2183 2186 2195\n",
            " 2202 2209 2213 2215 2219 2220 2222 2224 2232 2233 2240 2244 2246 2248\n",
            " 2253 2259 2266 2276 2277 2280 2282 2284 2291 2298 2309 2311 2313 2322\n",
            " 2338 2339 2340 2341 2346 2347 2348 2350 2361 2363 2364 2365 2366 2369\n",
            " 2374 2375 2380 2382 2385 2386 2396 2406 2410 2413 2416 2420 2422 2427\n",
            " 2436 2438 2439 2440 2441 2444 2445 2448 2449 2453 2456 2459 2461 2463\n",
            " 2464 2469 2472 2474 2483 2494 2498 2505 2507 2509 2514 2517 2522 2524\n",
            " 2526 2531 2538 2547 2550 2554 2557 2561 2566 2571 2574 2577 2581 2585\n",
            " 2590 2594 2600 2603 2606 2612 2618 2620 2622 2625 2633 2642 2647 2654\n",
            " 2655 2656 2661 2665 2669 2671 2672 2677 2684 2694 2700 2701 2704 2706\n",
            " 2709 2712 2713 2714 2715 2725 2727 2730 2735 2738 2742 2743 2748 2756\n",
            " 2760 2763 2767 2772 2774 2776 2779 2781 2785 2786 2790 2792 2805 2806\n",
            " 2807 2810 2820 2827 2832 2841 2847 2852 2857 2862 2865 2867 2871 2873\n",
            " 2878 2881 2884 2887 2889]\n",
            "[CV 1/5; 5/10] END colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=20, n_estimators=100, subsample=0.5;, score=-0.028 total time=  22.1s\n",
            "[CV 2/5; 5/10] START colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=20, n_estimators=100, subsample=0.5\n",
            "[23:34:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   3    5    7   12   14   20   22   25   27   31   32   33   43   47\n",
            "   51   62   64   69   70   71   74   76   88   89  109  111  113  115\n",
            "  125  133  137  141  143  145  148  156  159  174  175  176  180  190\n",
            "  191  195  199  200  203  205  207  209  210  212  213  215  220  227\n",
            "  231  238  252  258  262  268  269  272  310  311  314  315  332  334\n",
            "  356  361  362  363  364  367  368  369  371  373  377  380  384  385\n",
            "  390  399  403  407  409  410  417  429  431  435  444  449  464  465\n",
            "  466  467  470  474  475  480  489  490  492  493  498  499  501  505\n",
            "  509  512  513  517  518  521  524  529  533  534  537  539  541  545\n",
            "  549  550  558  560  564  573  574  577  580  584  585  586  587  594\n",
            "  598  605  606  612  624  627  628  630  642  647  649  651  663  665\n",
            "  679  680  691  696  701  710  711  716  727  731  733  736  744  750\n",
            "  751  759  760  763  765  771  773  776  780  789  794  806  809  812\n",
            "  814  820  821  833  838  844  855  859  866  868  884  890  894  902\n",
            "  905  907  909  916  917  921  922  931  934  937  958  968  969  973\n",
            "  979  981  990 1004 1010 1014 1015 1018 1033 1036 1037 1038 1040 1042\n",
            " 1043 1049 1068 1069 1076 1081 1084 1088 1090 1092 1094 1097 1100 1101\n",
            " 1105 1107 1116 1118 1123 1124 1128 1133 1141 1151 1152 1153 1161 1162\n",
            " 1164 1178 1179 1181 1189 1193 1197 1202 1209 1214 1221 1237 1241 1244\n",
            " 1245 1250 1253 1254 1258 1261 1262 1264 1266 1267 1268 1269 1270 1272\n",
            " 1276 1283 1287 1292 1293 1295 1303 1304 1310 1312 1316 1319 1328 1336\n",
            " 1341 1343 1344 1346 1351 1356 1374 1375 1378 1379 1383 1389 1397 1398\n",
            " 1399 1401 1404 1408 1413 1420 1437 1439 1440 1441 1446 1447 1450 1451\n",
            " 1458 1461 1475 1479 1481 1487 1488 1493 1504 1505 1506 1511 1512 1529\n",
            " 1532 1533 1537 1538 1541 1549 1550 1553 1559 1560 1565 1570 1571 1572\n",
            " 1573 1586 1588 1601 1607 1610 1611 1613 1614 1620 1626 1627 1634 1641\n",
            " 1647 1653 1658 1665 1672 1681 1684 1686 1696 1697 1705 1708 1720 1721\n",
            " 1725 1727 1738 1739 1742 1743 1751 1757 1762 1764 1769 1770 1773 1775\n",
            " 1779 1783 1786 1787 1789 1800 1803 1807 1809 1812 1821 1829 1836 1837\n",
            " 1839 1844 1855 1857 1875 1877 1879 1887 1889 1894 1897 1900 1902 1903\n",
            " 1907 1908 1917 1921 1923 1937 1947 1948 1951 1953 1956 1957 1959 1961\n",
            " 1964 1967 1968 1970 1974 1975 1981 1983 1986 1987 1994 1998 2003 2007\n",
            " 2009 2011 2013 2015 2020 2029 2036 2037 2041 2043 2045 2046 2047 2057\n",
            " 2058 2064 2070 2082 2086 2088 2089 2090 2093 2095 2101 2104 2110 2111\n",
            " 2113 2114 2115 2118 2119 2127 2134 2139 2141 2146 2147 2149 2150 2157\n",
            " 2159 2161 2166 2167 2169 2178 2182 2188 2197 2201 2207 2215 2217 2219\n",
            " 2222 2223 2224 2225 2231 2232 2233 2241 2245 2257 2262 2272 2291 2292\n",
            " 2293 2294 2296 2306 2307 2308 2309 2314 2340 2346 2347 2348 2353 2359\n",
            " 2369 2373 2380 2381 2382 2386 2393 2396 2401 2402 2403 2409 2411 2414\n",
            " 2419 2424 2431 2432 2433 2436 2437 2445 2450 2451 2452 2458 2460 2462\n",
            " 2463 2466 2471 2476 2494 2496 2503 2507 2510 2528 2530 2534 2535 2536\n",
            " 2538 2540 2542 2553 2554 2558 2559 2564 2571 2572 2574 2575 2582 2592\n",
            " 2594 2605 2612 2620 2623 2637 2643 2654 2657 2668 2677 2678 2680 2683\n",
            " 2690 2691 2693 2696 2700 2702 2705 2707 2708 2713 2717 2724 2727 2733\n",
            " 2735 2737 2748 2752 2753 2755 2765 2772 2775 2776 2781 2797 2800 2805\n",
            " 2806 2812 2813 2814 2815 2822 2831 2832 2835 2839 2843 2851 2855 2856\n",
            " 2859 2871 2872 2873 2884 2885 2886 2890 2892]\n",
            "[CV 2/5; 5/10] END colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=20, n_estimators=100, subsample=0.5;, score=-0.028 total time=  22.3s\n",
            "[CV 3/5; 5/10] START colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=20, n_estimators=100, subsample=0.5\n",
            "[23:34:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   4   11   30   35   36   37   41   54   63   66   69   76   87   97\n",
            "   98  102  106  130  131  133  134  142  148  149  159  161  165  176\n",
            "  178  187  190  191  194  201  202  206  224  226  227  232  238  246\n",
            "  248  250  256  259  261  264  270  271  274  278  279  287  288  290\n",
            "  303  304  307  313  314  316  318  322  324  327  334  335  339  346\n",
            "  347  349  358  367  369  373  374  375  376  377  378  390  391  393\n",
            "  394  397  398  411  420  421  423  428  429  435  442  443  448  450\n",
            "  457  461  464  465  467  469  474  493  497  499  500  501  503  520\n",
            "  529  530  545  547  553  561  562  567  569  570  573  586  592  597\n",
            "  598  599  603  604  605  611  625  629  630  633  636  640  645  654\n",
            "  658  662  670  675  678  686  690  692  697  699  702  707  710  718\n",
            "  719  725  731  732  733  738  745  746  752  777  782  784  788  790\n",
            "  793  794  797  798  800  802  804  813  824  825  826  832  836  852\n",
            "  856  859  861  864  868  871  878  885  889  891  896  904  911  913\n",
            "  917  923  927  952  958  962  969  974  976  979  986  988  989  990\n",
            "  997  998  999 1001 1008 1009 1029 1034 1041 1048 1052 1056 1061 1069\n",
            " 1072 1073 1080 1082 1091 1092 1099 1101 1111 1115 1120 1123 1124 1130\n",
            " 1134 1137 1144 1150 1152 1156 1168 1171 1173 1179 1183 1188 1196 1200\n",
            " 1202 1203 1205 1212 1214 1215 1222 1255 1256 1257 1262 1273 1279 1281\n",
            " 1287 1291 1306 1307 1310 1314 1315 1320 1324 1326 1329 1330 1332 1336\n",
            " 1346 1349 1351 1352 1353 1354 1365 1394 1397 1398 1400 1405 1407 1411\n",
            " 1423 1432 1434 1442 1445 1448 1449 1467 1469 1472 1490 1494 1495 1510\n",
            " 1516 1519 1521 1522 1526 1533 1547 1548 1551 1553 1574 1581 1583 1585\n",
            " 1589 1590 1598 1601 1611 1613 1614 1619 1622 1623 1637 1642 1647 1649\n",
            " 1650 1660 1667 1671 1673 1677 1682 1684 1695 1696 1697 1705 1723 1725\n",
            " 1727 1730 1732 1734 1742 1749 1772 1781 1782 1786 1795 1798 1802 1804\n",
            " 1805 1806 1812 1813 1814 1819 1820 1821 1831 1842 1844 1847 1849 1859\n",
            " 1860 1866 1869 1873 1878 1880 1886 1892 1896 1898 1900 1910 1911 1912\n",
            " 1919 1920 1922 1926 1931 1934 1941 1943 1946 1947 1951 1952 1957 1971\n",
            " 1972 1974 1979 1982 1983 1986 1989 1995 2000 2004 2010 2013 2014 2015\n",
            " 2016 2020 2021 2022 2038 2041 2042 2044 2045 2047 2056 2057 2059 2071\n",
            " 2074 2088 2091 2096 2107 2108 2110 2111 2113 2114 2120 2121 2134 2136\n",
            " 2140 2141 2147 2148 2151 2158 2163 2165 2166 2169 2172 2173 2178 2185\n",
            " 2188 2189 2203 2208 2209 2213 2218 2226 2234 2235 2251 2254 2263 2264\n",
            " 2266 2269 2271 2277 2278 2280 2281 2287 2288 2293 2294 2296 2302 2305\n",
            " 2306 2308 2310 2312 2315 2316 2318 2319 2335 2353 2357 2363 2368 2369\n",
            " 2370 2372 2375 2378 2379 2380 2382 2384 2405 2407 2414 2417 2429 2434\n",
            " 2435 2445 2451 2452 2454 2455 2459 2460 2467 2468 2473 2475 2479 2485\n",
            " 2487 2488 2490 2501 2509 2524 2530 2533 2535 2537 2538 2540 2541 2542\n",
            " 2552 2556 2557 2562 2564 2565 2566 2578 2581 2582 2587 2588 2589 2595\n",
            " 2599 2604 2607 2610 2612 2614 2616 2621 2626 2627 2630 2631 2632 2633\n",
            " 2644 2646 2648 2651 2652 2653 2654 2657 2660 2664 2671 2678 2686 2692\n",
            " 2696 2697 2698 2703 2704 2706 2707 2709 2710 2711 2716 2725 2729 2731\n",
            " 2734 2735 2739 2747 2755 2757 2758 2767 2771 2775 2777 2781 2791 2796\n",
            " 2802 2805 2806 2808 2809 2811 2814 2816 2818 2824 2827 2829 2833 2835\n",
            " 2837 2846 2850 2855 2858 2861 2865 2871 2874 2875 2877 2878 2879 2883\n",
            " 2886 2890 2891]\n",
            "[CV 3/5; 5/10] END colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=20, n_estimators=100, subsample=0.5;, score=-0.027 total time=  22.4s\n",
            "[CV 4/5; 5/10] START colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=20, n_estimators=100, subsample=0.5\n",
            "[23:35:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    4   14   16   23   25   26   29   30   39   40   43   47   62\n",
            "   64   67   70   75   76   78   83   84   90   97   98  102  107  108\n",
            "  113  121  123  126  127  128  132  137  138  142  146  154  158  159\n",
            "  168  188  191  192  198  201  204  209  211  215  219  229  234  238\n",
            "  239  240  242  243  245  246  254  255  257  258  259  264  272  286\n",
            "  287  296  297  302  303  315  316  328  329  334  338  345  347  349\n",
            "  354  359  365  367  373  379  385  386  397  399  411  415  421  423\n",
            "  428  431  439  440  458  460  463  464  469  474  475  479  485  487\n",
            "  515  527  533  535  550  553  554  555  556  557  560  561  568  569\n",
            "  571  573  575  582  586  595  597  601  603  608  618  624  628  629\n",
            "  630  631  640  643  649  652  653  662  668  671  678  679  686  688\n",
            "  690  691  695  698  699  702  704  706  709  710  720  736  739  747\n",
            "  753  762  766  778  789  790  792  799  802  804  805  813  829  830\n",
            "  835  850  856  864  866  872  876  902  906  910  914  920  923  929\n",
            "  934  938  943  944  945  946  950  957  959  960  961  965  971  978\n",
            "  984  985  995  996  998  999 1000 1002 1005 1008 1012 1013 1014 1020\n",
            " 1036 1037 1049 1050 1059 1061 1062 1065 1066 1067 1070 1072 1074 1076\n",
            " 1082 1087 1090 1091 1093 1096 1101 1102 1104 1105 1112 1115 1118 1128\n",
            " 1134 1136 1141 1142 1143 1145 1150 1155 1163 1166 1181 1188 1189 1192\n",
            " 1193 1194 1198 1199 1200 1201 1202 1208 1209 1217 1222 1223 1225 1226\n",
            " 1229 1231 1232 1234 1238 1245 1247 1248 1249 1260 1261 1265 1266 1267\n",
            " 1269 1275 1276 1277 1289 1292 1302 1305 1310 1313 1314 1315 1317 1319\n",
            " 1321 1323 1324 1325 1328 1335 1344 1347 1349 1357 1361 1365 1369 1373\n",
            " 1379 1388 1391 1395 1397 1401 1407 1419 1421 1424 1426 1433 1438 1439\n",
            " 1441 1445 1461 1463 1464 1478 1482 1492 1493 1498 1499 1501 1503 1505\n",
            " 1511 1514 1516 1517 1519 1521 1524 1528 1529 1533 1534 1538 1539 1557\n",
            " 1558 1559 1579 1583 1587 1590 1602 1603 1613 1617 1619 1622 1626 1631\n",
            " 1641 1651 1654 1655 1657 1663 1668 1670 1688 1695 1706 1711 1712 1714\n",
            " 1719 1727 1728 1732 1734 1735 1736 1740 1746 1748 1761 1762 1767 1768\n",
            " 1778 1781 1783 1785 1788 1791 1795 1796 1802 1805 1810 1811 1813 1817\n",
            " 1818 1819 1822 1823 1839 1843 1862 1865 1873 1874 1875 1876 1877 1882\n",
            " 1887 1894 1896 1902 1905 1914 1915 1917 1925 1929 1931 1938 1939 1944\n",
            " 1952 1953 1954 1960 1965 1979 1980 1984 1986 1991 1993 1996 2001 2010\n",
            " 2011 2019 2024 2025 2032 2033 2036 2038 2040 2041 2042 2044 2047 2048\n",
            " 2051 2054 2056 2059 2069 2071 2078 2079 2080 2085 2087 2094 2097 2099\n",
            " 2104 2110 2115 2120 2121 2122 2129 2130 2135 2141 2143 2145 2148 2150\n",
            " 2157 2158 2160 2162 2166 2169 2175 2184 2195 2199 2202 2205 2213 2215\n",
            " 2217 2219 2220 2223 2224 2225 2228 2230 2231 2234 2235 2237 2248 2249\n",
            " 2253 2255 2257 2258 2259 2262 2277 2278 2282 2283 2291 2292 2297 2310\n",
            " 2314 2317 2320 2325 2326 2332 2337 2338 2340 2341 2343 2345 2349 2353\n",
            " 2354 2358 2360 2362 2376 2383 2384 2387 2390 2391 2396 2399 2400 2404\n",
            " 2408 2413 2415 2416 2417 2418 2421 2422 2427 2429 2432 2433 2450 2451\n",
            " 2454 2457 2458 2460 2461 2465 2467 2470 2471 2475 2480 2487 2494 2498\n",
            " 2502 2507 2523 2524 2531 2533 2536 2538 2543 2545 2547 2549 2551 2553\n",
            " 2554 2557 2561 2563 2567 2570 2571 2572 2579 2582 2583 2585 2586 2588\n",
            " 2594 2595 2609 2613 2615 2617 2620 2623 2624 2625 2632 2633 2640 2647\n",
            " 2649 2650 2655 2657 2662 2664 2668 2669 2671 2689 2699 2701 2704 2706\n",
            " 2707 2710 2717 2720 2723 2726 2733 2735 2736 2747 2754 2755 2757 2763\n",
            " 2771 2779 2786 2790 2791 2792 2796 2800 2802 2805 2809 2832 2840 2845\n",
            " 2846 2850 2855 2860 2861 2863 2869 2870 2876 2877 2879 2883 2887 2889]\n",
            "[CV 4/5; 5/10] END colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=20, n_estimators=100, subsample=0.5;, score=-0.028 total time=  22.0s\n",
            "[CV 5/5; 5/10] START colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=20, n_estimators=100, subsample=0.5\n",
            "[23:35:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   5   11   14   25   27   37   41   42   51   52   55   56   59   60\n",
            "   76   81   83   90   96  100  108  109  114  116  119  124  128  135\n",
            "  137  142  145  147  150  157  164  167  170  178  185  190  192  194\n",
            "  198  202  211  214  222  223  237  238  243  246  252  255  258  260\n",
            "  261  268  270  271  276  283  286  288  294  302  318  322  326  331\n",
            "  335  336  348  350  351  353  354  370  375  380  382  383  390  393\n",
            "  403  404  406  407  409  421  424  433  438  440  442  455  463  473\n",
            "  476  478  479  481  482  487  489  497  499  502  504  509  510  516\n",
            "  517  521  529  533  536  540  541  546  552  556  557  560  566  572\n",
            "  575  578  579  581  595  602  603  612  614  617  618  622  626  629\n",
            "  639  642  644  657  660  666  668  673  675  676  688  689  690  692\n",
            "  695  696  697  703  705  715  717  718  719  728  730  733  740  747\n",
            "  755  759  761  764  765  773  776  779  782  784  786  794  797  799\n",
            "  800  810  811  816  822  830  831  833  836  855  858  864  868  879\n",
            "  880  896  898  904  910  917  925  928  930  932  940  942  948  950\n",
            "  963  966  968  970  971  972  974  984  987  989  992  993  997 1002\n",
            " 1006 1010 1014 1023 1029 1032 1035 1041 1046 1050 1051 1057 1062 1063\n",
            " 1065 1067 1068 1069 1072 1076 1077 1088 1089 1093 1101 1107 1114 1118\n",
            " 1121 1128 1130 1131 1138 1139 1142 1144 1150 1151 1155 1161 1167 1175\n",
            " 1177 1181 1187 1194 1196 1199 1201 1202 1205 1222 1223 1225 1230 1231\n",
            " 1234 1246 1250 1252 1253 1255 1263 1270 1272 1273 1277 1279 1285 1289\n",
            " 1291 1297 1298 1303 1304 1306 1307 1311 1321 1328 1331 1336 1337 1341\n",
            " 1347 1355 1358 1364 1370 1372 1374 1376 1379 1380 1381 1383 1392 1394\n",
            " 1399 1404 1409 1412 1419 1420 1422 1431 1433 1437 1438 1441 1447 1448\n",
            " 1449 1454 1458 1459 1463 1465 1467 1468 1471 1486 1491 1497 1499 1501\n",
            " 1508 1509 1510 1514 1522 1524 1527 1533 1537 1542 1551 1554 1561 1563\n",
            " 1565 1567 1569 1571 1572 1574 1577 1581 1583 1584 1588 1595 1596 1598\n",
            " 1600 1608 1612 1617 1621 1624 1630 1635 1636 1637 1640 1643 1653 1656\n",
            " 1657 1661 1668 1672 1673 1676 1679 1681 1686 1687 1688 1696 1699 1701\n",
            " 1709 1710 1720 1722 1725 1726 1731 1733 1737 1738 1741 1746 1747 1749\n",
            " 1751 1754 1756 1763 1765 1772 1782 1783 1787 1788 1792 1796 1802 1809\n",
            " 1817 1819 1822 1834 1835 1848 1851 1860 1868 1876 1880 1893 1894 1900\n",
            " 1905 1929 1934 1938 1947 1948 1953 1956 1967 1969 1976 1978 1988 1989\n",
            " 1994 1995 1996 1999 2000 2005 2009 2011 2013 2020 2026 2027 2032 2045\n",
            " 2062 2063 2072 2074 2075 2081 2088 2089 2090 2099 2101 2110 2111 2117\n",
            " 2120 2129 2131 2132 2133 2138 2142 2143 2144 2147 2151 2153 2154 2166\n",
            " 2175 2178 2185 2188 2198 2202 2204 2206 2207 2209 2224 2230 2231 2237\n",
            " 2248 2249 2251 2258 2261 2262 2264 2272 2276 2280 2281 2282 2283 2285\n",
            " 2288 2295 2297 2300 2308 2314 2315 2316 2317 2320 2321 2327 2328 2332\n",
            " 2336 2337 2351 2359 2368 2370 2373 2383 2392 2394 2404 2405 2408 2410\n",
            " 2425 2435 2439 2440 2453 2458 2467 2470 2473 2478 2481 2483 2487 2489\n",
            " 2490 2499 2500 2505 2512 2513 2517 2522 2523 2524 2527 2528 2529 2533\n",
            " 2538 2541 2549 2551 2578 2589 2596 2601 2610 2627 2630 2633 2643 2645\n",
            " 2649 2653 2655 2672 2673 2679 2690 2692 2697 2698 2699 2705 2714 2718\n",
            " 2727 2732 2744 2745 2746 2747 2751 2757 2758 2761 2763 2767 2781 2782\n",
            " 2786 2789 2795 2801 2806 2810 2812 2814 2816 2818 2824 2826 2832 2833\n",
            " 2838 2841 2843 2844 2847 2850 2851 2853 2868 2871 2876 2878 2880 2881\n",
            " 2887 2888 2889 2892]\n",
            "[CV 5/5; 5/10] END colsample_bylevel=0.5, colsample_bytree=0.7999999999999999, learning_rate=0.01, max_depth=20, n_estimators=100, subsample=0.5;, score=-0.028 total time=  22.3s\n",
            "[CV 1/5; 6/10] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, learning_rate=0.5, max_depth=5, n_estimators=500, subsample=0.7999999999999999\n",
            "[23:35:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    8   11   17   19   20   23   33   34   36   39   43   47   52\n",
            "   55   65   67   70   74   76   78   80   85   87   89   97   98  102\n",
            "  108  109  111  114  117  119  121  123  124  128  130  135  138  140\n",
            "  149  162  169  171  174  175  177  180  188  189  190  192  195  202\n",
            "  212  224  227  234  235  237  238  242  243  245  247  248  251  252\n",
            "  257  262  264  267  271  274  275  277  279  280  287  292  297  304\n",
            "  306  307  314  319  327  332  334  336  340  345  346  347  350  352\n",
            "  354  358  368  375  379  381  385  388  390  391  394  395  402  404\n",
            "  412  418  422  423  424  428  430  438  443  447  450  459  468  477\n",
            "  479  484  485  486  488  495  499  511  522  529  532  534  536  541\n",
            "  543  560  562  563  568  570  577  586  589  590  594  599  603  613\n",
            "  615  617  624  625  627  634  635  639  645  650  667  676  679  689\n",
            "  690  691  695  696  700  703  707  715  718  720  726  728  730  733\n",
            "  737  749  755  759  763  764  765  773  774  779  786  798  802  808\n",
            "  822  824  829  832  836  852  856  862  865  867  870  872  873  874\n",
            "  884  888  893  894  899  900  917  920  922  923  926  940  941  944\n",
            "  959  965  968  974  976  978  979  981  983  989  990  991  995  996\n",
            " 1001 1009 1012 1015 1025 1028 1038 1044 1049 1070 1071 1079 1080 1081\n",
            " 1083 1089 1090 1096 1098 1104 1105 1111 1113 1120 1121 1123 1125 1127\n",
            " 1131 1135 1141 1145 1151 1154 1156 1157 1158 1163 1164 1166 1179 1183\n",
            " 1192 1195 1202 1205 1206 1209 1210 1224 1226 1239 1240 1245 1256 1259\n",
            " 1260 1262 1263 1270 1273 1280 1288 1289 1292 1295 1296 1300 1304 1309\n",
            " 1322 1330 1332 1338 1340 1343 1346 1358 1363 1377 1378 1380 1383 1384\n",
            " 1391 1393 1401 1402 1403 1410 1417 1418 1422 1438 1444 1445 1450 1453\n",
            " 1455 1456 1464 1466 1468 1469 1475 1482 1489 1491 1494 1499 1505 1513\n",
            " 1528 1532 1535 1536 1537 1538 1539 1545 1551 1554 1555 1557 1559 1561\n",
            " 1562 1565 1566 1573 1579 1588 1597 1599 1602 1607 1609 1612 1614 1615\n",
            " 1618 1622 1625 1630 1631 1643 1645 1649 1650 1656 1675 1676 1679 1684\n",
            " 1685 1691 1697 1701 1705 1706 1707 1709 1716 1726 1727 1728 1740 1742\n",
            " 1748 1751 1753 1763 1768 1769 1770 1786 1794 1798 1799 1801 1804 1812\n",
            " 1814 1821 1822 1825 1835 1841 1842 1846 1848 1856 1857 1874 1875 1879\n",
            " 1880 1892 1907 1917 1927 1930 1940 1942 1949 1952 1957 1966 1971 1974\n",
            " 1975 1976 1979 1981 1984 1987 1989 1992 1993 1995 2002 2003 2007 2010\n",
            " 2015 2027 2028 2029 2031 2035 2037 2049 2054 2056 2060 2061 2066 2070\n",
            " 2071 2075 2076 2082 2085 2087 2094 2098 2110 2111 2112 2113 2122 2123\n",
            " 2141 2142 2145 2157 2162 2166 2167 2172 2177 2180 2181 2183 2186 2195\n",
            " 2202 2209 2213 2215 2219 2220 2222 2224 2232 2233 2240 2244 2246 2248\n",
            " 2253 2259 2266 2276 2277 2280 2282 2284 2291 2298 2309 2311 2313 2322\n",
            " 2338 2339 2340 2341 2346 2347 2348 2350 2361 2363 2364 2365 2366 2369\n",
            " 2374 2375 2380 2382 2385 2386 2396 2406 2410 2413 2416 2420 2422 2427\n",
            " 2436 2438 2439 2440 2441 2444 2445 2448 2449 2453 2456 2459 2461 2463\n",
            " 2464 2469 2472 2474 2483 2494 2498 2505 2507 2509 2514 2517 2522 2524\n",
            " 2526 2531 2538 2547 2550 2554 2557 2561 2566 2571 2574 2577 2581 2585\n",
            " 2590 2594 2600 2603 2606 2612 2618 2620 2622 2625 2633 2642 2647 2654\n",
            " 2655 2656 2661 2665 2669 2671 2672 2677 2684 2694 2700 2701 2704 2706\n",
            " 2709 2712 2713 2714 2715 2725 2727 2730 2735 2738 2742 2743 2748 2756\n",
            " 2760 2763 2767 2772 2774 2776 2779 2781 2785 2786 2790 2792 2805 2806\n",
            " 2807 2810 2820 2827 2832 2841 2847 2852 2857 2862 2865 2867 2871 2873\n",
            " 2878 2881 2884 2887 2889]\n",
            "[CV 1/5; 6/10] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, learning_rate=0.5, max_depth=5, n_estimators=500, subsample=0.7999999999999999;, score=-0.021 total time=  12.0s\n",
            "[CV 2/5; 6/10] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, learning_rate=0.5, max_depth=5, n_estimators=500, subsample=0.7999999999999999\n",
            "[23:36:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   3    5    7   12   14   20   22   25   27   31   32   33   43   47\n",
            "   51   62   64   69   70   71   74   76   88   89  109  111  113  115\n",
            "  125  133  137  141  143  145  148  156  159  174  175  176  180  190\n",
            "  191  195  199  200  203  205  207  209  210  212  213  215  220  227\n",
            "  231  238  252  258  262  268  269  272  310  311  314  315  332  334\n",
            "  356  361  362  363  364  367  368  369  371  373  377  380  384  385\n",
            "  390  399  403  407  409  410  417  429  431  435  444  449  464  465\n",
            "  466  467  470  474  475  480  489  490  492  493  498  499  501  505\n",
            "  509  512  513  517  518  521  524  529  533  534  537  539  541  545\n",
            "  549  550  558  560  564  573  574  577  580  584  585  586  587  594\n",
            "  598  605  606  612  624  627  628  630  642  647  649  651  663  665\n",
            "  679  680  691  696  701  710  711  716  727  731  733  736  744  750\n",
            "  751  759  760  763  765  771  773  776  780  789  794  806  809  812\n",
            "  814  820  821  833  838  844  855  859  866  868  884  890  894  902\n",
            "  905  907  909  916  917  921  922  931  934  937  958  968  969  973\n",
            "  979  981  990 1004 1010 1014 1015 1018 1033 1036 1037 1038 1040 1042\n",
            " 1043 1049 1068 1069 1076 1081 1084 1088 1090 1092 1094 1097 1100 1101\n",
            " 1105 1107 1116 1118 1123 1124 1128 1133 1141 1151 1152 1153 1161 1162\n",
            " 1164 1178 1179 1181 1189 1193 1197 1202 1209 1214 1221 1237 1241 1244\n",
            " 1245 1250 1253 1254 1258 1261 1262 1264 1266 1267 1268 1269 1270 1272\n",
            " 1276 1283 1287 1292 1293 1295 1303 1304 1310 1312 1316 1319 1328 1336\n",
            " 1341 1343 1344 1346 1351 1356 1374 1375 1378 1379 1383 1389 1397 1398\n",
            " 1399 1401 1404 1408 1413 1420 1437 1439 1440 1441 1446 1447 1450 1451\n",
            " 1458 1461 1475 1479 1481 1487 1488 1493 1504 1505 1506 1511 1512 1529\n",
            " 1532 1533 1537 1538 1541 1549 1550 1553 1559 1560 1565 1570 1571 1572\n",
            " 1573 1586 1588 1601 1607 1610 1611 1613 1614 1620 1626 1627 1634 1641\n",
            " 1647 1653 1658 1665 1672 1681 1684 1686 1696 1697 1705 1708 1720 1721\n",
            " 1725 1727 1738 1739 1742 1743 1751 1757 1762 1764 1769 1770 1773 1775\n",
            " 1779 1783 1786 1787 1789 1800 1803 1807 1809 1812 1821 1829 1836 1837\n",
            " 1839 1844 1855 1857 1875 1877 1879 1887 1889 1894 1897 1900 1902 1903\n",
            " 1907 1908 1917 1921 1923 1937 1947 1948 1951 1953 1956 1957 1959 1961\n",
            " 1964 1967 1968 1970 1974 1975 1981 1983 1986 1987 1994 1998 2003 2007\n",
            " 2009 2011 2013 2015 2020 2029 2036 2037 2041 2043 2045 2046 2047 2057\n",
            " 2058 2064 2070 2082 2086 2088 2089 2090 2093 2095 2101 2104 2110 2111\n",
            " 2113 2114 2115 2118 2119 2127 2134 2139 2141 2146 2147 2149 2150 2157\n",
            " 2159 2161 2166 2167 2169 2178 2182 2188 2197 2201 2207 2215 2217 2219\n",
            " 2222 2223 2224 2225 2231 2232 2233 2241 2245 2257 2262 2272 2291 2292\n",
            " 2293 2294 2296 2306 2307 2308 2309 2314 2340 2346 2347 2348 2353 2359\n",
            " 2369 2373 2380 2381 2382 2386 2393 2396 2401 2402 2403 2409 2411 2414\n",
            " 2419 2424 2431 2432 2433 2436 2437 2445 2450 2451 2452 2458 2460 2462\n",
            " 2463 2466 2471 2476 2494 2496 2503 2507 2510 2528 2530 2534 2535 2536\n",
            " 2538 2540 2542 2553 2554 2558 2559 2564 2571 2572 2574 2575 2582 2592\n",
            " 2594 2605 2612 2620 2623 2637 2643 2654 2657 2668 2677 2678 2680 2683\n",
            " 2690 2691 2693 2696 2700 2702 2705 2707 2708 2713 2717 2724 2727 2733\n",
            " 2735 2737 2748 2752 2753 2755 2765 2772 2775 2776 2781 2797 2800 2805\n",
            " 2806 2812 2813 2814 2815 2822 2831 2832 2835 2839 2843 2851 2855 2856\n",
            " 2859 2871 2872 2873 2884 2885 2886 2890 2892]\n",
            "[CV 2/5; 6/10] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, learning_rate=0.5, max_depth=5, n_estimators=500, subsample=0.7999999999999999;, score=nan total time=  11.9s\n",
            "[CV 3/5; 6/10] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, learning_rate=0.5, max_depth=5, n_estimators=500, subsample=0.7999999999999999\n",
            "[23:36:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"<ipython-input-32-fc5a6eefbb96>\", line 5, in penalized_MSE_train\n",
            "    return penalized_MSE_helper(sci.special.inv_boxcox(y_true, fitted_lambda),sci.special.inv_boxcox(y_pred, fitted_lambda))\n",
            "  File \"<ipython-input-31-ae3c46e3511d>\", line 11, in penalized_MSE_helper\n",
            "    return (1/2)*MSE(critical_y, critical_predictions)+ (1/2)*MSE(common_y, common_predictions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 424, in mean_squared_error\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 91, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 792, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   4   11   30   35   36   37   41   54   63   66   69   76   87   97\n",
            "   98  102  106  130  131  133  134  142  148  149  159  161  165  176\n",
            "  178  187  190  191  194  201  202  206  224  226  227  232  238  246\n",
            "  248  250  256  259  261  264  270  271  274  278  279  287  288  290\n",
            "  303  304  307  313  314  316  318  322  324  327  334  335  339  346\n",
            "  347  349  358  367  369  373  374  375  376  377  378  390  391  393\n",
            "  394  397  398  411  420  421  423  428  429  435  442  443  448  450\n",
            "  457  461  464  465  467  469  474  493  497  499  500  501  503  520\n",
            "  529  530  545  547  553  561  562  567  569  570  573  586  592  597\n",
            "  598  599  603  604  605  611  625  629  630  633  636  640  645  654\n",
            "  658  662  670  675  678  686  690  692  697  699  702  707  710  718\n",
            "  719  725  731  732  733  738  745  746  752  777  782  784  788  790\n",
            "  793  794  797  798  800  802  804  813  824  825  826  832  836  852\n",
            "  856  859  861  864  868  871  878  885  889  891  896  904  911  913\n",
            "  917  923  927  952  958  962  969  974  976  979  986  988  989  990\n",
            "  997  998  999 1001 1008 1009 1029 1034 1041 1048 1052 1056 1061 1069\n",
            " 1072 1073 1080 1082 1091 1092 1099 1101 1111 1115 1120 1123 1124 1130\n",
            " 1134 1137 1144 1150 1152 1156 1168 1171 1173 1179 1183 1188 1196 1200\n",
            " 1202 1203 1205 1212 1214 1215 1222 1255 1256 1257 1262 1273 1279 1281\n",
            " 1287 1291 1306 1307 1310 1314 1315 1320 1324 1326 1329 1330 1332 1336\n",
            " 1346 1349 1351 1352 1353 1354 1365 1394 1397 1398 1400 1405 1407 1411\n",
            " 1423 1432 1434 1442 1445 1448 1449 1467 1469 1472 1490 1494 1495 1510\n",
            " 1516 1519 1521 1522 1526 1533 1547 1548 1551 1553 1574 1581 1583 1585\n",
            " 1589 1590 1598 1601 1611 1613 1614 1619 1622 1623 1637 1642 1647 1649\n",
            " 1650 1660 1667 1671 1673 1677 1682 1684 1695 1696 1697 1705 1723 1725\n",
            " 1727 1730 1732 1734 1742 1749 1772 1781 1782 1786 1795 1798 1802 1804\n",
            " 1805 1806 1812 1813 1814 1819 1820 1821 1831 1842 1844 1847 1849 1859\n",
            " 1860 1866 1869 1873 1878 1880 1886 1892 1896 1898 1900 1910 1911 1912\n",
            " 1919 1920 1922 1926 1931 1934 1941 1943 1946 1947 1951 1952 1957 1971\n",
            " 1972 1974 1979 1982 1983 1986 1989 1995 2000 2004 2010 2013 2014 2015\n",
            " 2016 2020 2021 2022 2038 2041 2042 2044 2045 2047 2056 2057 2059 2071\n",
            " 2074 2088 2091 2096 2107 2108 2110 2111 2113 2114 2120 2121 2134 2136\n",
            " 2140 2141 2147 2148 2151 2158 2163 2165 2166 2169 2172 2173 2178 2185\n",
            " 2188 2189 2203 2208 2209 2213 2218 2226 2234 2235 2251 2254 2263 2264\n",
            " 2266 2269 2271 2277 2278 2280 2281 2287 2288 2293 2294 2296 2302 2305\n",
            " 2306 2308 2310 2312 2315 2316 2318 2319 2335 2353 2357 2363 2368 2369\n",
            " 2370 2372 2375 2378 2379 2380 2382 2384 2405 2407 2414 2417 2429 2434\n",
            " 2435 2445 2451 2452 2454 2455 2459 2460 2467 2468 2473 2475 2479 2485\n",
            " 2487 2488 2490 2501 2509 2524 2530 2533 2535 2537 2538 2540 2541 2542\n",
            " 2552 2556 2557 2562 2564 2565 2566 2578 2581 2582 2587 2588 2589 2595\n",
            " 2599 2604 2607 2610 2612 2614 2616 2621 2626 2627 2630 2631 2632 2633\n",
            " 2644 2646 2648 2651 2652 2653 2654 2657 2660 2664 2671 2678 2686 2692\n",
            " 2696 2697 2698 2703 2704 2706 2707 2709 2710 2711 2716 2725 2729 2731\n",
            " 2734 2735 2739 2747 2755 2757 2758 2767 2771 2775 2777 2781 2791 2796\n",
            " 2802 2805 2806 2808 2809 2811 2814 2816 2818 2824 2827 2829 2833 2835\n",
            " 2837 2846 2850 2855 2858 2861 2865 2871 2874 2875 2877 2878 2879 2883\n",
            " 2886 2890 2891]\n",
            "[CV 3/5; 6/10] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, learning_rate=0.5, max_depth=5, n_estimators=500, subsample=0.7999999999999999;, score=-0.169 total time=  12.0s\n",
            "[CV 4/5; 6/10] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, learning_rate=0.5, max_depth=5, n_estimators=500, subsample=0.7999999999999999\n",
            "[23:36:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    4   14   16   23   25   26   29   30   39   40   43   47   62\n",
            "   64   67   70   75   76   78   83   84   90   97   98  102  107  108\n",
            "  113  121  123  126  127  128  132  137  138  142  146  154  158  159\n",
            "  168  188  191  192  198  201  204  209  211  215  219  229  234  238\n",
            "  239  240  242  243  245  246  254  255  257  258  259  264  272  286\n",
            "  287  296  297  302  303  315  316  328  329  334  338  345  347  349\n",
            "  354  359  365  367  373  379  385  386  397  399  411  415  421  423\n",
            "  428  431  439  440  458  460  463  464  469  474  475  479  485  487\n",
            "  515  527  533  535  550  553  554  555  556  557  560  561  568  569\n",
            "  571  573  575  582  586  595  597  601  603  608  618  624  628  629\n",
            "  630  631  640  643  649  652  653  662  668  671  678  679  686  688\n",
            "  690  691  695  698  699  702  704  706  709  710  720  736  739  747\n",
            "  753  762  766  778  789  790  792  799  802  804  805  813  829  830\n",
            "  835  850  856  864  866  872  876  902  906  910  914  920  923  929\n",
            "  934  938  943  944  945  946  950  957  959  960  961  965  971  978\n",
            "  984  985  995  996  998  999 1000 1002 1005 1008 1012 1013 1014 1020\n",
            " 1036 1037 1049 1050 1059 1061 1062 1065 1066 1067 1070 1072 1074 1076\n",
            " 1082 1087 1090 1091 1093 1096 1101 1102 1104 1105 1112 1115 1118 1128\n",
            " 1134 1136 1141 1142 1143 1145 1150 1155 1163 1166 1181 1188 1189 1192\n",
            " 1193 1194 1198 1199 1200 1201 1202 1208 1209 1217 1222 1223 1225 1226\n",
            " 1229 1231 1232 1234 1238 1245 1247 1248 1249 1260 1261 1265 1266 1267\n",
            " 1269 1275 1276 1277 1289 1292 1302 1305 1310 1313 1314 1315 1317 1319\n",
            " 1321 1323 1324 1325 1328 1335 1344 1347 1349 1357 1361 1365 1369 1373\n",
            " 1379 1388 1391 1395 1397 1401 1407 1419 1421 1424 1426 1433 1438 1439\n",
            " 1441 1445 1461 1463 1464 1478 1482 1492 1493 1498 1499 1501 1503 1505\n",
            " 1511 1514 1516 1517 1519 1521 1524 1528 1529 1533 1534 1538 1539 1557\n",
            " 1558 1559 1579 1583 1587 1590 1602 1603 1613 1617 1619 1622 1626 1631\n",
            " 1641 1651 1654 1655 1657 1663 1668 1670 1688 1695 1706 1711 1712 1714\n",
            " 1719 1727 1728 1732 1734 1735 1736 1740 1746 1748 1761 1762 1767 1768\n",
            " 1778 1781 1783 1785 1788 1791 1795 1796 1802 1805 1810 1811 1813 1817\n",
            " 1818 1819 1822 1823 1839 1843 1862 1865 1873 1874 1875 1876 1877 1882\n",
            " 1887 1894 1896 1902 1905 1914 1915 1917 1925 1929 1931 1938 1939 1944\n",
            " 1952 1953 1954 1960 1965 1979 1980 1984 1986 1991 1993 1996 2001 2010\n",
            " 2011 2019 2024 2025 2032 2033 2036 2038 2040 2041 2042 2044 2047 2048\n",
            " 2051 2054 2056 2059 2069 2071 2078 2079 2080 2085 2087 2094 2097 2099\n",
            " 2104 2110 2115 2120 2121 2122 2129 2130 2135 2141 2143 2145 2148 2150\n",
            " 2157 2158 2160 2162 2166 2169 2175 2184 2195 2199 2202 2205 2213 2215\n",
            " 2217 2219 2220 2223 2224 2225 2228 2230 2231 2234 2235 2237 2248 2249\n",
            " 2253 2255 2257 2258 2259 2262 2277 2278 2282 2283 2291 2292 2297 2310\n",
            " 2314 2317 2320 2325 2326 2332 2337 2338 2340 2341 2343 2345 2349 2353\n",
            " 2354 2358 2360 2362 2376 2383 2384 2387 2390 2391 2396 2399 2400 2404\n",
            " 2408 2413 2415 2416 2417 2418 2421 2422 2427 2429 2432 2433 2450 2451\n",
            " 2454 2457 2458 2460 2461 2465 2467 2470 2471 2475 2480 2487 2494 2498\n",
            " 2502 2507 2523 2524 2531 2533 2536 2538 2543 2545 2547 2549 2551 2553\n",
            " 2554 2557 2561 2563 2567 2570 2571 2572 2579 2582 2583 2585 2586 2588\n",
            " 2594 2595 2609 2613 2615 2617 2620 2623 2624 2625 2632 2633 2640 2647\n",
            " 2649 2650 2655 2657 2662 2664 2668 2669 2671 2689 2699 2701 2704 2706\n",
            " 2707 2710 2717 2720 2723 2726 2733 2735 2736 2747 2754 2755 2757 2763\n",
            " 2771 2779 2786 2790 2791 2792 2796 2800 2802 2805 2809 2832 2840 2845\n",
            " 2846 2850 2855 2860 2861 2863 2869 2870 2876 2877 2879 2883 2887 2889]\n",
            "[CV 4/5; 6/10] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, learning_rate=0.5, max_depth=5, n_estimators=500, subsample=0.7999999999999999;, score=-0.032 total time=  11.9s\n",
            "[CV 5/5; 6/10] START colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, learning_rate=0.5, max_depth=5, n_estimators=500, subsample=0.7999999999999999\n",
            "[23:36:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   5   11   14   25   27   37   41   42   51   52   55   56   59   60\n",
            "   76   81   83   90   96  100  108  109  114  116  119  124  128  135\n",
            "  137  142  145  147  150  157  164  167  170  178  185  190  192  194\n",
            "  198  202  211  214  222  223  237  238  243  246  252  255  258  260\n",
            "  261  268  270  271  276  283  286  288  294  302  318  322  326  331\n",
            "  335  336  348  350  351  353  354  370  375  380  382  383  390  393\n",
            "  403  404  406  407  409  421  424  433  438  440  442  455  463  473\n",
            "  476  478  479  481  482  487  489  497  499  502  504  509  510  516\n",
            "  517  521  529  533  536  540  541  546  552  556  557  560  566  572\n",
            "  575  578  579  581  595  602  603  612  614  617  618  622  626  629\n",
            "  639  642  644  657  660  666  668  673  675  676  688  689  690  692\n",
            "  695  696  697  703  705  715  717  718  719  728  730  733  740  747\n",
            "  755  759  761  764  765  773  776  779  782  784  786  794  797  799\n",
            "  800  810  811  816  822  830  831  833  836  855  858  864  868  879\n",
            "  880  896  898  904  910  917  925  928  930  932  940  942  948  950\n",
            "  963  966  968  970  971  972  974  984  987  989  992  993  997 1002\n",
            " 1006 1010 1014 1023 1029 1032 1035 1041 1046 1050 1051 1057 1062 1063\n",
            " 1065 1067 1068 1069 1072 1076 1077 1088 1089 1093 1101 1107 1114 1118\n",
            " 1121 1128 1130 1131 1138 1139 1142 1144 1150 1151 1155 1161 1167 1175\n",
            " 1177 1181 1187 1194 1196 1199 1201 1202 1205 1222 1223 1225 1230 1231\n",
            " 1234 1246 1250 1252 1253 1255 1263 1270 1272 1273 1277 1279 1285 1289\n",
            " 1291 1297 1298 1303 1304 1306 1307 1311 1321 1328 1331 1336 1337 1341\n",
            " 1347 1355 1358 1364 1370 1372 1374 1376 1379 1380 1381 1383 1392 1394\n",
            " 1399 1404 1409 1412 1419 1420 1422 1431 1433 1437 1438 1441 1447 1448\n",
            " 1449 1454 1458 1459 1463 1465 1467 1468 1471 1486 1491 1497 1499 1501\n",
            " 1508 1509 1510 1514 1522 1524 1527 1533 1537 1542 1551 1554 1561 1563\n",
            " 1565 1567 1569 1571 1572 1574 1577 1581 1583 1584 1588 1595 1596 1598\n",
            " 1600 1608 1612 1617 1621 1624 1630 1635 1636 1637 1640 1643 1653 1656\n",
            " 1657 1661 1668 1672 1673 1676 1679 1681 1686 1687 1688 1696 1699 1701\n",
            " 1709 1710 1720 1722 1725 1726 1731 1733 1737 1738 1741 1746 1747 1749\n",
            " 1751 1754 1756 1763 1765 1772 1782 1783 1787 1788 1792 1796 1802 1809\n",
            " 1817 1819 1822 1834 1835 1848 1851 1860 1868 1876 1880 1893 1894 1900\n",
            " 1905 1929 1934 1938 1947 1948 1953 1956 1967 1969 1976 1978 1988 1989\n",
            " 1994 1995 1996 1999 2000 2005 2009 2011 2013 2020 2026 2027 2032 2045\n",
            " 2062 2063 2072 2074 2075 2081 2088 2089 2090 2099 2101 2110 2111 2117\n",
            " 2120 2129 2131 2132 2133 2138 2142 2143 2144 2147 2151 2153 2154 2166\n",
            " 2175 2178 2185 2188 2198 2202 2204 2206 2207 2209 2224 2230 2231 2237\n",
            " 2248 2249 2251 2258 2261 2262 2264 2272 2276 2280 2281 2282 2283 2285\n",
            " 2288 2295 2297 2300 2308 2314 2315 2316 2317 2320 2321 2327 2328 2332\n",
            " 2336 2337 2351 2359 2368 2370 2373 2383 2392 2394 2404 2405 2408 2410\n",
            " 2425 2435 2439 2440 2453 2458 2467 2470 2473 2478 2481 2483 2487 2489\n",
            " 2490 2499 2500 2505 2512 2513 2517 2522 2523 2524 2527 2528 2529 2533\n",
            " 2538 2541 2549 2551 2578 2589 2596 2601 2610 2627 2630 2633 2643 2645\n",
            " 2649 2653 2655 2672 2673 2679 2690 2692 2697 2698 2699 2705 2714 2718\n",
            " 2727 2732 2744 2745 2746 2747 2751 2757 2758 2761 2763 2767 2781 2782\n",
            " 2786 2789 2795 2801 2806 2810 2812 2814 2816 2818 2824 2826 2832 2833\n",
            " 2838 2841 2843 2844 2847 2850 2851 2853 2868 2871 2876 2878 2880 2881\n",
            " 2887 2888 2889 2892]\n",
            "[CV 5/5; 6/10] END colsample_bylevel=0.8999999999999999, colsample_bytree=0.5, learning_rate=0.5, max_depth=5, n_estimators=500, subsample=0.7999999999999999;, score=-0.016 total time=  11.9s\n",
            "[CV 1/5; 7/10] START colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
            "[23:36:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    8   11   17   19   20   23   33   34   36   39   43   47   52\n",
            "   55   65   67   70   74   76   78   80   85   87   89   97   98  102\n",
            "  108  109  111  114  117  119  121  123  124  128  130  135  138  140\n",
            "  149  162  169  171  174  175  177  180  188  189  190  192  195  202\n",
            "  212  224  227  234  235  237  238  242  243  245  247  248  251  252\n",
            "  257  262  264  267  271  274  275  277  279  280  287  292  297  304\n",
            "  306  307  314  319  327  332  334  336  340  345  346  347  350  352\n",
            "  354  358  368  375  379  381  385  388  390  391  394  395  402  404\n",
            "  412  418  422  423  424  428  430  438  443  447  450  459  468  477\n",
            "  479  484  485  486  488  495  499  511  522  529  532  534  536  541\n",
            "  543  560  562  563  568  570  577  586  589  590  594  599  603  613\n",
            "  615  617  624  625  627  634  635  639  645  650  667  676  679  689\n",
            "  690  691  695  696  700  703  707  715  718  720  726  728  730  733\n",
            "  737  749  755  759  763  764  765  773  774  779  786  798  802  808\n",
            "  822  824  829  832  836  852  856  862  865  867  870  872  873  874\n",
            "  884  888  893  894  899  900  917  920  922  923  926  940  941  944\n",
            "  959  965  968  974  976  978  979  981  983  989  990  991  995  996\n",
            " 1001 1009 1012 1015 1025 1028 1038 1044 1049 1070 1071 1079 1080 1081\n",
            " 1083 1089 1090 1096 1098 1104 1105 1111 1113 1120 1121 1123 1125 1127\n",
            " 1131 1135 1141 1145 1151 1154 1156 1157 1158 1163 1164 1166 1179 1183\n",
            " 1192 1195 1202 1205 1206 1209 1210 1224 1226 1239 1240 1245 1256 1259\n",
            " 1260 1262 1263 1270 1273 1280 1288 1289 1292 1295 1296 1300 1304 1309\n",
            " 1322 1330 1332 1338 1340 1343 1346 1358 1363 1377 1378 1380 1383 1384\n",
            " 1391 1393 1401 1402 1403 1410 1417 1418 1422 1438 1444 1445 1450 1453\n",
            " 1455 1456 1464 1466 1468 1469 1475 1482 1489 1491 1494 1499 1505 1513\n",
            " 1528 1532 1535 1536 1537 1538 1539 1545 1551 1554 1555 1557 1559 1561\n",
            " 1562 1565 1566 1573 1579 1588 1597 1599 1602 1607 1609 1612 1614 1615\n",
            " 1618 1622 1625 1630 1631 1643 1645 1649 1650 1656 1675 1676 1679 1684\n",
            " 1685 1691 1697 1701 1705 1706 1707 1709 1716 1726 1727 1728 1740 1742\n",
            " 1748 1751 1753 1763 1768 1769 1770 1786 1794 1798 1799 1801 1804 1812\n",
            " 1814 1821 1822 1825 1835 1841 1842 1846 1848 1856 1857 1874 1875 1879\n",
            " 1880 1892 1907 1917 1927 1930 1940 1942 1949 1952 1957 1966 1971 1974\n",
            " 1975 1976 1979 1981 1984 1987 1989 1992 1993 1995 2002 2003 2007 2010\n",
            " 2015 2027 2028 2029 2031 2035 2037 2049 2054 2056 2060 2061 2066 2070\n",
            " 2071 2075 2076 2082 2085 2087 2094 2098 2110 2111 2112 2113 2122 2123\n",
            " 2141 2142 2145 2157 2162 2166 2167 2172 2177 2180 2181 2183 2186 2195\n",
            " 2202 2209 2213 2215 2219 2220 2222 2224 2232 2233 2240 2244 2246 2248\n",
            " 2253 2259 2266 2276 2277 2280 2282 2284 2291 2298 2309 2311 2313 2322\n",
            " 2338 2339 2340 2341 2346 2347 2348 2350 2361 2363 2364 2365 2366 2369\n",
            " 2374 2375 2380 2382 2385 2386 2396 2406 2410 2413 2416 2420 2422 2427\n",
            " 2436 2438 2439 2440 2441 2444 2445 2448 2449 2453 2456 2459 2461 2463\n",
            " 2464 2469 2472 2474 2483 2494 2498 2505 2507 2509 2514 2517 2522 2524\n",
            " 2526 2531 2538 2547 2550 2554 2557 2561 2566 2571 2574 2577 2581 2585\n",
            " 2590 2594 2600 2603 2606 2612 2618 2620 2622 2625 2633 2642 2647 2654\n",
            " 2655 2656 2661 2665 2669 2671 2672 2677 2684 2694 2700 2701 2704 2706\n",
            " 2709 2712 2713 2714 2715 2725 2727 2730 2735 2738 2742 2743 2748 2756\n",
            " 2760 2763 2767 2772 2774 2776 2779 2781 2785 2786 2790 2792 2805 2806\n",
            " 2807 2810 2820 2827 2832 2841 2847 2852 2857 2862 2865 2867 2871 2873\n",
            " 2878 2881 2884 2887 2889]\n",
            "[CV 1/5; 7/10] END colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=15, n_estimators=100, subsample=0.8999999999999999;, score=-0.005 total time=  21.8s\n",
            "[CV 2/5; 7/10] START colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
            "[23:37:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   3    5    7   12   14   20   22   25   27   31   32   33   43   47\n",
            "   51   62   64   69   70   71   74   76   88   89  109  111  113  115\n",
            "  125  133  137  141  143  145  148  156  159  174  175  176  180  190\n",
            "  191  195  199  200  203  205  207  209  210  212  213  215  220  227\n",
            "  231  238  252  258  262  268  269  272  310  311  314  315  332  334\n",
            "  356  361  362  363  364  367  368  369  371  373  377  380  384  385\n",
            "  390  399  403  407  409  410  417  429  431  435  444  449  464  465\n",
            "  466  467  470  474  475  480  489  490  492  493  498  499  501  505\n",
            "  509  512  513  517  518  521  524  529  533  534  537  539  541  545\n",
            "  549  550  558  560  564  573  574  577  580  584  585  586  587  594\n",
            "  598  605  606  612  624  627  628  630  642  647  649  651  663  665\n",
            "  679  680  691  696  701  710  711  716  727  731  733  736  744  750\n",
            "  751  759  760  763  765  771  773  776  780  789  794  806  809  812\n",
            "  814  820  821  833  838  844  855  859  866  868  884  890  894  902\n",
            "  905  907  909  916  917  921  922  931  934  937  958  968  969  973\n",
            "  979  981  990 1004 1010 1014 1015 1018 1033 1036 1037 1038 1040 1042\n",
            " 1043 1049 1068 1069 1076 1081 1084 1088 1090 1092 1094 1097 1100 1101\n",
            " 1105 1107 1116 1118 1123 1124 1128 1133 1141 1151 1152 1153 1161 1162\n",
            " 1164 1178 1179 1181 1189 1193 1197 1202 1209 1214 1221 1237 1241 1244\n",
            " 1245 1250 1253 1254 1258 1261 1262 1264 1266 1267 1268 1269 1270 1272\n",
            " 1276 1283 1287 1292 1293 1295 1303 1304 1310 1312 1316 1319 1328 1336\n",
            " 1341 1343 1344 1346 1351 1356 1374 1375 1378 1379 1383 1389 1397 1398\n",
            " 1399 1401 1404 1408 1413 1420 1437 1439 1440 1441 1446 1447 1450 1451\n",
            " 1458 1461 1475 1479 1481 1487 1488 1493 1504 1505 1506 1511 1512 1529\n",
            " 1532 1533 1537 1538 1541 1549 1550 1553 1559 1560 1565 1570 1571 1572\n",
            " 1573 1586 1588 1601 1607 1610 1611 1613 1614 1620 1626 1627 1634 1641\n",
            " 1647 1653 1658 1665 1672 1681 1684 1686 1696 1697 1705 1708 1720 1721\n",
            " 1725 1727 1738 1739 1742 1743 1751 1757 1762 1764 1769 1770 1773 1775\n",
            " 1779 1783 1786 1787 1789 1800 1803 1807 1809 1812 1821 1829 1836 1837\n",
            " 1839 1844 1855 1857 1875 1877 1879 1887 1889 1894 1897 1900 1902 1903\n",
            " 1907 1908 1917 1921 1923 1937 1947 1948 1951 1953 1956 1957 1959 1961\n",
            " 1964 1967 1968 1970 1974 1975 1981 1983 1986 1987 1994 1998 2003 2007\n",
            " 2009 2011 2013 2015 2020 2029 2036 2037 2041 2043 2045 2046 2047 2057\n",
            " 2058 2064 2070 2082 2086 2088 2089 2090 2093 2095 2101 2104 2110 2111\n",
            " 2113 2114 2115 2118 2119 2127 2134 2139 2141 2146 2147 2149 2150 2157\n",
            " 2159 2161 2166 2167 2169 2178 2182 2188 2197 2201 2207 2215 2217 2219\n",
            " 2222 2223 2224 2225 2231 2232 2233 2241 2245 2257 2262 2272 2291 2292\n",
            " 2293 2294 2296 2306 2307 2308 2309 2314 2340 2346 2347 2348 2353 2359\n",
            " 2369 2373 2380 2381 2382 2386 2393 2396 2401 2402 2403 2409 2411 2414\n",
            " 2419 2424 2431 2432 2433 2436 2437 2445 2450 2451 2452 2458 2460 2462\n",
            " 2463 2466 2471 2476 2494 2496 2503 2507 2510 2528 2530 2534 2535 2536\n",
            " 2538 2540 2542 2553 2554 2558 2559 2564 2571 2572 2574 2575 2582 2592\n",
            " 2594 2605 2612 2620 2623 2637 2643 2654 2657 2668 2677 2678 2680 2683\n",
            " 2690 2691 2693 2696 2700 2702 2705 2707 2708 2713 2717 2724 2727 2733\n",
            " 2735 2737 2748 2752 2753 2755 2765 2772 2775 2776 2781 2797 2800 2805\n",
            " 2806 2812 2813 2814 2815 2822 2831 2832 2835 2839 2843 2851 2855 2856\n",
            " 2859 2871 2872 2873 2884 2885 2886 2890 2892]\n",
            "[CV 2/5; 7/10] END colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=15, n_estimators=100, subsample=0.8999999999999999;, score=-0.004 total time=  22.3s\n",
            "[CV 3/5; 7/10] START colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
            "[23:37:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   4   11   30   35   36   37   41   54   63   66   69   76   87   97\n",
            "   98  102  106  130  131  133  134  142  148  149  159  161  165  176\n",
            "  178  187  190  191  194  201  202  206  224  226  227  232  238  246\n",
            "  248  250  256  259  261  264  270  271  274  278  279  287  288  290\n",
            "  303  304  307  313  314  316  318  322  324  327  334  335  339  346\n",
            "  347  349  358  367  369  373  374  375  376  377  378  390  391  393\n",
            "  394  397  398  411  420  421  423  428  429  435  442  443  448  450\n",
            "  457  461  464  465  467  469  474  493  497  499  500  501  503  520\n",
            "  529  530  545  547  553  561  562  567  569  570  573  586  592  597\n",
            "  598  599  603  604  605  611  625  629  630  633  636  640  645  654\n",
            "  658  662  670  675  678  686  690  692  697  699  702  707  710  718\n",
            "  719  725  731  732  733  738  745  746  752  777  782  784  788  790\n",
            "  793  794  797  798  800  802  804  813  824  825  826  832  836  852\n",
            "  856  859  861  864  868  871  878  885  889  891  896  904  911  913\n",
            "  917  923  927  952  958  962  969  974  976  979  986  988  989  990\n",
            "  997  998  999 1001 1008 1009 1029 1034 1041 1048 1052 1056 1061 1069\n",
            " 1072 1073 1080 1082 1091 1092 1099 1101 1111 1115 1120 1123 1124 1130\n",
            " 1134 1137 1144 1150 1152 1156 1168 1171 1173 1179 1183 1188 1196 1200\n",
            " 1202 1203 1205 1212 1214 1215 1222 1255 1256 1257 1262 1273 1279 1281\n",
            " 1287 1291 1306 1307 1310 1314 1315 1320 1324 1326 1329 1330 1332 1336\n",
            " 1346 1349 1351 1352 1353 1354 1365 1394 1397 1398 1400 1405 1407 1411\n",
            " 1423 1432 1434 1442 1445 1448 1449 1467 1469 1472 1490 1494 1495 1510\n",
            " 1516 1519 1521 1522 1526 1533 1547 1548 1551 1553 1574 1581 1583 1585\n",
            " 1589 1590 1598 1601 1611 1613 1614 1619 1622 1623 1637 1642 1647 1649\n",
            " 1650 1660 1667 1671 1673 1677 1682 1684 1695 1696 1697 1705 1723 1725\n",
            " 1727 1730 1732 1734 1742 1749 1772 1781 1782 1786 1795 1798 1802 1804\n",
            " 1805 1806 1812 1813 1814 1819 1820 1821 1831 1842 1844 1847 1849 1859\n",
            " 1860 1866 1869 1873 1878 1880 1886 1892 1896 1898 1900 1910 1911 1912\n",
            " 1919 1920 1922 1926 1931 1934 1941 1943 1946 1947 1951 1952 1957 1971\n",
            " 1972 1974 1979 1982 1983 1986 1989 1995 2000 2004 2010 2013 2014 2015\n",
            " 2016 2020 2021 2022 2038 2041 2042 2044 2045 2047 2056 2057 2059 2071\n",
            " 2074 2088 2091 2096 2107 2108 2110 2111 2113 2114 2120 2121 2134 2136\n",
            " 2140 2141 2147 2148 2151 2158 2163 2165 2166 2169 2172 2173 2178 2185\n",
            " 2188 2189 2203 2208 2209 2213 2218 2226 2234 2235 2251 2254 2263 2264\n",
            " 2266 2269 2271 2277 2278 2280 2281 2287 2288 2293 2294 2296 2302 2305\n",
            " 2306 2308 2310 2312 2315 2316 2318 2319 2335 2353 2357 2363 2368 2369\n",
            " 2370 2372 2375 2378 2379 2380 2382 2384 2405 2407 2414 2417 2429 2434\n",
            " 2435 2445 2451 2452 2454 2455 2459 2460 2467 2468 2473 2475 2479 2485\n",
            " 2487 2488 2490 2501 2509 2524 2530 2533 2535 2537 2538 2540 2541 2542\n",
            " 2552 2556 2557 2562 2564 2565 2566 2578 2581 2582 2587 2588 2589 2595\n",
            " 2599 2604 2607 2610 2612 2614 2616 2621 2626 2627 2630 2631 2632 2633\n",
            " 2644 2646 2648 2651 2652 2653 2654 2657 2660 2664 2671 2678 2686 2692\n",
            " 2696 2697 2698 2703 2704 2706 2707 2709 2710 2711 2716 2725 2729 2731\n",
            " 2734 2735 2739 2747 2755 2757 2758 2767 2771 2775 2777 2781 2791 2796\n",
            " 2802 2805 2806 2808 2809 2811 2814 2816 2818 2824 2827 2829 2833 2835\n",
            " 2837 2846 2850 2855 2858 2861 2865 2871 2874 2875 2877 2878 2879 2883\n",
            " 2886 2890 2891]\n",
            "[CV 3/5; 7/10] END colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=15, n_estimators=100, subsample=0.8999999999999999;, score=-0.003 total time=  22.0s\n",
            "[CV 4/5; 7/10] START colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
            "[23:38:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    4   14   16   23   25   26   29   30   39   40   43   47   62\n",
            "   64   67   70   75   76   78   83   84   90   97   98  102  107  108\n",
            "  113  121  123  126  127  128  132  137  138  142  146  154  158  159\n",
            "  168  188  191  192  198  201  204  209  211  215  219  229  234  238\n",
            "  239  240  242  243  245  246  254  255  257  258  259  264  272  286\n",
            "  287  296  297  302  303  315  316  328  329  334  338  345  347  349\n",
            "  354  359  365  367  373  379  385  386  397  399  411  415  421  423\n",
            "  428  431  439  440  458  460  463  464  469  474  475  479  485  487\n",
            "  515  527  533  535  550  553  554  555  556  557  560  561  568  569\n",
            "  571  573  575  582  586  595  597  601  603  608  618  624  628  629\n",
            "  630  631  640  643  649  652  653  662  668  671  678  679  686  688\n",
            "  690  691  695  698  699  702  704  706  709  710  720  736  739  747\n",
            "  753  762  766  778  789  790  792  799  802  804  805  813  829  830\n",
            "  835  850  856  864  866  872  876  902  906  910  914  920  923  929\n",
            "  934  938  943  944  945  946  950  957  959  960  961  965  971  978\n",
            "  984  985  995  996  998  999 1000 1002 1005 1008 1012 1013 1014 1020\n",
            " 1036 1037 1049 1050 1059 1061 1062 1065 1066 1067 1070 1072 1074 1076\n",
            " 1082 1087 1090 1091 1093 1096 1101 1102 1104 1105 1112 1115 1118 1128\n",
            " 1134 1136 1141 1142 1143 1145 1150 1155 1163 1166 1181 1188 1189 1192\n",
            " 1193 1194 1198 1199 1200 1201 1202 1208 1209 1217 1222 1223 1225 1226\n",
            " 1229 1231 1232 1234 1238 1245 1247 1248 1249 1260 1261 1265 1266 1267\n",
            " 1269 1275 1276 1277 1289 1292 1302 1305 1310 1313 1314 1315 1317 1319\n",
            " 1321 1323 1324 1325 1328 1335 1344 1347 1349 1357 1361 1365 1369 1373\n",
            " 1379 1388 1391 1395 1397 1401 1407 1419 1421 1424 1426 1433 1438 1439\n",
            " 1441 1445 1461 1463 1464 1478 1482 1492 1493 1498 1499 1501 1503 1505\n",
            " 1511 1514 1516 1517 1519 1521 1524 1528 1529 1533 1534 1538 1539 1557\n",
            " 1558 1559 1579 1583 1587 1590 1602 1603 1613 1617 1619 1622 1626 1631\n",
            " 1641 1651 1654 1655 1657 1663 1668 1670 1688 1695 1706 1711 1712 1714\n",
            " 1719 1727 1728 1732 1734 1735 1736 1740 1746 1748 1761 1762 1767 1768\n",
            " 1778 1781 1783 1785 1788 1791 1795 1796 1802 1805 1810 1811 1813 1817\n",
            " 1818 1819 1822 1823 1839 1843 1862 1865 1873 1874 1875 1876 1877 1882\n",
            " 1887 1894 1896 1902 1905 1914 1915 1917 1925 1929 1931 1938 1939 1944\n",
            " 1952 1953 1954 1960 1965 1979 1980 1984 1986 1991 1993 1996 2001 2010\n",
            " 2011 2019 2024 2025 2032 2033 2036 2038 2040 2041 2042 2044 2047 2048\n",
            " 2051 2054 2056 2059 2069 2071 2078 2079 2080 2085 2087 2094 2097 2099\n",
            " 2104 2110 2115 2120 2121 2122 2129 2130 2135 2141 2143 2145 2148 2150\n",
            " 2157 2158 2160 2162 2166 2169 2175 2184 2195 2199 2202 2205 2213 2215\n",
            " 2217 2219 2220 2223 2224 2225 2228 2230 2231 2234 2235 2237 2248 2249\n",
            " 2253 2255 2257 2258 2259 2262 2277 2278 2282 2283 2291 2292 2297 2310\n",
            " 2314 2317 2320 2325 2326 2332 2337 2338 2340 2341 2343 2345 2349 2353\n",
            " 2354 2358 2360 2362 2376 2383 2384 2387 2390 2391 2396 2399 2400 2404\n",
            " 2408 2413 2415 2416 2417 2418 2421 2422 2427 2429 2432 2433 2450 2451\n",
            " 2454 2457 2458 2460 2461 2465 2467 2470 2471 2475 2480 2487 2494 2498\n",
            " 2502 2507 2523 2524 2531 2533 2536 2538 2543 2545 2547 2549 2551 2553\n",
            " 2554 2557 2561 2563 2567 2570 2571 2572 2579 2582 2583 2585 2586 2588\n",
            " 2594 2595 2609 2613 2615 2617 2620 2623 2624 2625 2632 2633 2640 2647\n",
            " 2649 2650 2655 2657 2662 2664 2668 2669 2671 2689 2699 2701 2704 2706\n",
            " 2707 2710 2717 2720 2723 2726 2733 2735 2736 2747 2754 2755 2757 2763\n",
            " 2771 2779 2786 2790 2791 2792 2796 2800 2802 2805 2809 2832 2840 2845\n",
            " 2846 2850 2855 2860 2861 2863 2869 2870 2876 2877 2879 2883 2887 2889]\n",
            "[CV 4/5; 7/10] END colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=15, n_estimators=100, subsample=0.8999999999999999;, score=-0.005 total time=  21.5s\n",
            "[CV 5/5; 7/10] START colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=15, n_estimators=100, subsample=0.8999999999999999\n",
            "[23:38:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   5   11   14   25   27   37   41   42   51   52   55   56   59   60\n",
            "   76   81   83   90   96  100  108  109  114  116  119  124  128  135\n",
            "  137  142  145  147  150  157  164  167  170  178  185  190  192  194\n",
            "  198  202  211  214  222  223  237  238  243  246  252  255  258  260\n",
            "  261  268  270  271  276  283  286  288  294  302  318  322  326  331\n",
            "  335  336  348  350  351  353  354  370  375  380  382  383  390  393\n",
            "  403  404  406  407  409  421  424  433  438  440  442  455  463  473\n",
            "  476  478  479  481  482  487  489  497  499  502  504  509  510  516\n",
            "  517  521  529  533  536  540  541  546  552  556  557  560  566  572\n",
            "  575  578  579  581  595  602  603  612  614  617  618  622  626  629\n",
            "  639  642  644  657  660  666  668  673  675  676  688  689  690  692\n",
            "  695  696  697  703  705  715  717  718  719  728  730  733  740  747\n",
            "  755  759  761  764  765  773  776  779  782  784  786  794  797  799\n",
            "  800  810  811  816  822  830  831  833  836  855  858  864  868  879\n",
            "  880  896  898  904  910  917  925  928  930  932  940  942  948  950\n",
            "  963  966  968  970  971  972  974  984  987  989  992  993  997 1002\n",
            " 1006 1010 1014 1023 1029 1032 1035 1041 1046 1050 1051 1057 1062 1063\n",
            " 1065 1067 1068 1069 1072 1076 1077 1088 1089 1093 1101 1107 1114 1118\n",
            " 1121 1128 1130 1131 1138 1139 1142 1144 1150 1151 1155 1161 1167 1175\n",
            " 1177 1181 1187 1194 1196 1199 1201 1202 1205 1222 1223 1225 1230 1231\n",
            " 1234 1246 1250 1252 1253 1255 1263 1270 1272 1273 1277 1279 1285 1289\n",
            " 1291 1297 1298 1303 1304 1306 1307 1311 1321 1328 1331 1336 1337 1341\n",
            " 1347 1355 1358 1364 1370 1372 1374 1376 1379 1380 1381 1383 1392 1394\n",
            " 1399 1404 1409 1412 1419 1420 1422 1431 1433 1437 1438 1441 1447 1448\n",
            " 1449 1454 1458 1459 1463 1465 1467 1468 1471 1486 1491 1497 1499 1501\n",
            " 1508 1509 1510 1514 1522 1524 1527 1533 1537 1542 1551 1554 1561 1563\n",
            " 1565 1567 1569 1571 1572 1574 1577 1581 1583 1584 1588 1595 1596 1598\n",
            " 1600 1608 1612 1617 1621 1624 1630 1635 1636 1637 1640 1643 1653 1656\n",
            " 1657 1661 1668 1672 1673 1676 1679 1681 1686 1687 1688 1696 1699 1701\n",
            " 1709 1710 1720 1722 1725 1726 1731 1733 1737 1738 1741 1746 1747 1749\n",
            " 1751 1754 1756 1763 1765 1772 1782 1783 1787 1788 1792 1796 1802 1809\n",
            " 1817 1819 1822 1834 1835 1848 1851 1860 1868 1876 1880 1893 1894 1900\n",
            " 1905 1929 1934 1938 1947 1948 1953 1956 1967 1969 1976 1978 1988 1989\n",
            " 1994 1995 1996 1999 2000 2005 2009 2011 2013 2020 2026 2027 2032 2045\n",
            " 2062 2063 2072 2074 2075 2081 2088 2089 2090 2099 2101 2110 2111 2117\n",
            " 2120 2129 2131 2132 2133 2138 2142 2143 2144 2147 2151 2153 2154 2166\n",
            " 2175 2178 2185 2188 2198 2202 2204 2206 2207 2209 2224 2230 2231 2237\n",
            " 2248 2249 2251 2258 2261 2262 2264 2272 2276 2280 2281 2282 2283 2285\n",
            " 2288 2295 2297 2300 2308 2314 2315 2316 2317 2320 2321 2327 2328 2332\n",
            " 2336 2337 2351 2359 2368 2370 2373 2383 2392 2394 2404 2405 2408 2410\n",
            " 2425 2435 2439 2440 2453 2458 2467 2470 2473 2478 2481 2483 2487 2489\n",
            " 2490 2499 2500 2505 2512 2513 2517 2522 2523 2524 2527 2528 2529 2533\n",
            " 2538 2541 2549 2551 2578 2589 2596 2601 2610 2627 2630 2633 2643 2645\n",
            " 2649 2653 2655 2672 2673 2679 2690 2692 2697 2698 2699 2705 2714 2718\n",
            " 2727 2732 2744 2745 2746 2747 2751 2757 2758 2761 2763 2767 2781 2782\n",
            " 2786 2789 2795 2801 2806 2810 2812 2814 2816 2818 2824 2826 2832 2833\n",
            " 2838 2841 2843 2844 2847 2850 2851 2853 2868 2871 2876 2878 2880 2881\n",
            " 2887 2888 2889 2892]\n",
            "[CV 5/5; 7/10] END colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=15, n_estimators=100, subsample=0.8999999999999999;, score=-0.005 total time=  21.7s\n",
            "[CV 1/5; 8/10] START colsample_bylevel=0.5, colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.7\n",
            "[23:38:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    8   11   17   19   20   23   33   34   36   39   43   47   52\n",
            "   55   65   67   70   74   76   78   80   85   87   89   97   98  102\n",
            "  108  109  111  114  117  119  121  123  124  128  130  135  138  140\n",
            "  149  162  169  171  174  175  177  180  188  189  190  192  195  202\n",
            "  212  224  227  234  235  237  238  242  243  245  247  248  251  252\n",
            "  257  262  264  267  271  274  275  277  279  280  287  292  297  304\n",
            "  306  307  314  319  327  332  334  336  340  345  346  347  350  352\n",
            "  354  358  368  375  379  381  385  388  390  391  394  395  402  404\n",
            "  412  418  422  423  424  428  430  438  443  447  450  459  468  477\n",
            "  479  484  485  486  488  495  499  511  522  529  532  534  536  541\n",
            "  543  560  562  563  568  570  577  586  589  590  594  599  603  613\n",
            "  615  617  624  625  627  634  635  639  645  650  667  676  679  689\n",
            "  690  691  695  696  700  703  707  715  718  720  726  728  730  733\n",
            "  737  749  755  759  763  764  765  773  774  779  786  798  802  808\n",
            "  822  824  829  832  836  852  856  862  865  867  870  872  873  874\n",
            "  884  888  893  894  899  900  917  920  922  923  926  940  941  944\n",
            "  959  965  968  974  976  978  979  981  983  989  990  991  995  996\n",
            " 1001 1009 1012 1015 1025 1028 1038 1044 1049 1070 1071 1079 1080 1081\n",
            " 1083 1089 1090 1096 1098 1104 1105 1111 1113 1120 1121 1123 1125 1127\n",
            " 1131 1135 1141 1145 1151 1154 1156 1157 1158 1163 1164 1166 1179 1183\n",
            " 1192 1195 1202 1205 1206 1209 1210 1224 1226 1239 1240 1245 1256 1259\n",
            " 1260 1262 1263 1270 1273 1280 1288 1289 1292 1295 1296 1300 1304 1309\n",
            " 1322 1330 1332 1338 1340 1343 1346 1358 1363 1377 1378 1380 1383 1384\n",
            " 1391 1393 1401 1402 1403 1410 1417 1418 1422 1438 1444 1445 1450 1453\n",
            " 1455 1456 1464 1466 1468 1469 1475 1482 1489 1491 1494 1499 1505 1513\n",
            " 1528 1532 1535 1536 1537 1538 1539 1545 1551 1554 1555 1557 1559 1561\n",
            " 1562 1565 1566 1573 1579 1588 1597 1599 1602 1607 1609 1612 1614 1615\n",
            " 1618 1622 1625 1630 1631 1643 1645 1649 1650 1656 1675 1676 1679 1684\n",
            " 1685 1691 1697 1701 1705 1706 1707 1709 1716 1726 1727 1728 1740 1742\n",
            " 1748 1751 1753 1763 1768 1769 1770 1786 1794 1798 1799 1801 1804 1812\n",
            " 1814 1821 1822 1825 1835 1841 1842 1846 1848 1856 1857 1874 1875 1879\n",
            " 1880 1892 1907 1917 1927 1930 1940 1942 1949 1952 1957 1966 1971 1974\n",
            " 1975 1976 1979 1981 1984 1987 1989 1992 1993 1995 2002 2003 2007 2010\n",
            " 2015 2027 2028 2029 2031 2035 2037 2049 2054 2056 2060 2061 2066 2070\n",
            " 2071 2075 2076 2082 2085 2087 2094 2098 2110 2111 2112 2113 2122 2123\n",
            " 2141 2142 2145 2157 2162 2166 2167 2172 2177 2180 2181 2183 2186 2195\n",
            " 2202 2209 2213 2215 2219 2220 2222 2224 2232 2233 2240 2244 2246 2248\n",
            " 2253 2259 2266 2276 2277 2280 2282 2284 2291 2298 2309 2311 2313 2322\n",
            " 2338 2339 2340 2341 2346 2347 2348 2350 2361 2363 2364 2365 2366 2369\n",
            " 2374 2375 2380 2382 2385 2386 2396 2406 2410 2413 2416 2420 2422 2427\n",
            " 2436 2438 2439 2440 2441 2444 2445 2448 2449 2453 2456 2459 2461 2463\n",
            " 2464 2469 2472 2474 2483 2494 2498 2505 2507 2509 2514 2517 2522 2524\n",
            " 2526 2531 2538 2547 2550 2554 2557 2561 2566 2571 2574 2577 2581 2585\n",
            " 2590 2594 2600 2603 2606 2612 2618 2620 2622 2625 2633 2642 2647 2654\n",
            " 2655 2656 2661 2665 2669 2671 2672 2677 2684 2694 2700 2701 2704 2706\n",
            " 2709 2712 2713 2714 2715 2725 2727 2730 2735 2738 2742 2743 2748 2756\n",
            " 2760 2763 2767 2772 2774 2776 2779 2781 2785 2786 2790 2792 2805 2806\n",
            " 2807 2810 2820 2827 2832 2841 2847 2852 2857 2862 2865 2867 2871 2873\n",
            " 2878 2881 2884 2887 2889]\n",
            "[CV 1/5; 8/10] END colsample_bylevel=0.5, colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.7;, score=-0.016 total time=  13.1s\n",
            "[CV 2/5; 8/10] START colsample_bylevel=0.5, colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.7\n",
            "[23:38:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   3    5    7   12   14   20   22   25   27   31   32   33   43   47\n",
            "   51   62   64   69   70   71   74   76   88   89  109  111  113  115\n",
            "  125  133  137  141  143  145  148  156  159  174  175  176  180  190\n",
            "  191  195  199  200  203  205  207  209  210  212  213  215  220  227\n",
            "  231  238  252  258  262  268  269  272  310  311  314  315  332  334\n",
            "  356  361  362  363  364  367  368  369  371  373  377  380  384  385\n",
            "  390  399  403  407  409  410  417  429  431  435  444  449  464  465\n",
            "  466  467  470  474  475  480  489  490  492  493  498  499  501  505\n",
            "  509  512  513  517  518  521  524  529  533  534  537  539  541  545\n",
            "  549  550  558  560  564  573  574  577  580  584  585  586  587  594\n",
            "  598  605  606  612  624  627  628  630  642  647  649  651  663  665\n",
            "  679  680  691  696  701  710  711  716  727  731  733  736  744  750\n",
            "  751  759  760  763  765  771  773  776  780  789  794  806  809  812\n",
            "  814  820  821  833  838  844  855  859  866  868  884  890  894  902\n",
            "  905  907  909  916  917  921  922  931  934  937  958  968  969  973\n",
            "  979  981  990 1004 1010 1014 1015 1018 1033 1036 1037 1038 1040 1042\n",
            " 1043 1049 1068 1069 1076 1081 1084 1088 1090 1092 1094 1097 1100 1101\n",
            " 1105 1107 1116 1118 1123 1124 1128 1133 1141 1151 1152 1153 1161 1162\n",
            " 1164 1178 1179 1181 1189 1193 1197 1202 1209 1214 1221 1237 1241 1244\n",
            " 1245 1250 1253 1254 1258 1261 1262 1264 1266 1267 1268 1269 1270 1272\n",
            " 1276 1283 1287 1292 1293 1295 1303 1304 1310 1312 1316 1319 1328 1336\n",
            " 1341 1343 1344 1346 1351 1356 1374 1375 1378 1379 1383 1389 1397 1398\n",
            " 1399 1401 1404 1408 1413 1420 1437 1439 1440 1441 1446 1447 1450 1451\n",
            " 1458 1461 1475 1479 1481 1487 1488 1493 1504 1505 1506 1511 1512 1529\n",
            " 1532 1533 1537 1538 1541 1549 1550 1553 1559 1560 1565 1570 1571 1572\n",
            " 1573 1586 1588 1601 1607 1610 1611 1613 1614 1620 1626 1627 1634 1641\n",
            " 1647 1653 1658 1665 1672 1681 1684 1686 1696 1697 1705 1708 1720 1721\n",
            " 1725 1727 1738 1739 1742 1743 1751 1757 1762 1764 1769 1770 1773 1775\n",
            " 1779 1783 1786 1787 1789 1800 1803 1807 1809 1812 1821 1829 1836 1837\n",
            " 1839 1844 1855 1857 1875 1877 1879 1887 1889 1894 1897 1900 1902 1903\n",
            " 1907 1908 1917 1921 1923 1937 1947 1948 1951 1953 1956 1957 1959 1961\n",
            " 1964 1967 1968 1970 1974 1975 1981 1983 1986 1987 1994 1998 2003 2007\n",
            " 2009 2011 2013 2015 2020 2029 2036 2037 2041 2043 2045 2046 2047 2057\n",
            " 2058 2064 2070 2082 2086 2088 2089 2090 2093 2095 2101 2104 2110 2111\n",
            " 2113 2114 2115 2118 2119 2127 2134 2139 2141 2146 2147 2149 2150 2157\n",
            " 2159 2161 2166 2167 2169 2178 2182 2188 2197 2201 2207 2215 2217 2219\n",
            " 2222 2223 2224 2225 2231 2232 2233 2241 2245 2257 2262 2272 2291 2292\n",
            " 2293 2294 2296 2306 2307 2308 2309 2314 2340 2346 2347 2348 2353 2359\n",
            " 2369 2373 2380 2381 2382 2386 2393 2396 2401 2402 2403 2409 2411 2414\n",
            " 2419 2424 2431 2432 2433 2436 2437 2445 2450 2451 2452 2458 2460 2462\n",
            " 2463 2466 2471 2476 2494 2496 2503 2507 2510 2528 2530 2534 2535 2536\n",
            " 2538 2540 2542 2553 2554 2558 2559 2564 2571 2572 2574 2575 2582 2592\n",
            " 2594 2605 2612 2620 2623 2637 2643 2654 2657 2668 2677 2678 2680 2683\n",
            " 2690 2691 2693 2696 2700 2702 2705 2707 2708 2713 2717 2724 2727 2733\n",
            " 2735 2737 2748 2752 2753 2755 2765 2772 2775 2776 2781 2797 2800 2805\n",
            " 2806 2812 2813 2814 2815 2822 2831 2832 2835 2839 2843 2851 2855 2856\n",
            " 2859 2871 2872 2873 2884 2885 2886 2890 2892]\n",
            "[CV 2/5; 8/10] END colsample_bylevel=0.5, colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.7;, score=-0.015 total time=  13.0s\n",
            "[CV 3/5; 8/10] START colsample_bylevel=0.5, colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.7\n",
            "[23:39:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   4   11   30   35   36   37   41   54   63   66   69   76   87   97\n",
            "   98  102  106  130  131  133  134  142  148  149  159  161  165  176\n",
            "  178  187  190  191  194  201  202  206  224  226  227  232  238  246\n",
            "  248  250  256  259  261  264  270  271  274  278  279  287  288  290\n",
            "  303  304  307  313  314  316  318  322  324  327  334  335  339  346\n",
            "  347  349  358  367  369  373  374  375  376  377  378  390  391  393\n",
            "  394  397  398  411  420  421  423  428  429  435  442  443  448  450\n",
            "  457  461  464  465  467  469  474  493  497  499  500  501  503  520\n",
            "  529  530  545  547  553  561  562  567  569  570  573  586  592  597\n",
            "  598  599  603  604  605  611  625  629  630  633  636  640  645  654\n",
            "  658  662  670  675  678  686  690  692  697  699  702  707  710  718\n",
            "  719  725  731  732  733  738  745  746  752  777  782  784  788  790\n",
            "  793  794  797  798  800  802  804  813  824  825  826  832  836  852\n",
            "  856  859  861  864  868  871  878  885  889  891  896  904  911  913\n",
            "  917  923  927  952  958  962  969  974  976  979  986  988  989  990\n",
            "  997  998  999 1001 1008 1009 1029 1034 1041 1048 1052 1056 1061 1069\n",
            " 1072 1073 1080 1082 1091 1092 1099 1101 1111 1115 1120 1123 1124 1130\n",
            " 1134 1137 1144 1150 1152 1156 1168 1171 1173 1179 1183 1188 1196 1200\n",
            " 1202 1203 1205 1212 1214 1215 1222 1255 1256 1257 1262 1273 1279 1281\n",
            " 1287 1291 1306 1307 1310 1314 1315 1320 1324 1326 1329 1330 1332 1336\n",
            " 1346 1349 1351 1352 1353 1354 1365 1394 1397 1398 1400 1405 1407 1411\n",
            " 1423 1432 1434 1442 1445 1448 1449 1467 1469 1472 1490 1494 1495 1510\n",
            " 1516 1519 1521 1522 1526 1533 1547 1548 1551 1553 1574 1581 1583 1585\n",
            " 1589 1590 1598 1601 1611 1613 1614 1619 1622 1623 1637 1642 1647 1649\n",
            " 1650 1660 1667 1671 1673 1677 1682 1684 1695 1696 1697 1705 1723 1725\n",
            " 1727 1730 1732 1734 1742 1749 1772 1781 1782 1786 1795 1798 1802 1804\n",
            " 1805 1806 1812 1813 1814 1819 1820 1821 1831 1842 1844 1847 1849 1859\n",
            " 1860 1866 1869 1873 1878 1880 1886 1892 1896 1898 1900 1910 1911 1912\n",
            " 1919 1920 1922 1926 1931 1934 1941 1943 1946 1947 1951 1952 1957 1971\n",
            " 1972 1974 1979 1982 1983 1986 1989 1995 2000 2004 2010 2013 2014 2015\n",
            " 2016 2020 2021 2022 2038 2041 2042 2044 2045 2047 2056 2057 2059 2071\n",
            " 2074 2088 2091 2096 2107 2108 2110 2111 2113 2114 2120 2121 2134 2136\n",
            " 2140 2141 2147 2148 2151 2158 2163 2165 2166 2169 2172 2173 2178 2185\n",
            " 2188 2189 2203 2208 2209 2213 2218 2226 2234 2235 2251 2254 2263 2264\n",
            " 2266 2269 2271 2277 2278 2280 2281 2287 2288 2293 2294 2296 2302 2305\n",
            " 2306 2308 2310 2312 2315 2316 2318 2319 2335 2353 2357 2363 2368 2369\n",
            " 2370 2372 2375 2378 2379 2380 2382 2384 2405 2407 2414 2417 2429 2434\n",
            " 2435 2445 2451 2452 2454 2455 2459 2460 2467 2468 2473 2475 2479 2485\n",
            " 2487 2488 2490 2501 2509 2524 2530 2533 2535 2537 2538 2540 2541 2542\n",
            " 2552 2556 2557 2562 2564 2565 2566 2578 2581 2582 2587 2588 2589 2595\n",
            " 2599 2604 2607 2610 2612 2614 2616 2621 2626 2627 2630 2631 2632 2633\n",
            " 2644 2646 2648 2651 2652 2653 2654 2657 2660 2664 2671 2678 2686 2692\n",
            " 2696 2697 2698 2703 2704 2706 2707 2709 2710 2711 2716 2725 2729 2731\n",
            " 2734 2735 2739 2747 2755 2757 2758 2767 2771 2775 2777 2781 2791 2796\n",
            " 2802 2805 2806 2808 2809 2811 2814 2816 2818 2824 2827 2829 2833 2835\n",
            " 2837 2846 2850 2855 2858 2861 2865 2871 2874 2875 2877 2878 2879 2883\n",
            " 2886 2890 2891]\n",
            "[CV 3/5; 8/10] END colsample_bylevel=0.5, colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.7;, score=-0.016 total time=  12.9s\n",
            "[CV 4/5; 8/10] START colsample_bylevel=0.5, colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.7\n",
            "[23:39:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    4   14   16   23   25   26   29   30   39   40   43   47   62\n",
            "   64   67   70   75   76   78   83   84   90   97   98  102  107  108\n",
            "  113  121  123  126  127  128  132  137  138  142  146  154  158  159\n",
            "  168  188  191  192  198  201  204  209  211  215  219  229  234  238\n",
            "  239  240  242  243  245  246  254  255  257  258  259  264  272  286\n",
            "  287  296  297  302  303  315  316  328  329  334  338  345  347  349\n",
            "  354  359  365  367  373  379  385  386  397  399  411  415  421  423\n",
            "  428  431  439  440  458  460  463  464  469  474  475  479  485  487\n",
            "  515  527  533  535  550  553  554  555  556  557  560  561  568  569\n",
            "  571  573  575  582  586  595  597  601  603  608  618  624  628  629\n",
            "  630  631  640  643  649  652  653  662  668  671  678  679  686  688\n",
            "  690  691  695  698  699  702  704  706  709  710  720  736  739  747\n",
            "  753  762  766  778  789  790  792  799  802  804  805  813  829  830\n",
            "  835  850  856  864  866  872  876  902  906  910  914  920  923  929\n",
            "  934  938  943  944  945  946  950  957  959  960  961  965  971  978\n",
            "  984  985  995  996  998  999 1000 1002 1005 1008 1012 1013 1014 1020\n",
            " 1036 1037 1049 1050 1059 1061 1062 1065 1066 1067 1070 1072 1074 1076\n",
            " 1082 1087 1090 1091 1093 1096 1101 1102 1104 1105 1112 1115 1118 1128\n",
            " 1134 1136 1141 1142 1143 1145 1150 1155 1163 1166 1181 1188 1189 1192\n",
            " 1193 1194 1198 1199 1200 1201 1202 1208 1209 1217 1222 1223 1225 1226\n",
            " 1229 1231 1232 1234 1238 1245 1247 1248 1249 1260 1261 1265 1266 1267\n",
            " 1269 1275 1276 1277 1289 1292 1302 1305 1310 1313 1314 1315 1317 1319\n",
            " 1321 1323 1324 1325 1328 1335 1344 1347 1349 1357 1361 1365 1369 1373\n",
            " 1379 1388 1391 1395 1397 1401 1407 1419 1421 1424 1426 1433 1438 1439\n",
            " 1441 1445 1461 1463 1464 1478 1482 1492 1493 1498 1499 1501 1503 1505\n",
            " 1511 1514 1516 1517 1519 1521 1524 1528 1529 1533 1534 1538 1539 1557\n",
            " 1558 1559 1579 1583 1587 1590 1602 1603 1613 1617 1619 1622 1626 1631\n",
            " 1641 1651 1654 1655 1657 1663 1668 1670 1688 1695 1706 1711 1712 1714\n",
            " 1719 1727 1728 1732 1734 1735 1736 1740 1746 1748 1761 1762 1767 1768\n",
            " 1778 1781 1783 1785 1788 1791 1795 1796 1802 1805 1810 1811 1813 1817\n",
            " 1818 1819 1822 1823 1839 1843 1862 1865 1873 1874 1875 1876 1877 1882\n",
            " 1887 1894 1896 1902 1905 1914 1915 1917 1925 1929 1931 1938 1939 1944\n",
            " 1952 1953 1954 1960 1965 1979 1980 1984 1986 1991 1993 1996 2001 2010\n",
            " 2011 2019 2024 2025 2032 2033 2036 2038 2040 2041 2042 2044 2047 2048\n",
            " 2051 2054 2056 2059 2069 2071 2078 2079 2080 2085 2087 2094 2097 2099\n",
            " 2104 2110 2115 2120 2121 2122 2129 2130 2135 2141 2143 2145 2148 2150\n",
            " 2157 2158 2160 2162 2166 2169 2175 2184 2195 2199 2202 2205 2213 2215\n",
            " 2217 2219 2220 2223 2224 2225 2228 2230 2231 2234 2235 2237 2248 2249\n",
            " 2253 2255 2257 2258 2259 2262 2277 2278 2282 2283 2291 2292 2297 2310\n",
            " 2314 2317 2320 2325 2326 2332 2337 2338 2340 2341 2343 2345 2349 2353\n",
            " 2354 2358 2360 2362 2376 2383 2384 2387 2390 2391 2396 2399 2400 2404\n",
            " 2408 2413 2415 2416 2417 2418 2421 2422 2427 2429 2432 2433 2450 2451\n",
            " 2454 2457 2458 2460 2461 2465 2467 2470 2471 2475 2480 2487 2494 2498\n",
            " 2502 2507 2523 2524 2531 2533 2536 2538 2543 2545 2547 2549 2551 2553\n",
            " 2554 2557 2561 2563 2567 2570 2571 2572 2579 2582 2583 2585 2586 2588\n",
            " 2594 2595 2609 2613 2615 2617 2620 2623 2624 2625 2632 2633 2640 2647\n",
            " 2649 2650 2655 2657 2662 2664 2668 2669 2671 2689 2699 2701 2704 2706\n",
            " 2707 2710 2717 2720 2723 2726 2733 2735 2736 2747 2754 2755 2757 2763\n",
            " 2771 2779 2786 2790 2791 2792 2796 2800 2802 2805 2809 2832 2840 2845\n",
            " 2846 2850 2855 2860 2861 2863 2869 2870 2876 2877 2879 2883 2887 2889]\n",
            "[CV 4/5; 8/10] END colsample_bylevel=0.5, colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.7;, score=-0.015 total time=  12.9s\n",
            "[CV 5/5; 8/10] START colsample_bylevel=0.5, colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.7\n",
            "[23:39:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   5   11   14   25   27   37   41   42   51   52   55   56   59   60\n",
            "   76   81   83   90   96  100  108  109  114  116  119  124  128  135\n",
            "  137  142  145  147  150  157  164  167  170  178  185  190  192  194\n",
            "  198  202  211  214  222  223  237  238  243  246  252  255  258  260\n",
            "  261  268  270  271  276  283  286  288  294  302  318  322  326  331\n",
            "  335  336  348  350  351  353  354  370  375  380  382  383  390  393\n",
            "  403  404  406  407  409  421  424  433  438  440  442  455  463  473\n",
            "  476  478  479  481  482  487  489  497  499  502  504  509  510  516\n",
            "  517  521  529  533  536  540  541  546  552  556  557  560  566  572\n",
            "  575  578  579  581  595  602  603  612  614  617  618  622  626  629\n",
            "  639  642  644  657  660  666  668  673  675  676  688  689  690  692\n",
            "  695  696  697  703  705  715  717  718  719  728  730  733  740  747\n",
            "  755  759  761  764  765  773  776  779  782  784  786  794  797  799\n",
            "  800  810  811  816  822  830  831  833  836  855  858  864  868  879\n",
            "  880  896  898  904  910  917  925  928  930  932  940  942  948  950\n",
            "  963  966  968  970  971  972  974  984  987  989  992  993  997 1002\n",
            " 1006 1010 1014 1023 1029 1032 1035 1041 1046 1050 1051 1057 1062 1063\n",
            " 1065 1067 1068 1069 1072 1076 1077 1088 1089 1093 1101 1107 1114 1118\n",
            " 1121 1128 1130 1131 1138 1139 1142 1144 1150 1151 1155 1161 1167 1175\n",
            " 1177 1181 1187 1194 1196 1199 1201 1202 1205 1222 1223 1225 1230 1231\n",
            " 1234 1246 1250 1252 1253 1255 1263 1270 1272 1273 1277 1279 1285 1289\n",
            " 1291 1297 1298 1303 1304 1306 1307 1311 1321 1328 1331 1336 1337 1341\n",
            " 1347 1355 1358 1364 1370 1372 1374 1376 1379 1380 1381 1383 1392 1394\n",
            " 1399 1404 1409 1412 1419 1420 1422 1431 1433 1437 1438 1441 1447 1448\n",
            " 1449 1454 1458 1459 1463 1465 1467 1468 1471 1486 1491 1497 1499 1501\n",
            " 1508 1509 1510 1514 1522 1524 1527 1533 1537 1542 1551 1554 1561 1563\n",
            " 1565 1567 1569 1571 1572 1574 1577 1581 1583 1584 1588 1595 1596 1598\n",
            " 1600 1608 1612 1617 1621 1624 1630 1635 1636 1637 1640 1643 1653 1656\n",
            " 1657 1661 1668 1672 1673 1676 1679 1681 1686 1687 1688 1696 1699 1701\n",
            " 1709 1710 1720 1722 1725 1726 1731 1733 1737 1738 1741 1746 1747 1749\n",
            " 1751 1754 1756 1763 1765 1772 1782 1783 1787 1788 1792 1796 1802 1809\n",
            " 1817 1819 1822 1834 1835 1848 1851 1860 1868 1876 1880 1893 1894 1900\n",
            " 1905 1929 1934 1938 1947 1948 1953 1956 1967 1969 1976 1978 1988 1989\n",
            " 1994 1995 1996 1999 2000 2005 2009 2011 2013 2020 2026 2027 2032 2045\n",
            " 2062 2063 2072 2074 2075 2081 2088 2089 2090 2099 2101 2110 2111 2117\n",
            " 2120 2129 2131 2132 2133 2138 2142 2143 2144 2147 2151 2153 2154 2166\n",
            " 2175 2178 2185 2188 2198 2202 2204 2206 2207 2209 2224 2230 2231 2237\n",
            " 2248 2249 2251 2258 2261 2262 2264 2272 2276 2280 2281 2282 2283 2285\n",
            " 2288 2295 2297 2300 2308 2314 2315 2316 2317 2320 2321 2327 2328 2332\n",
            " 2336 2337 2351 2359 2368 2370 2373 2383 2392 2394 2404 2405 2408 2410\n",
            " 2425 2435 2439 2440 2453 2458 2467 2470 2473 2478 2481 2483 2487 2489\n",
            " 2490 2499 2500 2505 2512 2513 2517 2522 2523 2524 2527 2528 2529 2533\n",
            " 2538 2541 2549 2551 2578 2589 2596 2601 2610 2627 2630 2633 2643 2645\n",
            " 2649 2653 2655 2672 2673 2679 2690 2692 2697 2698 2699 2705 2714 2718\n",
            " 2727 2732 2744 2745 2746 2747 2751 2757 2758 2761 2763 2767 2781 2782\n",
            " 2786 2789 2795 2801 2806 2810 2812 2814 2816 2818 2824 2826 2832 2833\n",
            " 2838 2841 2843 2844 2847 2850 2851 2853 2868 2871 2876 2878 2880 2881\n",
            " 2887 2888 2889 2892]\n",
            "[CV 5/5; 8/10] END colsample_bylevel=0.5, colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.7;, score=-0.016 total time=  13.0s\n",
            "[CV 1/5; 9/10] START colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7\n",
            "[23:39:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    8   11   17   19   20   23   33   34   36   39   43   47   52\n",
            "   55   65   67   70   74   76   78   80   85   87   89   97   98  102\n",
            "  108  109  111  114  117  119  121  123  124  128  130  135  138  140\n",
            "  149  162  169  171  174  175  177  180  188  189  190  192  195  202\n",
            "  212  224  227  234  235  237  238  242  243  245  247  248  251  252\n",
            "  257  262  264  267  271  274  275  277  279  280  287  292  297  304\n",
            "  306  307  314  319  327  332  334  336  340  345  346  347  350  352\n",
            "  354  358  368  375  379  381  385  388  390  391  394  395  402  404\n",
            "  412  418  422  423  424  428  430  438  443  447  450  459  468  477\n",
            "  479  484  485  486  488  495  499  511  522  529  532  534  536  541\n",
            "  543  560  562  563  568  570  577  586  589  590  594  599  603  613\n",
            "  615  617  624  625  627  634  635  639  645  650  667  676  679  689\n",
            "  690  691  695  696  700  703  707  715  718  720  726  728  730  733\n",
            "  737  749  755  759  763  764  765  773  774  779  786  798  802  808\n",
            "  822  824  829  832  836  852  856  862  865  867  870  872  873  874\n",
            "  884  888  893  894  899  900  917  920  922  923  926  940  941  944\n",
            "  959  965  968  974  976  978  979  981  983  989  990  991  995  996\n",
            " 1001 1009 1012 1015 1025 1028 1038 1044 1049 1070 1071 1079 1080 1081\n",
            " 1083 1089 1090 1096 1098 1104 1105 1111 1113 1120 1121 1123 1125 1127\n",
            " 1131 1135 1141 1145 1151 1154 1156 1157 1158 1163 1164 1166 1179 1183\n",
            " 1192 1195 1202 1205 1206 1209 1210 1224 1226 1239 1240 1245 1256 1259\n",
            " 1260 1262 1263 1270 1273 1280 1288 1289 1292 1295 1296 1300 1304 1309\n",
            " 1322 1330 1332 1338 1340 1343 1346 1358 1363 1377 1378 1380 1383 1384\n",
            " 1391 1393 1401 1402 1403 1410 1417 1418 1422 1438 1444 1445 1450 1453\n",
            " 1455 1456 1464 1466 1468 1469 1475 1482 1489 1491 1494 1499 1505 1513\n",
            " 1528 1532 1535 1536 1537 1538 1539 1545 1551 1554 1555 1557 1559 1561\n",
            " 1562 1565 1566 1573 1579 1588 1597 1599 1602 1607 1609 1612 1614 1615\n",
            " 1618 1622 1625 1630 1631 1643 1645 1649 1650 1656 1675 1676 1679 1684\n",
            " 1685 1691 1697 1701 1705 1706 1707 1709 1716 1726 1727 1728 1740 1742\n",
            " 1748 1751 1753 1763 1768 1769 1770 1786 1794 1798 1799 1801 1804 1812\n",
            " 1814 1821 1822 1825 1835 1841 1842 1846 1848 1856 1857 1874 1875 1879\n",
            " 1880 1892 1907 1917 1927 1930 1940 1942 1949 1952 1957 1966 1971 1974\n",
            " 1975 1976 1979 1981 1984 1987 1989 1992 1993 1995 2002 2003 2007 2010\n",
            " 2015 2027 2028 2029 2031 2035 2037 2049 2054 2056 2060 2061 2066 2070\n",
            " 2071 2075 2076 2082 2085 2087 2094 2098 2110 2111 2112 2113 2122 2123\n",
            " 2141 2142 2145 2157 2162 2166 2167 2172 2177 2180 2181 2183 2186 2195\n",
            " 2202 2209 2213 2215 2219 2220 2222 2224 2232 2233 2240 2244 2246 2248\n",
            " 2253 2259 2266 2276 2277 2280 2282 2284 2291 2298 2309 2311 2313 2322\n",
            " 2338 2339 2340 2341 2346 2347 2348 2350 2361 2363 2364 2365 2366 2369\n",
            " 2374 2375 2380 2382 2385 2386 2396 2406 2410 2413 2416 2420 2422 2427\n",
            " 2436 2438 2439 2440 2441 2444 2445 2448 2449 2453 2456 2459 2461 2463\n",
            " 2464 2469 2472 2474 2483 2494 2498 2505 2507 2509 2514 2517 2522 2524\n",
            " 2526 2531 2538 2547 2550 2554 2557 2561 2566 2571 2574 2577 2581 2585\n",
            " 2590 2594 2600 2603 2606 2612 2618 2620 2622 2625 2633 2642 2647 2654\n",
            " 2655 2656 2661 2665 2669 2671 2672 2677 2684 2694 2700 2701 2704 2706\n",
            " 2709 2712 2713 2714 2715 2725 2727 2730 2735 2738 2742 2743 2748 2756\n",
            " 2760 2763 2767 2772 2774 2776 2779 2781 2785 2786 2790 2792 2805 2806\n",
            " 2807 2810 2820 2827 2832 2841 2847 2852 2857 2862 2865 2867 2871 2873\n",
            " 2878 2881 2884 2887 2889]\n",
            "[CV 1/5; 9/10] END colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7;, score=-0.006 total time=  50.9s\n",
            "[CV 2/5; 9/10] START colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7\n",
            "[23:40:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   3    5    7   12   14   20   22   25   27   31   32   33   43   47\n",
            "   51   62   64   69   70   71   74   76   88   89  109  111  113  115\n",
            "  125  133  137  141  143  145  148  156  159  174  175  176  180  190\n",
            "  191  195  199  200  203  205  207  209  210  212  213  215  220  227\n",
            "  231  238  252  258  262  268  269  272  310  311  314  315  332  334\n",
            "  356  361  362  363  364  367  368  369  371  373  377  380  384  385\n",
            "  390  399  403  407  409  410  417  429  431  435  444  449  464  465\n",
            "  466  467  470  474  475  480  489  490  492  493  498  499  501  505\n",
            "  509  512  513  517  518  521  524  529  533  534  537  539  541  545\n",
            "  549  550  558  560  564  573  574  577  580  584  585  586  587  594\n",
            "  598  605  606  612  624  627  628  630  642  647  649  651  663  665\n",
            "  679  680  691  696  701  710  711  716  727  731  733  736  744  750\n",
            "  751  759  760  763  765  771  773  776  780  789  794  806  809  812\n",
            "  814  820  821  833  838  844  855  859  866  868  884  890  894  902\n",
            "  905  907  909  916  917  921  922  931  934  937  958  968  969  973\n",
            "  979  981  990 1004 1010 1014 1015 1018 1033 1036 1037 1038 1040 1042\n",
            " 1043 1049 1068 1069 1076 1081 1084 1088 1090 1092 1094 1097 1100 1101\n",
            " 1105 1107 1116 1118 1123 1124 1128 1133 1141 1151 1152 1153 1161 1162\n",
            " 1164 1178 1179 1181 1189 1193 1197 1202 1209 1214 1221 1237 1241 1244\n",
            " 1245 1250 1253 1254 1258 1261 1262 1264 1266 1267 1268 1269 1270 1272\n",
            " 1276 1283 1287 1292 1293 1295 1303 1304 1310 1312 1316 1319 1328 1336\n",
            " 1341 1343 1344 1346 1351 1356 1374 1375 1378 1379 1383 1389 1397 1398\n",
            " 1399 1401 1404 1408 1413 1420 1437 1439 1440 1441 1446 1447 1450 1451\n",
            " 1458 1461 1475 1479 1481 1487 1488 1493 1504 1505 1506 1511 1512 1529\n",
            " 1532 1533 1537 1538 1541 1549 1550 1553 1559 1560 1565 1570 1571 1572\n",
            " 1573 1586 1588 1601 1607 1610 1611 1613 1614 1620 1626 1627 1634 1641\n",
            " 1647 1653 1658 1665 1672 1681 1684 1686 1696 1697 1705 1708 1720 1721\n",
            " 1725 1727 1738 1739 1742 1743 1751 1757 1762 1764 1769 1770 1773 1775\n",
            " 1779 1783 1786 1787 1789 1800 1803 1807 1809 1812 1821 1829 1836 1837\n",
            " 1839 1844 1855 1857 1875 1877 1879 1887 1889 1894 1897 1900 1902 1903\n",
            " 1907 1908 1917 1921 1923 1937 1947 1948 1951 1953 1956 1957 1959 1961\n",
            " 1964 1967 1968 1970 1974 1975 1981 1983 1986 1987 1994 1998 2003 2007\n",
            " 2009 2011 2013 2015 2020 2029 2036 2037 2041 2043 2045 2046 2047 2057\n",
            " 2058 2064 2070 2082 2086 2088 2089 2090 2093 2095 2101 2104 2110 2111\n",
            " 2113 2114 2115 2118 2119 2127 2134 2139 2141 2146 2147 2149 2150 2157\n",
            " 2159 2161 2166 2167 2169 2178 2182 2188 2197 2201 2207 2215 2217 2219\n",
            " 2222 2223 2224 2225 2231 2232 2233 2241 2245 2257 2262 2272 2291 2292\n",
            " 2293 2294 2296 2306 2307 2308 2309 2314 2340 2346 2347 2348 2353 2359\n",
            " 2369 2373 2380 2381 2382 2386 2393 2396 2401 2402 2403 2409 2411 2414\n",
            " 2419 2424 2431 2432 2433 2436 2437 2445 2450 2451 2452 2458 2460 2462\n",
            " 2463 2466 2471 2476 2494 2496 2503 2507 2510 2528 2530 2534 2535 2536\n",
            " 2538 2540 2542 2553 2554 2558 2559 2564 2571 2572 2574 2575 2582 2592\n",
            " 2594 2605 2612 2620 2623 2637 2643 2654 2657 2668 2677 2678 2680 2683\n",
            " 2690 2691 2693 2696 2700 2702 2705 2707 2708 2713 2717 2724 2727 2733\n",
            " 2735 2737 2748 2752 2753 2755 2765 2772 2775 2776 2781 2797 2800 2805\n",
            " 2806 2812 2813 2814 2815 2822 2831 2832 2835 2839 2843 2851 2855 2856\n",
            " 2859 2871 2872 2873 2884 2885 2886 2890 2892]\n",
            "[CV 2/5; 9/10] END colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7;, score=-0.004 total time=  51.7s\n",
            "[CV 3/5; 9/10] START colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7\n",
            "[23:41:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   4   11   30   35   36   37   41   54   63   66   69   76   87   97\n",
            "   98  102  106  130  131  133  134  142  148  149  159  161  165  176\n",
            "  178  187  190  191  194  201  202  206  224  226  227  232  238  246\n",
            "  248  250  256  259  261  264  270  271  274  278  279  287  288  290\n",
            "  303  304  307  313  314  316  318  322  324  327  334  335  339  346\n",
            "  347  349  358  367  369  373  374  375  376  377  378  390  391  393\n",
            "  394  397  398  411  420  421  423  428  429  435  442  443  448  450\n",
            "  457  461  464  465  467  469  474  493  497  499  500  501  503  520\n",
            "  529  530  545  547  553  561  562  567  569  570  573  586  592  597\n",
            "  598  599  603  604  605  611  625  629  630  633  636  640  645  654\n",
            "  658  662  670  675  678  686  690  692  697  699  702  707  710  718\n",
            "  719  725  731  732  733  738  745  746  752  777  782  784  788  790\n",
            "  793  794  797  798  800  802  804  813  824  825  826  832  836  852\n",
            "  856  859  861  864  868  871  878  885  889  891  896  904  911  913\n",
            "  917  923  927  952  958  962  969  974  976  979  986  988  989  990\n",
            "  997  998  999 1001 1008 1009 1029 1034 1041 1048 1052 1056 1061 1069\n",
            " 1072 1073 1080 1082 1091 1092 1099 1101 1111 1115 1120 1123 1124 1130\n",
            " 1134 1137 1144 1150 1152 1156 1168 1171 1173 1179 1183 1188 1196 1200\n",
            " 1202 1203 1205 1212 1214 1215 1222 1255 1256 1257 1262 1273 1279 1281\n",
            " 1287 1291 1306 1307 1310 1314 1315 1320 1324 1326 1329 1330 1332 1336\n",
            " 1346 1349 1351 1352 1353 1354 1365 1394 1397 1398 1400 1405 1407 1411\n",
            " 1423 1432 1434 1442 1445 1448 1449 1467 1469 1472 1490 1494 1495 1510\n",
            " 1516 1519 1521 1522 1526 1533 1547 1548 1551 1553 1574 1581 1583 1585\n",
            " 1589 1590 1598 1601 1611 1613 1614 1619 1622 1623 1637 1642 1647 1649\n",
            " 1650 1660 1667 1671 1673 1677 1682 1684 1695 1696 1697 1705 1723 1725\n",
            " 1727 1730 1732 1734 1742 1749 1772 1781 1782 1786 1795 1798 1802 1804\n",
            " 1805 1806 1812 1813 1814 1819 1820 1821 1831 1842 1844 1847 1849 1859\n",
            " 1860 1866 1869 1873 1878 1880 1886 1892 1896 1898 1900 1910 1911 1912\n",
            " 1919 1920 1922 1926 1931 1934 1941 1943 1946 1947 1951 1952 1957 1971\n",
            " 1972 1974 1979 1982 1983 1986 1989 1995 2000 2004 2010 2013 2014 2015\n",
            " 2016 2020 2021 2022 2038 2041 2042 2044 2045 2047 2056 2057 2059 2071\n",
            " 2074 2088 2091 2096 2107 2108 2110 2111 2113 2114 2120 2121 2134 2136\n",
            " 2140 2141 2147 2148 2151 2158 2163 2165 2166 2169 2172 2173 2178 2185\n",
            " 2188 2189 2203 2208 2209 2213 2218 2226 2234 2235 2251 2254 2263 2264\n",
            " 2266 2269 2271 2277 2278 2280 2281 2287 2288 2293 2294 2296 2302 2305\n",
            " 2306 2308 2310 2312 2315 2316 2318 2319 2335 2353 2357 2363 2368 2369\n",
            " 2370 2372 2375 2378 2379 2380 2382 2384 2405 2407 2414 2417 2429 2434\n",
            " 2435 2445 2451 2452 2454 2455 2459 2460 2467 2468 2473 2475 2479 2485\n",
            " 2487 2488 2490 2501 2509 2524 2530 2533 2535 2537 2538 2540 2541 2542\n",
            " 2552 2556 2557 2562 2564 2565 2566 2578 2581 2582 2587 2588 2589 2595\n",
            " 2599 2604 2607 2610 2612 2614 2616 2621 2626 2627 2630 2631 2632 2633\n",
            " 2644 2646 2648 2651 2652 2653 2654 2657 2660 2664 2671 2678 2686 2692\n",
            " 2696 2697 2698 2703 2704 2706 2707 2709 2710 2711 2716 2725 2729 2731\n",
            " 2734 2735 2739 2747 2755 2757 2758 2767 2771 2775 2777 2781 2791 2796\n",
            " 2802 2805 2806 2808 2809 2811 2814 2816 2818 2824 2827 2829 2833 2835\n",
            " 2837 2846 2850 2855 2858 2861 2865 2871 2874 2875 2877 2878 2879 2883\n",
            " 2886 2890 2891]\n",
            "[CV 3/5; 9/10] END colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7;, score=-0.004 total time=  51.3s\n",
            "[CV 4/5; 9/10] START colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7\n",
            "[23:42:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    4   14   16   23   25   26   29   30   39   40   43   47   62\n",
            "   64   67   70   75   76   78   83   84   90   97   98  102  107  108\n",
            "  113  121  123  126  127  128  132  137  138  142  146  154  158  159\n",
            "  168  188  191  192  198  201  204  209  211  215  219  229  234  238\n",
            "  239  240  242  243  245  246  254  255  257  258  259  264  272  286\n",
            "  287  296  297  302  303  315  316  328  329  334  338  345  347  349\n",
            "  354  359  365  367  373  379  385  386  397  399  411  415  421  423\n",
            "  428  431  439  440  458  460  463  464  469  474  475  479  485  487\n",
            "  515  527  533  535  550  553  554  555  556  557  560  561  568  569\n",
            "  571  573  575  582  586  595  597  601  603  608  618  624  628  629\n",
            "  630  631  640  643  649  652  653  662  668  671  678  679  686  688\n",
            "  690  691  695  698  699  702  704  706  709  710  720  736  739  747\n",
            "  753  762  766  778  789  790  792  799  802  804  805  813  829  830\n",
            "  835  850  856  864  866  872  876  902  906  910  914  920  923  929\n",
            "  934  938  943  944  945  946  950  957  959  960  961  965  971  978\n",
            "  984  985  995  996  998  999 1000 1002 1005 1008 1012 1013 1014 1020\n",
            " 1036 1037 1049 1050 1059 1061 1062 1065 1066 1067 1070 1072 1074 1076\n",
            " 1082 1087 1090 1091 1093 1096 1101 1102 1104 1105 1112 1115 1118 1128\n",
            " 1134 1136 1141 1142 1143 1145 1150 1155 1163 1166 1181 1188 1189 1192\n",
            " 1193 1194 1198 1199 1200 1201 1202 1208 1209 1217 1222 1223 1225 1226\n",
            " 1229 1231 1232 1234 1238 1245 1247 1248 1249 1260 1261 1265 1266 1267\n",
            " 1269 1275 1276 1277 1289 1292 1302 1305 1310 1313 1314 1315 1317 1319\n",
            " 1321 1323 1324 1325 1328 1335 1344 1347 1349 1357 1361 1365 1369 1373\n",
            " 1379 1388 1391 1395 1397 1401 1407 1419 1421 1424 1426 1433 1438 1439\n",
            " 1441 1445 1461 1463 1464 1478 1482 1492 1493 1498 1499 1501 1503 1505\n",
            " 1511 1514 1516 1517 1519 1521 1524 1528 1529 1533 1534 1538 1539 1557\n",
            " 1558 1559 1579 1583 1587 1590 1602 1603 1613 1617 1619 1622 1626 1631\n",
            " 1641 1651 1654 1655 1657 1663 1668 1670 1688 1695 1706 1711 1712 1714\n",
            " 1719 1727 1728 1732 1734 1735 1736 1740 1746 1748 1761 1762 1767 1768\n",
            " 1778 1781 1783 1785 1788 1791 1795 1796 1802 1805 1810 1811 1813 1817\n",
            " 1818 1819 1822 1823 1839 1843 1862 1865 1873 1874 1875 1876 1877 1882\n",
            " 1887 1894 1896 1902 1905 1914 1915 1917 1925 1929 1931 1938 1939 1944\n",
            " 1952 1953 1954 1960 1965 1979 1980 1984 1986 1991 1993 1996 2001 2010\n",
            " 2011 2019 2024 2025 2032 2033 2036 2038 2040 2041 2042 2044 2047 2048\n",
            " 2051 2054 2056 2059 2069 2071 2078 2079 2080 2085 2087 2094 2097 2099\n",
            " 2104 2110 2115 2120 2121 2122 2129 2130 2135 2141 2143 2145 2148 2150\n",
            " 2157 2158 2160 2162 2166 2169 2175 2184 2195 2199 2202 2205 2213 2215\n",
            " 2217 2219 2220 2223 2224 2225 2228 2230 2231 2234 2235 2237 2248 2249\n",
            " 2253 2255 2257 2258 2259 2262 2277 2278 2282 2283 2291 2292 2297 2310\n",
            " 2314 2317 2320 2325 2326 2332 2337 2338 2340 2341 2343 2345 2349 2353\n",
            " 2354 2358 2360 2362 2376 2383 2384 2387 2390 2391 2396 2399 2400 2404\n",
            " 2408 2413 2415 2416 2417 2418 2421 2422 2427 2429 2432 2433 2450 2451\n",
            " 2454 2457 2458 2460 2461 2465 2467 2470 2471 2475 2480 2487 2494 2498\n",
            " 2502 2507 2523 2524 2531 2533 2536 2538 2543 2545 2547 2549 2551 2553\n",
            " 2554 2557 2561 2563 2567 2570 2571 2572 2579 2582 2583 2585 2586 2588\n",
            " 2594 2595 2609 2613 2615 2617 2620 2623 2624 2625 2632 2633 2640 2647\n",
            " 2649 2650 2655 2657 2662 2664 2668 2669 2671 2689 2699 2701 2704 2706\n",
            " 2707 2710 2717 2720 2723 2726 2733 2735 2736 2747 2754 2755 2757 2763\n",
            " 2771 2779 2786 2790 2791 2792 2796 2800 2802 2805 2809 2832 2840 2845\n",
            " 2846 2850 2855 2860 2861 2863 2869 2870 2876 2877 2879 2883 2887 2889]\n",
            "[CV 4/5; 9/10] END colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7;, score=-0.004 total time=  50.9s\n",
            "[CV 5/5; 9/10] START colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7\n",
            "[23:43:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   5   11   14   25   27   37   41   42   51   52   55   56   59   60\n",
            "   76   81   83   90   96  100  108  109  114  116  119  124  128  135\n",
            "  137  142  145  147  150  157  164  167  170  178  185  190  192  194\n",
            "  198  202  211  214  222  223  237  238  243  246  252  255  258  260\n",
            "  261  268  270  271  276  283  286  288  294  302  318  322  326  331\n",
            "  335  336  348  350  351  353  354  370  375  380  382  383  390  393\n",
            "  403  404  406  407  409  421  424  433  438  440  442  455  463  473\n",
            "  476  478  479  481  482  487  489  497  499  502  504  509  510  516\n",
            "  517  521  529  533  536  540  541  546  552  556  557  560  566  572\n",
            "  575  578  579  581  595  602  603  612  614  617  618  622  626  629\n",
            "  639  642  644  657  660  666  668  673  675  676  688  689  690  692\n",
            "  695  696  697  703  705  715  717  718  719  728  730  733  740  747\n",
            "  755  759  761  764  765  773  776  779  782  784  786  794  797  799\n",
            "  800  810  811  816  822  830  831  833  836  855  858  864  868  879\n",
            "  880  896  898  904  910  917  925  928  930  932  940  942  948  950\n",
            "  963  966  968  970  971  972  974  984  987  989  992  993  997 1002\n",
            " 1006 1010 1014 1023 1029 1032 1035 1041 1046 1050 1051 1057 1062 1063\n",
            " 1065 1067 1068 1069 1072 1076 1077 1088 1089 1093 1101 1107 1114 1118\n",
            " 1121 1128 1130 1131 1138 1139 1142 1144 1150 1151 1155 1161 1167 1175\n",
            " 1177 1181 1187 1194 1196 1199 1201 1202 1205 1222 1223 1225 1230 1231\n",
            " 1234 1246 1250 1252 1253 1255 1263 1270 1272 1273 1277 1279 1285 1289\n",
            " 1291 1297 1298 1303 1304 1306 1307 1311 1321 1328 1331 1336 1337 1341\n",
            " 1347 1355 1358 1364 1370 1372 1374 1376 1379 1380 1381 1383 1392 1394\n",
            " 1399 1404 1409 1412 1419 1420 1422 1431 1433 1437 1438 1441 1447 1448\n",
            " 1449 1454 1458 1459 1463 1465 1467 1468 1471 1486 1491 1497 1499 1501\n",
            " 1508 1509 1510 1514 1522 1524 1527 1533 1537 1542 1551 1554 1561 1563\n",
            " 1565 1567 1569 1571 1572 1574 1577 1581 1583 1584 1588 1595 1596 1598\n",
            " 1600 1608 1612 1617 1621 1624 1630 1635 1636 1637 1640 1643 1653 1656\n",
            " 1657 1661 1668 1672 1673 1676 1679 1681 1686 1687 1688 1696 1699 1701\n",
            " 1709 1710 1720 1722 1725 1726 1731 1733 1737 1738 1741 1746 1747 1749\n",
            " 1751 1754 1756 1763 1765 1772 1782 1783 1787 1788 1792 1796 1802 1809\n",
            " 1817 1819 1822 1834 1835 1848 1851 1860 1868 1876 1880 1893 1894 1900\n",
            " 1905 1929 1934 1938 1947 1948 1953 1956 1967 1969 1976 1978 1988 1989\n",
            " 1994 1995 1996 1999 2000 2005 2009 2011 2013 2020 2026 2027 2032 2045\n",
            " 2062 2063 2072 2074 2075 2081 2088 2089 2090 2099 2101 2110 2111 2117\n",
            " 2120 2129 2131 2132 2133 2138 2142 2143 2144 2147 2151 2153 2154 2166\n",
            " 2175 2178 2185 2188 2198 2202 2204 2206 2207 2209 2224 2230 2231 2237\n",
            " 2248 2249 2251 2258 2261 2262 2264 2272 2276 2280 2281 2282 2283 2285\n",
            " 2288 2295 2297 2300 2308 2314 2315 2316 2317 2320 2321 2327 2328 2332\n",
            " 2336 2337 2351 2359 2368 2370 2373 2383 2392 2394 2404 2405 2408 2410\n",
            " 2425 2435 2439 2440 2453 2458 2467 2470 2473 2478 2481 2483 2487 2489\n",
            " 2490 2499 2500 2505 2512 2513 2517 2522 2523 2524 2527 2528 2529 2533\n",
            " 2538 2541 2549 2551 2578 2589 2596 2601 2610 2627 2630 2633 2643 2645\n",
            " 2649 2653 2655 2672 2673 2679 2690 2692 2697 2698 2699 2705 2714 2718\n",
            " 2727 2732 2744 2745 2746 2747 2751 2757 2758 2761 2763 2767 2781 2782\n",
            " 2786 2789 2795 2801 2806 2810 2812 2814 2816 2818 2824 2826 2832 2833\n",
            " 2838 2841 2843 2844 2847 2850 2851 2853 2868 2871 2876 2878 2880 2881\n",
            " 2887 2888 2889 2892]\n",
            "[CV 5/5; 9/10] END colsample_bylevel=0.7, colsample_bytree=0.8999999999999999, learning_rate=0.5, max_depth=20, n_estimators=1000, subsample=0.7;, score=-0.004 total time=  51.3s\n",
            "[CV 1/5; 10/10] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, subsample=0.6\n",
            "[23:44:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    8   11   17   19   20   23   33   34   36   39   43   47   52\n",
            "   55   65   67   70   74   76   78   80   85   87   89   97   98  102\n",
            "  108  109  111  114  117  119  121  123  124  128  130  135  138  140\n",
            "  149  162  169  171  174  175  177  180  188  189  190  192  195  202\n",
            "  212  224  227  234  235  237  238  242  243  245  247  248  251  252\n",
            "  257  262  264  267  271  274  275  277  279  280  287  292  297  304\n",
            "  306  307  314  319  327  332  334  336  340  345  346  347  350  352\n",
            "  354  358  368  375  379  381  385  388  390  391  394  395  402  404\n",
            "  412  418  422  423  424  428  430  438  443  447  450  459  468  477\n",
            "  479  484  485  486  488  495  499  511  522  529  532  534  536  541\n",
            "  543  560  562  563  568  570  577  586  589  590  594  599  603  613\n",
            "  615  617  624  625  627  634  635  639  645  650  667  676  679  689\n",
            "  690  691  695  696  700  703  707  715  718  720  726  728  730  733\n",
            "  737  749  755  759  763  764  765  773  774  779  786  798  802  808\n",
            "  822  824  829  832  836  852  856  862  865  867  870  872  873  874\n",
            "  884  888  893  894  899  900  917  920  922  923  926  940  941  944\n",
            "  959  965  968  974  976  978  979  981  983  989  990  991  995  996\n",
            " 1001 1009 1012 1015 1025 1028 1038 1044 1049 1070 1071 1079 1080 1081\n",
            " 1083 1089 1090 1096 1098 1104 1105 1111 1113 1120 1121 1123 1125 1127\n",
            " 1131 1135 1141 1145 1151 1154 1156 1157 1158 1163 1164 1166 1179 1183\n",
            " 1192 1195 1202 1205 1206 1209 1210 1224 1226 1239 1240 1245 1256 1259\n",
            " 1260 1262 1263 1270 1273 1280 1288 1289 1292 1295 1296 1300 1304 1309\n",
            " 1322 1330 1332 1338 1340 1343 1346 1358 1363 1377 1378 1380 1383 1384\n",
            " 1391 1393 1401 1402 1403 1410 1417 1418 1422 1438 1444 1445 1450 1453\n",
            " 1455 1456 1464 1466 1468 1469 1475 1482 1489 1491 1494 1499 1505 1513\n",
            " 1528 1532 1535 1536 1537 1538 1539 1545 1551 1554 1555 1557 1559 1561\n",
            " 1562 1565 1566 1573 1579 1588 1597 1599 1602 1607 1609 1612 1614 1615\n",
            " 1618 1622 1625 1630 1631 1643 1645 1649 1650 1656 1675 1676 1679 1684\n",
            " 1685 1691 1697 1701 1705 1706 1707 1709 1716 1726 1727 1728 1740 1742\n",
            " 1748 1751 1753 1763 1768 1769 1770 1786 1794 1798 1799 1801 1804 1812\n",
            " 1814 1821 1822 1825 1835 1841 1842 1846 1848 1856 1857 1874 1875 1879\n",
            " 1880 1892 1907 1917 1927 1930 1940 1942 1949 1952 1957 1966 1971 1974\n",
            " 1975 1976 1979 1981 1984 1987 1989 1992 1993 1995 2002 2003 2007 2010\n",
            " 2015 2027 2028 2029 2031 2035 2037 2049 2054 2056 2060 2061 2066 2070\n",
            " 2071 2075 2076 2082 2085 2087 2094 2098 2110 2111 2112 2113 2122 2123\n",
            " 2141 2142 2145 2157 2162 2166 2167 2172 2177 2180 2181 2183 2186 2195\n",
            " 2202 2209 2213 2215 2219 2220 2222 2224 2232 2233 2240 2244 2246 2248\n",
            " 2253 2259 2266 2276 2277 2280 2282 2284 2291 2298 2309 2311 2313 2322\n",
            " 2338 2339 2340 2341 2346 2347 2348 2350 2361 2363 2364 2365 2366 2369\n",
            " 2374 2375 2380 2382 2385 2386 2396 2406 2410 2413 2416 2420 2422 2427\n",
            " 2436 2438 2439 2440 2441 2444 2445 2448 2449 2453 2456 2459 2461 2463\n",
            " 2464 2469 2472 2474 2483 2494 2498 2505 2507 2509 2514 2517 2522 2524\n",
            " 2526 2531 2538 2547 2550 2554 2557 2561 2566 2571 2574 2577 2581 2585\n",
            " 2590 2594 2600 2603 2606 2612 2618 2620 2622 2625 2633 2642 2647 2654\n",
            " 2655 2656 2661 2665 2669 2671 2672 2677 2684 2694 2700 2701 2704 2706\n",
            " 2709 2712 2713 2714 2715 2725 2727 2730 2735 2738 2742 2743 2748 2756\n",
            " 2760 2763 2767 2772 2774 2776 2779 2781 2785 2786 2790 2792 2805 2806\n",
            " 2807 2810 2820 2827 2832 2841 2847 2852 2857 2862 2865 2867 2871 2873\n",
            " 2878 2881 2884 2887 2889]\n",
            "[CV 1/5; 10/10] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, subsample=0.6;, score=nan total time=   8.8s\n",
            "[CV 2/5; 10/10] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, subsample=0.6\n",
            "[23:44:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"<ipython-input-32-fc5a6eefbb96>\", line 5, in penalized_MSE_train\n",
            "    return penalized_MSE_helper(sci.special.inv_boxcox(y_true, fitted_lambda),sci.special.inv_boxcox(y_pred, fitted_lambda))\n",
            "  File \"<ipython-input-31-ae3c46e3511d>\", line 11, in penalized_MSE_helper\n",
            "    return (1/2)*MSE(critical_y, critical_predictions)+ (1/2)*MSE(common_y, common_predictions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 424, in mean_squared_error\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 91, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 792, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   3    5    7   12   14   20   22   25   27   31   32   33   43   47\n",
            "   51   62   64   69   70   71   74   76   88   89  109  111  113  115\n",
            "  125  133  137  141  143  145  148  156  159  174  175  176  180  190\n",
            "  191  195  199  200  203  205  207  209  210  212  213  215  220  227\n",
            "  231  238  252  258  262  268  269  272  310  311  314  315  332  334\n",
            "  356  361  362  363  364  367  368  369  371  373  377  380  384  385\n",
            "  390  399  403  407  409  410  417  429  431  435  444  449  464  465\n",
            "  466  467  470  474  475  480  489  490  492  493  498  499  501  505\n",
            "  509  512  513  517  518  521  524  529  533  534  537  539  541  545\n",
            "  549  550  558  560  564  573  574  577  580  584  585  586  587  594\n",
            "  598  605  606  612  624  627  628  630  642  647  649  651  663  665\n",
            "  679  680  691  696  701  710  711  716  727  731  733  736  744  750\n",
            "  751  759  760  763  765  771  773  776  780  789  794  806  809  812\n",
            "  814  820  821  833  838  844  855  859  866  868  884  890  894  902\n",
            "  905  907  909  916  917  921  922  931  934  937  958  968  969  973\n",
            "  979  981  990 1004 1010 1014 1015 1018 1033 1036 1037 1038 1040 1042\n",
            " 1043 1049 1068 1069 1076 1081 1084 1088 1090 1092 1094 1097 1100 1101\n",
            " 1105 1107 1116 1118 1123 1124 1128 1133 1141 1151 1152 1153 1161 1162\n",
            " 1164 1178 1179 1181 1189 1193 1197 1202 1209 1214 1221 1237 1241 1244\n",
            " 1245 1250 1253 1254 1258 1261 1262 1264 1266 1267 1268 1269 1270 1272\n",
            " 1276 1283 1287 1292 1293 1295 1303 1304 1310 1312 1316 1319 1328 1336\n",
            " 1341 1343 1344 1346 1351 1356 1374 1375 1378 1379 1383 1389 1397 1398\n",
            " 1399 1401 1404 1408 1413 1420 1437 1439 1440 1441 1446 1447 1450 1451\n",
            " 1458 1461 1475 1479 1481 1487 1488 1493 1504 1505 1506 1511 1512 1529\n",
            " 1532 1533 1537 1538 1541 1549 1550 1553 1559 1560 1565 1570 1571 1572\n",
            " 1573 1586 1588 1601 1607 1610 1611 1613 1614 1620 1626 1627 1634 1641\n",
            " 1647 1653 1658 1665 1672 1681 1684 1686 1696 1697 1705 1708 1720 1721\n",
            " 1725 1727 1738 1739 1742 1743 1751 1757 1762 1764 1769 1770 1773 1775\n",
            " 1779 1783 1786 1787 1789 1800 1803 1807 1809 1812 1821 1829 1836 1837\n",
            " 1839 1844 1855 1857 1875 1877 1879 1887 1889 1894 1897 1900 1902 1903\n",
            " 1907 1908 1917 1921 1923 1937 1947 1948 1951 1953 1956 1957 1959 1961\n",
            " 1964 1967 1968 1970 1974 1975 1981 1983 1986 1987 1994 1998 2003 2007\n",
            " 2009 2011 2013 2015 2020 2029 2036 2037 2041 2043 2045 2046 2047 2057\n",
            " 2058 2064 2070 2082 2086 2088 2089 2090 2093 2095 2101 2104 2110 2111\n",
            " 2113 2114 2115 2118 2119 2127 2134 2139 2141 2146 2147 2149 2150 2157\n",
            " 2159 2161 2166 2167 2169 2178 2182 2188 2197 2201 2207 2215 2217 2219\n",
            " 2222 2223 2224 2225 2231 2232 2233 2241 2245 2257 2262 2272 2291 2292\n",
            " 2293 2294 2296 2306 2307 2308 2309 2314 2340 2346 2347 2348 2353 2359\n",
            " 2369 2373 2380 2381 2382 2386 2393 2396 2401 2402 2403 2409 2411 2414\n",
            " 2419 2424 2431 2432 2433 2436 2437 2445 2450 2451 2452 2458 2460 2462\n",
            " 2463 2466 2471 2476 2494 2496 2503 2507 2510 2528 2530 2534 2535 2536\n",
            " 2538 2540 2542 2553 2554 2558 2559 2564 2571 2572 2574 2575 2582 2592\n",
            " 2594 2605 2612 2620 2623 2637 2643 2654 2657 2668 2677 2678 2680 2683\n",
            " 2690 2691 2693 2696 2700 2702 2705 2707 2708 2713 2717 2724 2727 2733\n",
            " 2735 2737 2748 2752 2753 2755 2765 2772 2775 2776 2781 2797 2800 2805\n",
            " 2806 2812 2813 2814 2815 2822 2831 2832 2835 2839 2843 2851 2855 2856\n",
            " 2859 2871 2872 2873 2884 2885 2886 2890 2892]\n",
            "[CV 2/5; 10/10] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, subsample=0.6;, score=-0.015 total time=   8.5s\n",
            "[CV 3/5; 10/10] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, subsample=0.6\n",
            "[23:44:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   4   11   30   35   36   37   41   54   63   66   69   76   87   97\n",
            "   98  102  106  130  131  133  134  142  148  149  159  161  165  176\n",
            "  178  187  190  191  194  201  202  206  224  226  227  232  238  246\n",
            "  248  250  256  259  261  264  270  271  274  278  279  287  288  290\n",
            "  303  304  307  313  314  316  318  322  324  327  334  335  339  346\n",
            "  347  349  358  367  369  373  374  375  376  377  378  390  391  393\n",
            "  394  397  398  411  420  421  423  428  429  435  442  443  448  450\n",
            "  457  461  464  465  467  469  474  493  497  499  500  501  503  520\n",
            "  529  530  545  547  553  561  562  567  569  570  573  586  592  597\n",
            "  598  599  603  604  605  611  625  629  630  633  636  640  645  654\n",
            "  658  662  670  675  678  686  690  692  697  699  702  707  710  718\n",
            "  719  725  731  732  733  738  745  746  752  777  782  784  788  790\n",
            "  793  794  797  798  800  802  804  813  824  825  826  832  836  852\n",
            "  856  859  861  864  868  871  878  885  889  891  896  904  911  913\n",
            "  917  923  927  952  958  962  969  974  976  979  986  988  989  990\n",
            "  997  998  999 1001 1008 1009 1029 1034 1041 1048 1052 1056 1061 1069\n",
            " 1072 1073 1080 1082 1091 1092 1099 1101 1111 1115 1120 1123 1124 1130\n",
            " 1134 1137 1144 1150 1152 1156 1168 1171 1173 1179 1183 1188 1196 1200\n",
            " 1202 1203 1205 1212 1214 1215 1222 1255 1256 1257 1262 1273 1279 1281\n",
            " 1287 1291 1306 1307 1310 1314 1315 1320 1324 1326 1329 1330 1332 1336\n",
            " 1346 1349 1351 1352 1353 1354 1365 1394 1397 1398 1400 1405 1407 1411\n",
            " 1423 1432 1434 1442 1445 1448 1449 1467 1469 1472 1490 1494 1495 1510\n",
            " 1516 1519 1521 1522 1526 1533 1547 1548 1551 1553 1574 1581 1583 1585\n",
            " 1589 1590 1598 1601 1611 1613 1614 1619 1622 1623 1637 1642 1647 1649\n",
            " 1650 1660 1667 1671 1673 1677 1682 1684 1695 1696 1697 1705 1723 1725\n",
            " 1727 1730 1732 1734 1742 1749 1772 1781 1782 1786 1795 1798 1802 1804\n",
            " 1805 1806 1812 1813 1814 1819 1820 1821 1831 1842 1844 1847 1849 1859\n",
            " 1860 1866 1869 1873 1878 1880 1886 1892 1896 1898 1900 1910 1911 1912\n",
            " 1919 1920 1922 1926 1931 1934 1941 1943 1946 1947 1951 1952 1957 1971\n",
            " 1972 1974 1979 1982 1983 1986 1989 1995 2000 2004 2010 2013 2014 2015\n",
            " 2016 2020 2021 2022 2038 2041 2042 2044 2045 2047 2056 2057 2059 2071\n",
            " 2074 2088 2091 2096 2107 2108 2110 2111 2113 2114 2120 2121 2134 2136\n",
            " 2140 2141 2147 2148 2151 2158 2163 2165 2166 2169 2172 2173 2178 2185\n",
            " 2188 2189 2203 2208 2209 2213 2218 2226 2234 2235 2251 2254 2263 2264\n",
            " 2266 2269 2271 2277 2278 2280 2281 2287 2288 2293 2294 2296 2302 2305\n",
            " 2306 2308 2310 2312 2315 2316 2318 2319 2335 2353 2357 2363 2368 2369\n",
            " 2370 2372 2375 2378 2379 2380 2382 2384 2405 2407 2414 2417 2429 2434\n",
            " 2435 2445 2451 2452 2454 2455 2459 2460 2467 2468 2473 2475 2479 2485\n",
            " 2487 2488 2490 2501 2509 2524 2530 2533 2535 2537 2538 2540 2541 2542\n",
            " 2552 2556 2557 2562 2564 2565 2566 2578 2581 2582 2587 2588 2589 2595\n",
            " 2599 2604 2607 2610 2612 2614 2616 2621 2626 2627 2630 2631 2632 2633\n",
            " 2644 2646 2648 2651 2652 2653 2654 2657 2660 2664 2671 2678 2686 2692\n",
            " 2696 2697 2698 2703 2704 2706 2707 2709 2710 2711 2716 2725 2729 2731\n",
            " 2734 2735 2739 2747 2755 2757 2758 2767 2771 2775 2777 2781 2791 2796\n",
            " 2802 2805 2806 2808 2809 2811 2814 2816 2818 2824 2827 2829 2833 2835\n",
            " 2837 2846 2850 2855 2858 2861 2865 2871 2874 2875 2877 2878 2879 2883\n",
            " 2886 2890 2891]\n",
            "[CV 3/5; 10/10] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, subsample=0.6;, score=-0.010 total time=   9.0s\n",
            "[CV 4/5; 10/10] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, subsample=0.6\n",
            "[23:44:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[   1    4   14   16   23   25   26   29   30   39   40   43   47   62\n",
            "   64   67   70   75   76   78   83   84   90   97   98  102  107  108\n",
            "  113  121  123  126  127  128  132  137  138  142  146  154  158  159\n",
            "  168  188  191  192  198  201  204  209  211  215  219  229  234  238\n",
            "  239  240  242  243  245  246  254  255  257  258  259  264  272  286\n",
            "  287  296  297  302  303  315  316  328  329  334  338  345  347  349\n",
            "  354  359  365  367  373  379  385  386  397  399  411  415  421  423\n",
            "  428  431  439  440  458  460  463  464  469  474  475  479  485  487\n",
            "  515  527  533  535  550  553  554  555  556  557  560  561  568  569\n",
            "  571  573  575  582  586  595  597  601  603  608  618  624  628  629\n",
            "  630  631  640  643  649  652  653  662  668  671  678  679  686  688\n",
            "  690  691  695  698  699  702  704  706  709  710  720  736  739  747\n",
            "  753  762  766  778  789  790  792  799  802  804  805  813  829  830\n",
            "  835  850  856  864  866  872  876  902  906  910  914  920  923  929\n",
            "  934  938  943  944  945  946  950  957  959  960  961  965  971  978\n",
            "  984  985  995  996  998  999 1000 1002 1005 1008 1012 1013 1014 1020\n",
            " 1036 1037 1049 1050 1059 1061 1062 1065 1066 1067 1070 1072 1074 1076\n",
            " 1082 1087 1090 1091 1093 1096 1101 1102 1104 1105 1112 1115 1118 1128\n",
            " 1134 1136 1141 1142 1143 1145 1150 1155 1163 1166 1181 1188 1189 1192\n",
            " 1193 1194 1198 1199 1200 1201 1202 1208 1209 1217 1222 1223 1225 1226\n",
            " 1229 1231 1232 1234 1238 1245 1247 1248 1249 1260 1261 1265 1266 1267\n",
            " 1269 1275 1276 1277 1289 1292 1302 1305 1310 1313 1314 1315 1317 1319\n",
            " 1321 1323 1324 1325 1328 1335 1344 1347 1349 1357 1361 1365 1369 1373\n",
            " 1379 1388 1391 1395 1397 1401 1407 1419 1421 1424 1426 1433 1438 1439\n",
            " 1441 1445 1461 1463 1464 1478 1482 1492 1493 1498 1499 1501 1503 1505\n",
            " 1511 1514 1516 1517 1519 1521 1524 1528 1529 1533 1534 1538 1539 1557\n",
            " 1558 1559 1579 1583 1587 1590 1602 1603 1613 1617 1619 1622 1626 1631\n",
            " 1641 1651 1654 1655 1657 1663 1668 1670 1688 1695 1706 1711 1712 1714\n",
            " 1719 1727 1728 1732 1734 1735 1736 1740 1746 1748 1761 1762 1767 1768\n",
            " 1778 1781 1783 1785 1788 1791 1795 1796 1802 1805 1810 1811 1813 1817\n",
            " 1818 1819 1822 1823 1839 1843 1862 1865 1873 1874 1875 1876 1877 1882\n",
            " 1887 1894 1896 1902 1905 1914 1915 1917 1925 1929 1931 1938 1939 1944\n",
            " 1952 1953 1954 1960 1965 1979 1980 1984 1986 1991 1993 1996 2001 2010\n",
            " 2011 2019 2024 2025 2032 2033 2036 2038 2040 2041 2042 2044 2047 2048\n",
            " 2051 2054 2056 2059 2069 2071 2078 2079 2080 2085 2087 2094 2097 2099\n",
            " 2104 2110 2115 2120 2121 2122 2129 2130 2135 2141 2143 2145 2148 2150\n",
            " 2157 2158 2160 2162 2166 2169 2175 2184 2195 2199 2202 2205 2213 2215\n",
            " 2217 2219 2220 2223 2224 2225 2228 2230 2231 2234 2235 2237 2248 2249\n",
            " 2253 2255 2257 2258 2259 2262 2277 2278 2282 2283 2291 2292 2297 2310\n",
            " 2314 2317 2320 2325 2326 2332 2337 2338 2340 2341 2343 2345 2349 2353\n",
            " 2354 2358 2360 2362 2376 2383 2384 2387 2390 2391 2396 2399 2400 2404\n",
            " 2408 2413 2415 2416 2417 2418 2421 2422 2427 2429 2432 2433 2450 2451\n",
            " 2454 2457 2458 2460 2461 2465 2467 2470 2471 2475 2480 2487 2494 2498\n",
            " 2502 2507 2523 2524 2531 2533 2536 2538 2543 2545 2547 2549 2551 2553\n",
            " 2554 2557 2561 2563 2567 2570 2571 2572 2579 2582 2583 2585 2586 2588\n",
            " 2594 2595 2609 2613 2615 2617 2620 2623 2624 2625 2632 2633 2640 2647\n",
            " 2649 2650 2655 2657 2662 2664 2668 2669 2671 2689 2699 2701 2704 2706\n",
            " 2707 2710 2717 2720 2723 2726 2733 2735 2736 2747 2754 2755 2757 2763\n",
            " 2771 2779 2786 2790 2791 2792 2796 2800 2802 2805 2809 2832 2840 2845\n",
            " 2846 2850 2855 2860 2861 2863 2869 2870 2876 2877 2879 2883 2887 2889]\n",
            "[CV 4/5; 10/10] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, subsample=0.6;, score=nan total time=   8.7s\n",
            "[CV 5/5; 10/10] START colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, subsample=0.6\n",
            "[23:44:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"<ipython-input-32-fc5a6eefbb96>\", line 5, in penalized_MSE_train\n",
            "    return penalized_MSE_helper(sci.special.inv_boxcox(y_true, fitted_lambda),sci.special.inv_boxcox(y_pred, fitted_lambda))\n",
            "  File \"<ipython-input-31-ae3c46e3511d>\", line 11, in penalized_MSE_helper\n",
            "    return (1/2)*MSE(critical_y, critical_predictions)+ (1/2)*MSE(common_y, common_predictions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 424, in mean_squared_error\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 91, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 792, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
            "\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   5   11   14   25   27   37   41   42   51   52   55   56   59   60\n",
            "   76   81   83   90   96  100  108  109  114  116  119  124  128  135\n",
            "  137  142  145  147  150  157  164  167  170  178  185  190  192  194\n",
            "  198  202  211  214  222  223  237  238  243  246  252  255  258  260\n",
            "  261  268  270  271  276  283  286  288  294  302  318  322  326  331\n",
            "  335  336  348  350  351  353  354  370  375  380  382  383  390  393\n",
            "  403  404  406  407  409  421  424  433  438  440  442  455  463  473\n",
            "  476  478  479  481  482  487  489  497  499  502  504  509  510  516\n",
            "  517  521  529  533  536  540  541  546  552  556  557  560  566  572\n",
            "  575  578  579  581  595  602  603  612  614  617  618  622  626  629\n",
            "  639  642  644  657  660  666  668  673  675  676  688  689  690  692\n",
            "  695  696  697  703  705  715  717  718  719  728  730  733  740  747\n",
            "  755  759  761  764  765  773  776  779  782  784  786  794  797  799\n",
            "  800  810  811  816  822  830  831  833  836  855  858  864  868  879\n",
            "  880  896  898  904  910  917  925  928  930  932  940  942  948  950\n",
            "  963  966  968  970  971  972  974  984  987  989  992  993  997 1002\n",
            " 1006 1010 1014 1023 1029 1032 1035 1041 1046 1050 1051 1057 1062 1063\n",
            " 1065 1067 1068 1069 1072 1076 1077 1088 1089 1093 1101 1107 1114 1118\n",
            " 1121 1128 1130 1131 1138 1139 1142 1144 1150 1151 1155 1161 1167 1175\n",
            " 1177 1181 1187 1194 1196 1199 1201 1202 1205 1222 1223 1225 1230 1231\n",
            " 1234 1246 1250 1252 1253 1255 1263 1270 1272 1273 1277 1279 1285 1289\n",
            " 1291 1297 1298 1303 1304 1306 1307 1311 1321 1328 1331 1336 1337 1341\n",
            " 1347 1355 1358 1364 1370 1372 1374 1376 1379 1380 1381 1383 1392 1394\n",
            " 1399 1404 1409 1412 1419 1420 1422 1431 1433 1437 1438 1441 1447 1448\n",
            " 1449 1454 1458 1459 1463 1465 1467 1468 1471 1486 1491 1497 1499 1501\n",
            " 1508 1509 1510 1514 1522 1524 1527 1533 1537 1542 1551 1554 1561 1563\n",
            " 1565 1567 1569 1571 1572 1574 1577 1581 1583 1584 1588 1595 1596 1598\n",
            " 1600 1608 1612 1617 1621 1624 1630 1635 1636 1637 1640 1643 1653 1656\n",
            " 1657 1661 1668 1672 1673 1676 1679 1681 1686 1687 1688 1696 1699 1701\n",
            " 1709 1710 1720 1722 1725 1726 1731 1733 1737 1738 1741 1746 1747 1749\n",
            " 1751 1754 1756 1763 1765 1772 1782 1783 1787 1788 1792 1796 1802 1809\n",
            " 1817 1819 1822 1834 1835 1848 1851 1860 1868 1876 1880 1893 1894 1900\n",
            " 1905 1929 1934 1938 1947 1948 1953 1956 1967 1969 1976 1978 1988 1989\n",
            " 1994 1995 1996 1999 2000 2005 2009 2011 2013 2020 2026 2027 2032 2045\n",
            " 2062 2063 2072 2074 2075 2081 2088 2089 2090 2099 2101 2110 2111 2117\n",
            " 2120 2129 2131 2132 2133 2138 2142 2143 2144 2147 2151 2153 2154 2166\n",
            " 2175 2178 2185 2188 2198 2202 2204 2206 2207 2209 2224 2230 2231 2237\n",
            " 2248 2249 2251 2258 2261 2262 2264 2272 2276 2280 2281 2282 2283 2285\n",
            " 2288 2295 2297 2300 2308 2314 2315 2316 2317 2320 2321 2327 2328 2332\n",
            " 2336 2337 2351 2359 2368 2370 2373 2383 2392 2394 2404 2405 2408 2410\n",
            " 2425 2435 2439 2440 2453 2458 2467 2470 2473 2478 2481 2483 2487 2489\n",
            " 2490 2499 2500 2505 2512 2513 2517 2522 2523 2524 2527 2528 2529 2533\n",
            " 2538 2541 2549 2551 2578 2589 2596 2601 2610 2627 2630 2633 2643 2645\n",
            " 2649 2653 2655 2672 2673 2679 2690 2692 2697 2698 2699 2705 2714 2718\n",
            " 2727 2732 2744 2745 2746 2747 2751 2757 2758 2761 2763 2767 2781 2782\n",
            " 2786 2789 2795 2801 2806 2810 2812 2814 2816 2818 2824 2826 2832 2833\n",
            " 2838 2841 2843 2844 2847 2850 2851 2853 2868 2871 2876 2878 2880 2881\n",
            " 2887 2888 2889 2892]\n",
            "[CV 5/5; 10/10] END colsample_bylevel=0.7999999999999999, colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100, subsample=0.6;, score=nan total time=   8.8s\n",
            "[23:44:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:775: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"<ipython-input-32-fc5a6eefbb96>\", line 5, in penalized_MSE_train\n",
            "    return penalized_MSE_helper(sci.special.inv_boxcox(y_true, fitted_lambda),sci.special.inv_boxcox(y_pred, fitted_lambda))\n",
            "  File \"<ipython-input-31-ae3c46e3511d>\", line 11, in penalized_MSE_helper\n",
            "    return (1/2)*MSE(critical_y, critical_predictions)+ (1/2)*MSE(common_y, common_predictions)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 424, in mean_squared_error\n",
            "    y_true, y_pred, multioutput\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py\", line 91, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 792, in check_array\n",
            "    _assert_all_finite(array, allow_nan=force_all_finite == \"allow-nan\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 116, in _assert_all_finite\n",
            "    type_err, msg_dtype if msg_dtype is not None else X.dtype\n",
            "ValueError: Input contains NaN, infinity or a value too large for dtype('float32').\n",
            "\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-0.00223567 -0.00245792         nan -0.00397269 -0.02787331         nan\n",
            " -0.00446286 -0.01572206 -0.00446993         nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(estimator=XGBRegressor(seed=20, tree_method='gpu_hist'),\n",
              "                   param_distributions={'colsample_bylevel': array([0.5, 0.6, 0.7, 0.8, 0.9]),\n",
              "                                        'colsample_bytree': array([0.5, 0.6, 0.7, 0.8, 0.9]),\n",
              "                                        'learning_rate': [0.01, 0.1, 0.5],\n",
              "                                        'max_depth': [5, 10, 15, 20],\n",
              "                                        'n_estimators': [100, 500, 1000],\n",
              "                                        'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])},\n",
              "                   scoring=make_scorer(penalized_MSE_train, greater_is_better=False),\n",
              "                   verbose=10)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best parameters:\", clf.best_params_)\n",
        "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))\n",
        "print('the MSE for tuned model XGB Regressor is',MSE(y_test, predictions))\n",
        "print('the weighted-MSE for tuned model XGB Regressor is',penalized_MSE(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwiFiEIzH4Ur",
        "outputId": "d8e6fb00-7ce2-4c4c-bea7-d0b301141a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'subsample': 0.7, 'n_estimators': 500, 'max_depth': 15, 'learning_rate': 0.01, 'colsample_bytree': 0.7999999999999999, 'colsample_bylevel': 0.7}\n",
            "Lowest RMSE:  0.04728283976535687\n",
            "the MSE for tuned model XGB Regressor is 0.002565872901295706\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
            " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
            " 96 97]\n",
            "the weighted-MSE for tuned model XGB Regressor is 7.521273302145339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range_values = np.arange(0.05,1.05,0.1)\n",
        "mse_ranges = []\n",
        "print(range_values)\n",
        "for val in range_values:\n",
        "    labels_range = y_test[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    correspondent_predictions = predictions[np.where(np.abs(y_test-val)<=0.05)]\n",
        "    mse_ranges.append(MSE(correspondent_predictions, labels_range))\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "intervals = ['0.0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4','0.4-0.5', '0.5-0.6', '0.6-0-7', '0.7-0.8', '0.8-0.9', '0.9-1.0']\n",
        "dict_mse = {'intervals': intervals, 'mse': mse_ranges}\n",
        "df_mse = pd.DataFrame.from_dict(dict_mse)\n",
        "sns.barplot(x = df_mse['intervals'], y = df_mse['mse'], color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "X81-RgfUIt9I",
        "outputId": "4eaa4a26-2d78-4dd1-fd6e-55fe93f53f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05 0.15 0.25 0.35 0.45 0.55 0.65 0.75 0.85 0.95]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 842.4x595.44 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}